{
  "benchmark_config": {
    "model_name": "all-MiniLM-L6-v2",
    "k_values": [
      1,
      3,
      5
    ],
    "batch_size": 8,
    "tools_path": "D:\\USC\\Assignments\\CSCI-544\\Project\\Enhancing_RAG_MCP\\1_Emulating_RAG_MCP\\data\\tools\\all_tools.json",
    "queries_path": "D:\\USC\\Assignments\\CSCI-544\\Project\\Enhancing_RAG_MCP\\1_Emulating_RAG_MCP\\data\\queries\\mcp_task_description.json",
    "num_tools": 28,
    "num_queries": 56
  },
  "queries": [
    {
      "query": "Hey, I’m working on this new dashboard that pulls search results from three different services—one for AI stuff, one for code hosting, and one for edge networking—and I’m scratching my head over how each handles pagination. Some APIs might use a page/page_size setup, others a cursor or next_cursor, and I’m not even sure if all of them support paging in their search calls or if I have to switch to their “list” routes instead. \n\nCould you dig into each service’s search endpoints and tell me:\n• whether it pages at all or not  \n• if it does, what style it uses (page numbers, cursors, etc.)  \n• the exact parameter names, types, required flags, and defaults  \n• any response fields that indicate where to pick up the next batch  \n\nAnd if a service’s search doesn’t page, check its list endpoints the same way. I really need a solid breakdown—names, defaults, response tokens—the whole picture, so I can convince my boss this setup will actually work. Need real details, not guesses. Thanks!",
      "fuzzy_query": "Hey, I’m working on this new dashboard that pulls search results from three different services—one for AI stuff, one for code hosting, and one for edge networking—and I’m scratching my head over how each handles pagination. Some APIs might use a page/page_size setup, others a cursor or next_cursor, and I’m not even sure if all of them support paging in their search calls or if I have to switch to their “list” routes instead. \n\nCould you dig into each service’s search endpoints and tell me:\n• whether it pages at all or not  \n• if it does, what style it uses (page numbers, cursors, etc.)  \n• the exact parameter names, types, required flags, and defaults  \n• any response fields that indicate where to pick up the next batch  \n\nAnd if a service’s search doesn’t page, check its list endpoints the same way. I really need a solid breakdown—names, defaults, response tokens—the whole picture, so I can convince my boss this setup will actually work. Need real details, not guesses. Thanks!",
      "ground_truth_tool": "OpenAPI Explorer",
      "query_id": "openapi_explorer_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Call for Papers",
        "Context7",
        "DEX Paprika",
        "Hugging Face",
        "Metropolitan Museum",
        "NASA Data",
        "National Parks",
        "NixOS",
        "Weather Data"
      ]
    },
    {
      "query": "Hey, I’m building a little integration for my team and could really use a sanity check on two services we’re about to hook up. One of them is an AI platform where most of what I’ll do is “create” stuff (models, completions, that kind of thing), and the other is a code-hosting service where I only care about endpoints under “/repos” for cloning, PRs, labels, etc. \n\nHere’s what I’m trying to figure out: for each of those AI create-calls, how many required fields do I actually need to send? And then for the repo routes on the other side, how many mandatory inputs are there in the path, query string or request body? On top of that, each service uses its own auth methods—API keys, OAuth2 flows, maybe others—and I’d love to know which types each one offers and which types they share so I can reuse our login flow.\n\nIt’d be a huge help if you could pull those counts straight from their specs, highlight any endpoints that demand more than three required inputs (those will need extra form design on our side), list out the auth scheme types for both platforms, and then point out the overlap. Ideally I’d get back a tidy JSON-style summary I can hand off to my manager. And please, real numbers only—I can’t show up with guesswork. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’m building a little integration for my team and could really use a sanity check on two services we’re about to hook up. One of them is an AI platform where most of what I’ll do is “create” stuff (models, completions, that kind of thing), and the other is a code-hosting service where I only care about endpoints under “/repos” for cloning, PRs, labels, etc. \n\nHere’s what I’m trying to figure out: for each of those AI create-calls, how many required fields do I actually need to send? And then for the repo routes on the other side, how many mandatory inputs are there in the path, query string or request body? On top of that, each service uses its own auth methods—API keys, OAuth2 flows, maybe others—and I’d love to know which types each one offers and which types they share so I can reuse our login flow.\n\nIt’d be a huge help if you could pull those counts straight from their specs, highlight any endpoints that demand more than three required inputs (those will need extra form design on our side), list out the auth scheme types for both platforms, and then point out the overlap. Ideally I’d get back a tidy JSON-style summary I can hand off to my manager. And please, real numbers only—I can’t show up with guesswork. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "OpenAPI Explorer",
      "query_id": "openapi_explorer_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Call for Papers",
        "Car Price Evaluator",
        "Math MCP",
        "Medical Calculator",
        "Metropolitan Museum",
        "Movie Recommender",
        "NixOS",
        "OKX Exchange",
        "Paper Search",
        "Unit Converter"
      ]
    },
    {
      "query": "Hey, I’m prepping for a Reactor X startup tomorrow and it’s stressing me out a bit. My boss handed me 14 different sensor readings, all in weird units, and I need to know if we meet the safety thresholds (which are all in SI or related metric units). Here’s what I’ve got:\n\n- Inlet temperature: 350 °F (threshold 150 °C)  \n- Inlet pressure: 50 psi (threshold 350 kPa)  \n- Reactor length: 10 ft (threshold 5 m)  \n- Catalyst weight: 500 lb (threshold 200 kg)  \n- Tank volume: 2000 imperial gal (threshold 8 m³)  \n- Data buffer: 2 GB (threshold 1500 MB)  \n- Heat-exchanger area: 1000 ft² (threshold 90 m²)  \n- Motor power: 50 hp (threshold 40 kW)  \n- Reaction time: 2 hours (threshold 6000 s)  \n- Valve angle: 0.25 turns (threshold 45 °)  \n- Conveyor speed: 2 m/s (threshold 4000 ft/min)  \n- Valve force: 500 lbf (threshold 2000 N)  \n- Fluid density: 128 lb/ft³ (threshold 2000 kg/m³)  \n- Fuel energy: 10000 Btu (threshold 12000 kJ)  \n\nCould you convert each reading into the same units as its threshold, then tell me for each one whether it passes (converted ≥ threshold) or fails? And if any come up as a fail, I’d really appreciate you doing a second check with a different conversion route—just to be absolutely sure we didn’t slip up on units. \n\nIt’d be awesome if you could bundle everything in a JSON summary that shows, for each sensor: its name, the original reading, the converted value with units, the threshold with units, pass/fail status, and the cross-validation details when you’ve done that extra check. I really need actual numbers on this—can’t go to my boss with just opinions. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’m prepping for a Reactor X startup tomorrow and it’s stressing me out a bit. My boss handed me 14 different sensor readings, all in weird units, and I need to know if we meet the safety thresholds (which are all in SI or related metric units). Here’s what I’ve got:\n\n- Inlet temperature: 350 °F (threshold 150 °C)  \n- Inlet pressure: 50 psi (threshold 350 kPa)  \n- Reactor length: 10 ft (threshold 5 m)  \n- Catalyst weight: 500 lb (threshold 200 kg)  \n- Tank volume: 2000 imperial gal (threshold 8 m³)  \n- Data buffer: 2 GB (threshold 1500 MB)  \n- Heat-exchanger area: 1000 ft² (threshold 90 m²)  \n- Motor power: 50 hp (threshold 40 kW)  \n- Reaction time: 2 hours (threshold 6000 s)  \n- Valve angle: 0.25 turns (threshold 45 °)  \n- Conveyor speed: 2 m/s (threshold 4000 ft/min)  \n- Valve force: 500 lbf (threshold 2000 N)  \n- Fluid density: 128 lb/ft³ (threshold 2000 kg/m³)  \n- Fuel energy: 10000 Btu (threshold 12000 kJ)  \n\nCould you convert each reading into the same units as its threshold, then tell me for each one whether it passes (converted ≥ threshold) or fails? And if any come up as a fail, I’d really appreciate you doing a second check with a different conversion route—just to be absolutely sure we didn’t slip up on units. \n\nIt’d be awesome if you could bundle everything in a JSON summary that shows, for each sensor: its name, the original reading, the converted value with units, the threshold with units, pass/fail status, and the cross-validation details when you’ve done that extra check. I really need actual numbers on this—can’t go to my boss with just opinions. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Unit Converter",
      "query_id": "unit_converter_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Car Price Evaluator",
        "FruityVice",
        "Game Trends",
        "Google Maps",
        "Medical Calculator",
        "OKX Exchange",
        "OpenAPI Explorer",
        "Paper Search",
        "Scientific Computing",
        "Weather Data"
      ]
    },
    {
      "query": "I’m gearing up for a 2 h 30 min high-altitude drone test flight and my boss wants every single detail in SI. Right now all my numbers are in U.S. customary units: engine inlet at 500 °F and outlet at 300 °F; propeller pitch is 15° (I’d like that in gons); cruise speed is 60 knots; altitude’s 10 000 ft; wing span 15 ft; wing area 1 200 in²; cargo-bay pressure 50 psi; takeoff thrust 3 000 lbf; on-board log storage is 2 GB with a 10 MB downlink buffer; battery capacity 5 kWh over this 2 h 30 min flight; and the fuel tank holds 200 US gal of fuel whose density is 810 g/L. \n\nCan you help me convert all of that—temperatures to kelvins, angle to gons, speed to m/s, lengths to meters, area to m², pressure to pascals, force to newtons, storage to bytes, energy to joules, compute the average power draw in kW then to horsepower, volume to m³, density to kg/m³, and time to seconds—then calculate the total starting fuel mass in kilograms and, if it ends up over 100 kg, report it in tonnes (otherwise in pounds)? In the end I need a tidy JSON where each entry has original_value, original_unit, converted_value, converted_unit, plus two computed fields—average_power and starting_fuel_mass—and a note on which fuel-mass branch you chose. I really need solid, data-driven numbers here—no hand-wavy estimates.",
      "fuzzy_query": "I’m gearing up for a 2 h 30 min high-altitude drone test flight and my boss wants every single detail in SI. Right now all my numbers are in U.S. customary units: engine inlet at 500 °F and outlet at 300 °F; propeller pitch is 15° (I’d like that in gons); cruise speed is 60 knots; altitude’s 10 000 ft; wing span 15 ft; wing area 1 200 in²; cargo-bay pressure 50 psi; takeoff thrust 3 000 lbf; on-board log storage is 2 GB with a 10 MB downlink buffer; battery capacity 5 kWh over this 2 h 30 min flight; and the fuel tank holds 200 US gal of fuel whose density is 810 g/L. \n\nCan you help me convert all of that—temperatures to kelvins, angle to gons, speed to m/s, lengths to meters, area to m², pressure to pascals, force to newtons, storage to bytes, energy to joules, compute the average power draw in kW then to horsepower, volume to m³, density to kg/m³, and time to seconds—then calculate the total starting fuel mass in kilograms and, if it ends up over 100 kg, report it in tonnes (otherwise in pounds)? In the end I need a tidy JSON where each entry has original_value, original_unit, converted_value, converted_unit, plus two computed fields—average_power and starting_fuel_mass—and a note on which fuel-mass branch you chose. I really need solid, data-driven numbers here—no hand-wavy estimates.",
      "ground_truth_tool": "Unit Converter",
      "query_id": "unit_converter_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Call for Papers",
        "Car Price Evaluator",
        "FruityVice",
        "Google Maps",
        "Huge Icons",
        "Hugging Face",
        "Math MCP",
        "National Parks",
        "NixOS",
        "Paper Search"
      ]
    },
    {
      "query": "I’m prepping for a presentation on the big global climate deals and could really use some solid data. Could you find the main half-dozen—or so—negotiation frameworks that show up most often and give me a quick intro to each, plus roughly how many internal links or references they have? Then dive into the Paris Agreement: I’d like about a 200-word summary focused on its emission-reduction targets and five standout facts. After that, I’m curious what topics usually pop up alongside the Kyoto Protocol—aim for at least five related ideas, and if you only spot a few, try to round it out. Oh, and would you cross-check those five Paris facts against your summary and flag any that don’t actually appear there? Finally, please wrap everything into a single JSON output since my professor insists on that. And whatever you pull, make sure it’s backed by real numbers or citations—I can’t go in there with just opinions.",
      "fuzzy_query": "I’m prepping for a presentation on the big global climate deals and could really use some solid data. Could you find the main half-dozen—or so—negotiation frameworks that show up most often and give me a quick intro to each, plus roughly how many internal links or references they have? Then dive into the Paris Agreement: I’d like about a 200-word summary focused on its emission-reduction targets and five standout facts. After that, I’m curious what topics usually pop up alongside the Kyoto Protocol—aim for at least five related ideas, and if you only spot a few, try to round it out. Oh, and would you cross-check those five Paris facts against your summary and flag any that don’t actually appear there? Finally, please wrap everything into a single JSON output since my professor insists on that. And whatever you pull, make sure it’s backed by real numbers or citations—I can’t go in there with just opinions.",
      "ground_truth_tool": "Wikipedia",
      "query_id": "wikipedia_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "BioMCP",
        "Call for Papers",
        "Context7",
        "FruityVice",
        "Google Maps",
        "Hugging Face",
        "Medical Calculator",
        "Metropolitan Museum",
        "OKX Exchange",
        "Unit Converter"
      ]
    },
    {
      "query": "I’m putting together a sustainability briefing and need to really understand how solar panels stack up against wind turbines when it comes to environmental impacts—think resource use, lifecycle emissions, land use, etc. Could you:\n\n- Give me a short, punchy summary of each technology’s environmental footprint (a paragraph or two each).\n- Pull out about five of the most important facts related to their environmental impact for each, and show them side-by-side so I can see the main differences at a glance.\n\nOn top of that, I’ve got to cover the policy side—what incentive schemes or regulatory frameworks are actually driving solar and wind adoption right now? A clear, two-to-three-paragraph overview of the key support mechanisms would be great. While you’re at it, when you look at the main write-ups on solar and wind, do they actually link to that policy overview? Let me know “yes” or “no” for each.\n\nLastly, if you spot another renewable technology in those policy discussions that seems like a smart next step for us to research, tell me which one and give me two sentences on why it’s worth a closer look. \n\nI’m presenting next week, so I really need solid numbers and references—can’t go in with just vague statements. Thanks!",
      "fuzzy_query": "I’m putting together a sustainability briefing and need to really understand how solar panels stack up against wind turbines when it comes to environmental impacts—think resource use, lifecycle emissions, land use, etc. Could you:\n\n- Give me a short, punchy summary of each technology’s environmental footprint (a paragraph or two each).\n- Pull out about five of the most important facts related to their environmental impact for each, and show them side-by-side so I can see the main differences at a glance.\n\nOn top of that, I’ve got to cover the policy side—what incentive schemes or regulatory frameworks are actually driving solar and wind adoption right now? A clear, two-to-three-paragraph overview of the key support mechanisms would be great. While you’re at it, when you look at the main write-ups on solar and wind, do they actually link to that policy overview? Let me know “yes” or “no” for each.\n\nLastly, if you spot another renewable technology in those policy discussions that seems like a smart next step for us to research, tell me which one and give me two sentences on why it’s worth a closer look. \n\nI’m presenting next week, so I really need solid numbers and references—can’t go in with just vague statements. Thanks!",
      "ground_truth_tool": "Wikipedia",
      "query_id": "wikipedia_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "BioMCP",
        "Call for Papers",
        "Car Price Evaluator",
        "Game Trends",
        "Medical Calculator",
        "Movie Recommender",
        "NASA Data",
        "OKX Exchange",
        "OSINT Intelligence",
        "Weather Data"
      ]
    },
    {
      "query": "I’m trying to plan a fun bike ride around Denver’s Central Park this Saturday morning—thinking of starting and ending at the Denver Art Museum sometime between 9 and noon. I’d love to swing by a really good café on the way—something within a few miles that’s got at least a 4-star rating and is actually open when I’m riding. But I don’t want to kill myself on hills or end up riding forever, so I’m hoping to find the spot that gives me the shortest round-trip plus the least uphill grunt. \n\nCould you help me figure out which cafés in about a 5 km radius fit the bill, rank them by total distance plus elevation gain, pick the best one, and then give me turn-by-turn bike directions (with distances, estimated times, and elevation change) for a 9 AM departure? Also, it’d be awesome to get a quick summary of all the candidates—name, address, rating, distance and elevation details—so I can see why the top pick wins. I really need actual numbers here, not just opinions, so I can be confident this ride won’t turn into a slog.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’m trying to plan a fun bike ride around Denver’s Central Park this Saturday morning—thinking of starting and ending at the Denver Art Museum sometime between 9 and noon. I’d love to swing by a really good café on the way—something within a few miles that’s got at least a 4-star rating and is actually open when I’m riding. But I don’t want to kill myself on hills or end up riding forever, so I’m hoping to find the spot that gives me the shortest round-trip plus the least uphill grunt. \n\nCould you help me figure out which cafés in about a 5 km radius fit the bill, rank them by total distance plus elevation gain, pick the best one, and then give me turn-by-turn bike directions (with distances, estimated times, and elevation change) for a 9 AM departure? Also, it’d be awesome to get a quick summary of all the candidates—name, address, rating, distance and elevation details—so I can see why the top pick wins. I really need actual numbers here, not just opinions, so I can be confident this ride won’t turn into a slog.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Google Maps",
      "query_id": "google_maps_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "BioMCP",
        "DEX Paprika",
        "Huge Icons",
        "Medical Calculator",
        "Metropolitan Museum",
        "NASA Data",
        "OKX Exchange",
        "OpenAPI Explorer",
        "Scientific Computing",
        "Weather Data"
      ]
    },
    {
      "query": "I’m planning a bike outing in downtown San Francisco next weekend and could really use a hand. I want to start around City Hall and rent from a solid shop that’s actually open when I arrive—and ideally rated 4 stars or higher. If I can’t find at least three places like that within a couple of kilometers, I’m okay with dropping to 3.5 stars just to have enough options. Then I’d love to cruise over to a top-rated café about a kilometer away. What I’m really after is the bike-shop/coffee-shop pairing that gives me the shortest ride. \n\nCould you figure out which rental spot and café that is, and give me all the nitty-gritty? I’d need the shop’s address, hours, phone number and website, plus the café’s name, address and rating. Also please include the total biking distance and time, full turn-by-turn directions, and how hilly the route is by giving me elevations at the start, midpoint and end—and even the street address of that midpoint. I need actual numbers and real locations, not vague guesses, so I can share it with my friends and get everything booked. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’m planning a bike outing in downtown San Francisco next weekend and could really use a hand. I want to start around City Hall and rent from a solid shop that’s actually open when I arrive—and ideally rated 4 stars or higher. If I can’t find at least three places like that within a couple of kilometers, I’m okay with dropping to 3.5 stars just to have enough options. Then I’d love to cruise over to a top-rated café about a kilometer away. What I’m really after is the bike-shop/coffee-shop pairing that gives me the shortest ride. \n\nCould you figure out which rental spot and café that is, and give me all the nitty-gritty? I’d need the shop’s address, hours, phone number and website, plus the café’s name, address and rating. Also please include the total biking distance and time, full turn-by-turn directions, and how hilly the route is by giving me elevations at the start, midpoint and end—and even the street address of that midpoint. I need actual numbers and real locations, not vague guesses, so I can share it with my friends and get everything booked. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Google Maps",
      "query_id": "google_maps_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "BioMCP",
        "Context7",
        "FruityVice",
        "Hugging Face",
        "Metropolitan Museum",
        "National Parks",
        "OKX Exchange",
        "OSINT Intelligence",
        "OpenAPI Explorer",
        "Scientific Computing"
      ]
    },
    {
      "query": "Hey, I’ve been tossing around this idea of launching a small sustainable agriculture venture—think urban farming or community gardens—right in downtown Seattle over the next six months. I’m really on the fence about timing and direction, so I was wondering if you could do a deep-dive I Ching reading for me. \n\nLike, what hexagram comes up first? Do any lines shift, and if they do, what’s the follow-up hexagram all about? Then, maybe run a second style of I Ching consult just to see if it echoes the first reading or highlights something totally different. I’d love to get the exact Chinese names, symbols, full commentary, and the line-by-line texts—so I’m not just getting a TL;DR, but the actual guidance in its own words.\n\nAt the end, could you weigh both readings side by side? Do they agree on the core message, or is one more cautious while the other pushes forward? And then give me a final take—should I dive in now, tweak the plan, or wait a bit? I really need those real quotes and details to share with my partner and make a solid call. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’ve been tossing around this idea of launching a small sustainable agriculture venture—think urban farming or community gardens—right in downtown Seattle over the next six months. I’m really on the fence about timing and direction, so I was wondering if you could do a deep-dive I Ching reading for me. \n\nLike, what hexagram comes up first? Do any lines shift, and if they do, what’s the follow-up hexagram all about? Then, maybe run a second style of I Ching consult just to see if it echoes the first reading or highlights something totally different. I’d love to get the exact Chinese names, symbols, full commentary, and the line-by-line texts—so I’m not just getting a TL;DR, but the actual guidance in its own words.\n\nAt the end, could you weigh both readings side by side? Do they agree on the core message, or is one more cautious while the other pushes forward? And then give me a final take—should I dive in now, tweak the plan, or wait a bit? I really need those real quotes and details to share with my partner and make a solid call. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Bibliomantic",
      "query_id": "bibliomantic_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Call for Papers",
        "Context7",
        "DEX Paprika",
        "Google Maps",
        "Huge Icons",
        "Metropolitan Museum",
        "Movie Recommender",
        "OKX Exchange",
        "OpenAPI Explorer",
        "Wikipedia"
      ]
    },
    {
      "query": "I’m trying to decide whether we should roll out our flagship product in the Southeast Asian market over the next few months. Our leadership team’s split – some think it’s the perfect moment, others worry it’s too much of a gamble. I’d love to tap into some I Ching insight to guide us. Could you peek at the oracle’s load (if it’s handling fewer than about fifty readings, go ahead with a full, in-depth cast; if it’s busier, do a quick toss of the coins)? Jot down the hexagram numbers and any moving lines for each, then pull in the commentaries. If the quick and deep readings agree, that’s our final verdict; if they clash, maybe do one more light toss to break the tie. Then, if there are moving lines, flip them to see the secondary hexagram and note its message too. At the end, I need everything laid out – the raw toss results, the final hexagram and its write-up, the follow-up one if it exists, and a clear recommendation I can share with my boss. Please give me actual numbers and detailed notes so I’m not just presenting opinions.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’m trying to decide whether we should roll out our flagship product in the Southeast Asian market over the next few months. Our leadership team’s split – some think it’s the perfect moment, others worry it’s too much of a gamble. I’d love to tap into some I Ching insight to guide us. Could you peek at the oracle’s load (if it’s handling fewer than about fifty readings, go ahead with a full, in-depth cast; if it’s busier, do a quick toss of the coins)? Jot down the hexagram numbers and any moving lines for each, then pull in the commentaries. If the quick and deep readings agree, that’s our final verdict; if they clash, maybe do one more light toss to break the tie. Then, if there are moving lines, flip them to see the secondary hexagram and note its message too. At the end, I need everything laid out – the raw toss results, the final hexagram and its write-up, the follow-up one if it exists, and a clear recommendation I can share with my boss. Please give me actual numbers and detailed notes so I’m not just presenting opinions.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Bibliomantic",
      "query_id": "bibliomantic_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Context7",
        "Google Maps",
        "Metropolitan Museum",
        "National Parks",
        "NixOS",
        "OSINT Intelligence",
        "Paper Search",
        "Reddit",
        "Scientific Computing",
        "Wikipedia"
      ]
    },
    {
      "query": "I’ve been asked to put together a 360-degree update on the BRAF V600E mutation in melanoma and honestly, I’m a bit swamped. I need to know what’s come out in the last three months—papers (including any preprints), how often this mutation actually shows up and what that might mean clinically, which late-stage vemurafenib trials are still recruiting and who’s backing them, plus any biomarker angles (like PD-L1 criteria), the current take on vemurafenib’s profile, and whether there have been serious safety alerts or even hiccups with the genomic testing kits used in these studies. Basically, I can’t show up without solid figures—allele frequencies, trial counts, sponsor names, adverse-event tallies, device problem reports—everything tied back to real sources. Can you help me pull all that together in one place?\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’ve been asked to put together a 360-degree update on the BRAF V600E mutation in melanoma and honestly, I’m a bit swamped. I need to know what’s come out in the last three months—papers (including any preprints), how often this mutation actually shows up and what that might mean clinically, which late-stage vemurafenib trials are still recruiting and who’s backing them, plus any biomarker angles (like PD-L1 criteria), the current take on vemurafenib’s profile, and whether there have been serious safety alerts or even hiccups with the genomic testing kits used in these studies. Basically, I can’t show up without solid figures—allele frequencies, trial counts, sponsor names, adverse-event tallies, device problem reports—everything tied back to real sources. Can you help me pull all that together in one place?\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "BioMCP",
      "query_id": "biomcp_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Context7",
        "DEX Paprika",
        "Huge Icons",
        "Medical Calculator",
        "Movie Recommender",
        "NixOS",
        "OSINT Intelligence",
        "OpenAPI Explorer",
        "Wikipedia"
      ]
    },
    {
      "query": "I’m working on a melanoma project and really stuck piecing together everything about that common BRAF V600E change. My boss wants a solid briefing on how that mutation drives the disease, what recent studies are saying, and whether treatments like vemurafenib or dabrafenib are truly holding up in patients who carry it. On top of that, I need to know what clinical trials are actually enrolling V600E-positive melanoma folks right now, how those trials are set up, what outcomes they’re reporting (and if any published papers or updates back them up), and how all that lines up with the drugs’ approved uses and safety concerns. \n\nI’m not looking for vague summaries—I need hard numbers, trial IDs, approval dates, key label warnings, safety‐signal stats, that sort of thing—all from the latest half‐year or so. Can you help me pull together a clear, evidence‐backed overview covering:\n\n• The role of BRAF V600E in melanoma  \n• Highlights from recent papers on that mutation  \n• Open Phase 2/3 studies targeting it (designs, outcomes, refs)  \n• Approval status and key label sections for vemurafenib/dabrafenib  \n• Any serious adverse event patterns reported post‐approval  \n\nI’ve got to show real data and sources—nothing off the cuff—so I can recommend the best targeted strategy. Thanks!",
      "fuzzy_query": "I’m working on a melanoma project and really stuck piecing together everything about that common BRAF V600E change. My boss wants a solid briefing on how that mutation drives the disease, what recent studies are saying, and whether treatments like vemurafenib or dabrafenib are truly holding up in patients who carry it. On top of that, I need to know what clinical trials are actually enrolling V600E-positive melanoma folks right now, how those trials are set up, what outcomes they’re reporting (and if any published papers or updates back them up), and how all that lines up with the drugs’ approved uses and safety concerns. \n\nI’m not looking for vague summaries—I need hard numbers, trial IDs, approval dates, key label warnings, safety‐signal stats, that sort of thing—all from the latest half‐year or so. Can you help me pull together a clear, evidence‐backed overview covering:\n\n• The role of BRAF V600E in melanoma  \n• Highlights from recent papers on that mutation  \n• Open Phase 2/3 studies targeting it (designs, outcomes, refs)  \n• Approval status and key label sections for vemurafenib/dabrafenib  \n• Any serious adverse event patterns reported post‐approval  \n\nI’ve got to show real data and sources—nothing off the cuff—so I can recommend the best targeted strategy. Thanks!",
      "ground_truth_tool": "BioMCP",
      "query_id": "biomcp_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Call for Papers",
        "Car Price Evaluator",
        "FruityVice",
        "Google Maps",
        "National Parks",
        "OKX Exchange",
        "OpenAPI Explorer",
        "Paper Search",
        "Weather Data",
        "Wikipedia"
      ]
    },
    {
      "query": "Hey, I’m knee-deep in organizing paper submissions for my team and just noticed there are dozens of Europe-based conferences on AI and on data privacy with deadlines sneaking up in the next week. I’m kind of panicking because I don’t want to miss any last-call dates—some might even close in the next 24 hours. \n\nCould you pull together a list of those upcoming European events in artificial intelligence and data privacy that still have open calls over the next seven days? It’d be awesome if you could flag which ones are truly urgent (like closing in a day) versus those with a bit more breathing room, and jot down the city, how many days we’ve got left, and whether it’s AI or privacy. \n\nI really need solid info—actual deadlines and locations—so I can get our proposals in on time. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’m knee-deep in organizing paper submissions for my team and just noticed there are dozens of Europe-based conferences on AI and on data privacy with deadlines sneaking up in the next week. I’m kind of panicking because I don’t want to miss any last-call dates—some might even close in the next 24 hours. \n\nCould you pull together a list of those upcoming European events in artificial intelligence and data privacy that still have open calls over the next seven days? It’d be awesome if you could flag which ones are truly urgent (like closing in a day) versus those with a bit more breathing room, and jot down the city, how many days we’ve got left, and whether it’s AI or privacy. \n\nI really need solid info—actual deadlines and locations—so I can get our proposals in on time. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Call for Papers",
      "query_id": "call_for_papers_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Car Price Evaluator",
        "FruityVice",
        "Huge Icons",
        "Math MCP",
        "Medical Calculator",
        "NASA Data",
        "OKX Exchange",
        "OSINT Intelligence",
        "Weather Data",
        "Wikipedia"
      ]
    },
    {
      "query": "I’m working on my PhD in sustainable energy and my supervisor just asked me to pull together a shortlist of conferences happening over the next six months that I should really keep an eye on. Honestly, there are so many calls for papers out there under labels like “renewable energy” or “sustainable energy” that I’m getting lost. Could you find me about five upcoming conferences—complete with their names, when they start (relative to now), and where they’re held—and highlight any common themes? I’ve noticed terms like wind, solar or hydro seem to show up a lot in titles, so if one of those subtopics is particularly hot, maybe zoom in on that a bit more. I need to send something solid to my supervisor soon, so please back it up with real event details, not just guesses.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’m working on my PhD in sustainable energy and my supervisor just asked me to pull together a shortlist of conferences happening over the next six months that I should really keep an eye on. Honestly, there are so many calls for papers out there under labels like “renewable energy” or “sustainable energy” that I’m getting lost. Could you find me about five upcoming conferences—complete with their names, when they start (relative to now), and where they’re held—and highlight any common themes? I’ve noticed terms like wind, solar or hydro seem to show up a lot in titles, so if one of those subtopics is particularly hot, maybe zoom in on that a bit more. I need to send something solid to my supervisor soon, so please back it up with real event details, not just guesses.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Call for Papers",
      "query_id": "call_for_papers_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "BioMCP",
        "FruityVice",
        "Hugging Face",
        "Math MCP",
        "Medical Calculator",
        "NASA Data",
        "Reddit",
        "Unit Converter",
        "Wikipedia"
      ]
    },
    {
      "query": "Hey, I’m prepping for a marketing push next week and could use some solid data. We need to spotlight the pickup brands that have the most models priced north of 100 000, while also highlighting car brands whose average model price sits under about 60 000. Then, if any brand shows up in both groups, I’d like to see what motorcycles they offer and how much those bikes go for. Could you pull together who the top three truck brands are (by count of six-figure models), which car brands make the budget cut, and any overlaps—and for those overlaps list out the bike models and their prices? I really need actual counts, averages, and price tags so I can back up my plan with real numbers, not just gut feelings. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’m prepping for a marketing push next week and could use some solid data. We need to spotlight the pickup brands that have the most models priced north of 100 000, while also highlighting car brands whose average model price sits under about 60 000. Then, if any brand shows up in both groups, I’d like to see what motorcycles they offer and how much those bikes go for. Could you pull together who the top three truck brands are (by count of six-figure models), which car brands make the budget cut, and any overlaps—and for those overlaps list out the bike models and their prices? I really need actual counts, averages, and price tags so I can back up my plan with real numbers, not just gut feelings. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Car Price Evaluator",
      "query_id": "car_price_evaluator_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "BioMCP",
        "Context7",
        "DEX Paprika",
        "Game Trends",
        "Medical Calculator",
        "Metropolitan Museum",
        "NASA Data",
        "Unit Converter",
        "Weather Data",
        "Wikipedia"
      ]
    },
    {
      "query": "Hey, I’m working on a little overview for my boss about how Brazilian car brands line up price-wise. Basically, I want to see which brands are on the cheaper end (say under R$40 000 on average), which sit in a mid-range (around R$40–80 000), and which ones are in that premium R$80 000-plus territory. For those top-tier brands, it’d be great to know if they’re big enough to also show up in bikes or trucks—and if there’s some internal brand code we can reference. At the end, I need a simple rundown with each brand’s average price, its segment (low/mid/high), and for the high-end names, their code plus a yes/no on whether they’ve diversified into motorcycles or trucks. I really need actual numbers and facts here—not just gut feelings—so I can back my recommendations with solid data. Could you help me pull this together?\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’m working on a little overview for my boss about how Brazilian car brands line up price-wise. Basically, I want to see which brands are on the cheaper end (say under R$40 000 on average), which sit in a mid-range (around R$40–80 000), and which ones are in that premium R$80 000-plus territory. For those top-tier brands, it’d be great to know if they’re big enough to also show up in bikes or trucks—and if there’s some internal brand code we can reference. At the end, I need a simple rundown with each brand’s average price, its segment (low/mid/high), and for the high-end names, their code plus a yes/no on whether they’ve diversified into motorcycles or trucks. I really need actual numbers and facts here—not just gut feelings—so I can back my recommendations with solid data. Could you help me pull this together?\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Car Price Evaluator",
      "query_id": "car_price_evaluator_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "BioMCP",
        "DEX Paprika",
        "Google Maps",
        "Hugging Face",
        "Math MCP",
        "National Parks",
        "Reddit",
        "Weather Data",
        "Wikipedia"
      ]
    },
    {
      "query": "I’m trying to choose between Next.js and Gatsby for a new project, and my manager wants a side-by-side look at their routing docs. Basically, I need to know how many real code examples each framework includes in its routing guide. If they’re almost neck-and-neck, I’d also like to see how many snippets they each have on dynamic routing. Could you dive into both official docs, count up those snippet examples for routing and dynamic routing, and let me know which one comes out ahead? I really need hard numbers—can’t just go to the boss with gut feelings.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’m trying to choose between Next.js and Gatsby for a new project, and my manager wants a side-by-side look at their routing docs. Basically, I need to know how many real code examples each framework includes in its routing guide. If they’re almost neck-and-neck, I’d also like to see how many snippets they each have on dynamic routing. Could you dive into both official docs, count up those snippet examples for routing and dynamic routing, and let me know which one comes out ahead? I really need hard numbers—can’t just go to the boss with gut feelings.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Context7",
      "query_id": "context7_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Call for Papers",
        "Car Price Evaluator",
        "Medical Calculator",
        "Metropolitan Museum",
        "Movie Recommender",
        "National Parks",
        "OSINT Intelligence",
        "Scientific Computing",
        "Unit Converter",
        "Wikipedia"
      ]
    },
    {
      "query": "Hey, I’ve got to lock in a JavaScript front-end framework for a new single-page app by next week, and routing plus solid state management are deal-breakers. I’m really prioritizing documentation that’s packed with real code examples, not just theory. Could you check out the two most highly regarded frameworks right now, tally up how many code snippets they each have for routing and for state handling, and see which one comes out ahead? If the front-runner has roughly 50 or more total snippets in those areas, I’ll go with that. If it falls short, I’d also want to know how many “advanced patterns” examples the second tool has and then pick whichever has more. I need actual counts to back this up—no vague opinions—so I can make a strong case to the team.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’ve got to lock in a JavaScript front-end framework for a new single-page app by next week, and routing plus solid state management are deal-breakers. I’m really prioritizing documentation that’s packed with real code examples, not just theory. Could you check out the two most highly regarded frameworks right now, tally up how many code snippets they each have for routing and for state handling, and see which one comes out ahead? If the front-runner has roughly 50 or more total snippets in those areas, I’ll go with that. If it falls short, I’d also want to know how many “advanced patterns” examples the second tool has and then pick whichever has more. I need actual counts to back this up—no vague opinions—so I can make a strong case to the team.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Context7",
      "query_id": "context7_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Call for Papers",
        "DEX Paprika",
        "Hugging Face",
        "Medical Calculator",
        "National Parks",
        "OSINT Intelligence",
        "Reddit",
        "Unit Converter",
        "Weather Data"
      ]
    },
    {
      "query": "I’m putting together a DeFi deep-dive for a client who’s curious how Ethereum stacks up against that other fast chain, Solana, in terms of big-money pools and how choppy they’ve been lately. Could you help me figure out which three pools on each network are moving the most USD volume right now, and call out any that jumped or dropped by more than about 5% in the last 24 hours? For those volatile ones, I’d love to see a daily price chart for roughly the past month and a look at the most recent ~50 swaps or liquidity moves. \n\nOn top of that, I need to know where USDC is getting the most action on each chain—so what’s the single largest USDC pair by volume, and how has its price trended day-to-day over the last month? And finally, can you give me a quick snapshot of overall DEX health across the ecosystem? I really need hard numbers and real data here—I can’t go in with just opinions. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’m putting together a DeFi deep-dive for a client who’s curious how Ethereum stacks up against that other fast chain, Solana, in terms of big-money pools and how choppy they’ve been lately. Could you help me figure out which three pools on each network are moving the most USD volume right now, and call out any that jumped or dropped by more than about 5% in the last 24 hours? For those volatile ones, I’d love to see a daily price chart for roughly the past month and a look at the most recent ~50 swaps or liquidity moves. \n\nOn top of that, I need to know where USDC is getting the most action on each chain—so what’s the single largest USDC pair by volume, and how has its price trended day-to-day over the last month? And finally, can you give me a quick snapshot of overall DEX health across the ecosystem? I really need hard numbers and real data here—I can’t go in with just opinions. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "DEX Paprika",
      "query_id": "dex_paprika_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Call for Papers",
        "Context7",
        "Game Trends",
        "Google Maps",
        "Hugging Face",
        "Medical Calculator",
        "Metropolitan Museum",
        "NASA Data",
        "OKX Exchange",
        "Weather Data"
      ]
    },
    {
      "query": "I’ve got this project where my team needs a clear picture of what’s been happening on the biggest DeFi venues over the last six months—specifically Uniswap V3 on Ethereum and QuickSwap on Polygon. I’m trying to figure out which pools have been doing the heaviest trading (let’s say the top five by volume on each chain), then dig into how those pools have behaved day-to-day: price swings, rough volatility, number of trades, that kind of thing. \n\nOn top of that, I’d like to know what tokens are sitting in each of those pools, and whether those same tokens show up in any major pools on the other network. Ultimately, I want a side-by-side look at each pool’s address, token info, volume stats, daily price history (so we can calculate a volatility percentage), plus a quick snapshot of transaction counts and where else those tokens are getting traded cross-chain. \n\nSounds like a lot, I know—but I really need actual figures and solid data to back this up. Can you help me pull all that together? Whatever you find, please make sure it’s backed up by real numbers or reliable sources, okay?\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’ve got this project where my team needs a clear picture of what’s been happening on the biggest DeFi venues over the last six months—specifically Uniswap V3 on Ethereum and QuickSwap on Polygon. I’m trying to figure out which pools have been doing the heaviest trading (let’s say the top five by volume on each chain), then dig into how those pools have behaved day-to-day: price swings, rough volatility, number of trades, that kind of thing. \n\nOn top of that, I’d like to know what tokens are sitting in each of those pools, and whether those same tokens show up in any major pools on the other network. Ultimately, I want a side-by-side look at each pool’s address, token info, volume stats, daily price history (so we can calculate a volatility percentage), plus a quick snapshot of transaction counts and where else those tokens are getting traded cross-chain. \n\nSounds like a lot, I know—but I really need actual figures and solid data to back this up. Can you help me pull all that together? Whatever you find, please make sure it’s backed up by real numbers or reliable sources, okay?\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "DEX Paprika",
      "query_id": "dex_paprika_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Car Price Evaluator",
        "FruityVice",
        "Google Maps",
        "Huge Icons",
        "Metropolitan Museum",
        "National Parks",
        "OKX Exchange",
        "OSINT Intelligence",
        "OpenAPI Explorer",
        "Unit Converter"
      ]
    },
    {
      "query": "Hey, I’m tinkering with a new snack idea and could really use your help. I want to build a fruit salad that ends up at about 500 calories, loads of fiber but under roughly 30 g of sugar total. My rough plan is to kick things off with an apple, then—depending on whether it falls into the Rosaceae family—go with either a strawberry or switch to pineapple. Next, based on how sweet that second pick is (I’m eyeballing about 5 g sugar per 100 g as my cutoff), I’d add either an orange or a banana. \n\nCan you grab the real nutrition facts for each of those fruits, help me decide which ones to use, figure out exactly how many grams of each to hit the 500 calories, maximize fiber, and stay under 30 g of sugar? I’d need:\n\n- The calories, fiber, and sugar per 100 g for each selected fruit\n- The precise weights of each fruit in the mix\n- A final tally of total calories, fiber, and sugar\n\nI really need hard numbers backed by genuine data—no guessing—so I can show the results to my team. Thanks!",
      "fuzzy_query": "Hey, I’m tinkering with a new snack idea and could really use your help. I want to build a fruit salad that ends up at about 500 calories, loads of fiber but under roughly 30 g of sugar total. My rough plan is to kick things off with an apple, then—depending on whether it falls into the Rosaceae family—go with either a strawberry or switch to pineapple. Next, based on how sweet that second pick is (I’m eyeballing about 5 g sugar per 100 g as my cutoff), I’d add either an orange or a banana. \n\nCan you grab the real nutrition facts for each of those fruits, help me decide which ones to use, figure out exactly how many grams of each to hit the 500 calories, maximize fiber, and stay under 30 g of sugar? I’d need:\n\n- The calories, fiber, and sugar per 100 g for each selected fruit\n- The precise weights of each fruit in the mix\n- A final tally of total calories, fiber, and sugar\n\nI really need hard numbers backed by genuine data—no guessing—so I can show the results to my team. Thanks!",
      "ground_truth_tool": "FruityVice",
      "query_id": "fruityvice_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "BioMCP",
        "Car Price Evaluator",
        "Context7",
        "DEX Paprika",
        "Game Trends",
        "Google Maps",
        "Medical Calculator",
        "NASA Data",
        "OKX Exchange"
      ]
    },
    {
      "query": "Hey, I’ve got a bit of a smoothie challenge for next week and could use your brain on it. My coach wants each 300 mL drink to have exactly 200 g of fruit but stay under about 30 g of sugar and still hit at least 8 g of fiber. I’m thinking about using things like apple, banana, orange, strawberry, kiwi, mango, pineapple, blueberry—and if that doesn’t give me enough options, maybe throw in pear or grape. \n\nWhat I really need is a handful of three-fruit blends (so roughly 66–67 g of each fruit) that meet those sugar and fiber limits, and then a 7-day lineup cycling through all the valid combos. Could you break down each day’s smoothie with exactly which fruits, how many grams of each, plus the total sugar and fiber? I can’t just wing this—I need real numbers to show my coach.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’ve got a bit of a smoothie challenge for next week and could use your brain on it. My coach wants each 300 mL drink to have exactly 200 g of fruit but stay under about 30 g of sugar and still hit at least 8 g of fiber. I’m thinking about using things like apple, banana, orange, strawberry, kiwi, mango, pineapple, blueberry—and if that doesn’t give me enough options, maybe throw in pear or grape. \n\nWhat I really need is a handful of three-fruit blends (so roughly 66–67 g of each fruit) that meet those sugar and fiber limits, and then a 7-day lineup cycling through all the valid combos. Could you break down each day’s smoothie with exactly which fruits, how many grams of each, plus the total sugar and fiber? I can’t just wing this—I need real numbers to show my coach.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "FruityVice",
      "query_id": "fruityvice_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Call for Papers",
        "Hugging Face",
        "Medical Calculator",
        "NASA Data",
        "National Parks",
        "NixOS",
        "Paper Search",
        "Reddit",
        "Unit Converter"
      ]
    },
    {
      "query": "I’m working at a small indie game publisher and my boss wants me to spot any breakout titles over the next week. What I’m really after are those under-the-radar games that haven’t cracked the top five bestsellers but are still pulling in roughly 5,000 concurrent players. If any of those are buzzing on both Steam and Epic, I’d love to see their individual ranks and an averaged ranking—only if that average comes out to ten or below. For games that only pop on Steam, make sure they’re not quietly heading into any Epic free-to-play or upcoming giveaways. And for anything only trending on Epic, flag if it’s set to go free in the next seven days. Could you put together a shortlist laid out like that, with real rank numbers, player counts, and free-status notes? I really need hard data to bring back to my team, not just gut feelings.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’m working at a small indie game publisher and my boss wants me to spot any breakout titles over the next week. What I’m really after are those under-the-radar games that haven’t cracked the top five bestsellers but are still pulling in roughly 5,000 concurrent players. If any of those are buzzing on both Steam and Epic, I’d love to see their individual ranks and an averaged ranking—only if that average comes out to ten or below. For games that only pop on Steam, make sure they’re not quietly heading into any Epic free-to-play or upcoming giveaways. And for anything only trending on Epic, flag if it’s set to go free in the next seven days. Could you put together a shortlist laid out like that, with real rank numbers, player counts, and free-status notes? I really need hard data to bring back to my team, not just gut feelings.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Game Trends",
      "query_id": "game_trends_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Car Price Evaluator",
        "FruityVice",
        "Google Maps",
        "Huge Icons",
        "Metropolitan Museum",
        "OKX Exchange",
        "OpenAPI Explorer",
        "Paper Search",
        "Unit Converter"
      ]
    },
    {
      "query": "Hey, I’m putting together a pitch for next week’s gaming campaign and I need a clear picture of what’s really popping on both Steam and Epic over the past seven days. I’m curious which titles made it into the top tier of buzz on each store, and then for the ten biggest hitters I’d like to know two things on Steam: what their peak live player counts looked like and where they sit in the sales charts right now. At the same time, I want to check on Epic whether those same games are free today or dropping free soon, and how hot they are on Epic’s trending list.\n\nI’m trying to spot the sweet spots—like games that have huge Steam crowds (say above about fifty-thousand at peak) but are free on Epic, which I’d flag as “High-Impact Free Play,” or stuff that’s selling really well on Steam (top twenty sellers) but isn’t filling its lobbies (under around ten-thousand peak) that I’d call “Sales-Driven.” Everything else would just be “Standard Trend.” \n\nCould you pull together real numbers for those ten games—Steam peak player counts, Steam sales ranks, Epic free status, Epic trending scores—and label each one with the category above? I’d really appreciate a neat, data-driven rundown (ideally something I can drop straight into a JSON-style report) because I need hard evidence to show the team, not just gut feelings.",
      "fuzzy_query": "Hey, I’m putting together a pitch for next week’s gaming campaign and I need a clear picture of what’s really popping on both Steam and Epic over the past seven days. I’m curious which titles made it into the top tier of buzz on each store, and then for the ten biggest hitters I’d like to know two things on Steam: what their peak live player counts looked like and where they sit in the sales charts right now. At the same time, I want to check on Epic whether those same games are free today or dropping free soon, and how hot they are on Epic’s trending list.\n\nI’m trying to spot the sweet spots—like games that have huge Steam crowds (say above about fifty-thousand at peak) but are free on Epic, which I’d flag as “High-Impact Free Play,” or stuff that’s selling really well on Steam (top twenty sellers) but isn’t filling its lobbies (under around ten-thousand peak) that I’d call “Sales-Driven.” Everything else would just be “Standard Trend.” \n\nCould you pull together real numbers for those ten games—Steam peak player counts, Steam sales ranks, Epic free status, Epic trending scores—and label each one with the category above? I’d really appreciate a neat, data-driven rundown (ideally something I can drop straight into a JSON-style report) because I need hard evidence to show the team, not just gut feelings.",
      "ground_truth_tool": "Game Trends",
      "query_id": "game_trends_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "BioMCP",
        "Call for Papers",
        "Context7",
        "DEX Paprika",
        "FruityVice",
        "Google Maps",
        "Medical Calculator",
        "NixOS",
        "OSINT Intelligence",
        "Reddit"
      ]
    },
    {
      "query": "Hey, I’m wrapping up a new UI kit for my app and there are five icons I absolutely need—home, search, user-profile, notification and settings—but I’m not sure they all show up under those exact names in the library I’m using. For example, I’ve seen “user-profile” turned into “person” or “account,” notifications sneak in as “bell” or “alert,” and settings sometimes go by “gear” or “cog.” Could you dig in and see which ones are available under the exact or fallback names, then give me the actual import or usage snippets for React, Vue, Angular, Svelte, React Native and Flutter? If any icon doesn’t exist at all or a framework can’t handle one, just flag it so I know what’s missing or only partially supported. I really need real code examples, not just guesses, so I can hand it straight to my team.",
      "fuzzy_query": "Hey, I’m wrapping up a new UI kit for my app and there are five icons I absolutely need—home, search, user-profile, notification and settings—but I’m not sure they all show up under those exact names in the library I’m using. For example, I’ve seen “user-profile” turned into “person” or “account,” notifications sneak in as “bell” or “alert,” and settings sometimes go by “gear” or “cog.” Could you dig in and see which ones are available under the exact or fallback names, then give me the actual import or usage snippets for React, Vue, Angular, Svelte, React Native and Flutter? If any icon doesn’t exist at all or a framework can’t handle one, just flag it so I know what’s missing or only partially supported. I really need real code examples, not just guesses, so I can hand it straight to my team.",
      "ground_truth_tool": "Huge Icons",
      "query_id": "huge_icons_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Call for Papers",
        "Car Price Evaluator",
        "DEX Paprika",
        "FruityVice",
        "Game Trends",
        "Medical Calculator",
        "NixOS",
        "Paper Search",
        "Unit Converter"
      ]
    },
    {
      "query": "I’m putting together docs for the Hugeicons set in my cross-platform component library and could really use some hard numbers and copy-and-paste code. First off, how many icons are in the entire collection? I need at least ten to make this guide worthwhile—if it’s under ten, let me know so I can rethink my approach. \n\nThen for the six core UI bits—home, search, notifications, settings, user, and logout—I’d like you to pick the very first icon that matches each name, but if it doesn’t show up try the “outline” version instead. Once you’ve chosen those, could you walk me through exactly how to import and use each one in React, Vue, Angular, Svelte, React Native, and Flutter? Finally, I need a ready-to-go React snippet for the home icon. \n\nIt would be amazing if you could bundle the whole thing—total icon count, a mapping of category to icon name (noting if you had to fall back), plus the usage instructions for each platform, and the React home example—in one JSON object I can drop straight into my docs. I really need concrete data and real code, not just general advice.",
      "fuzzy_query": "I’m putting together docs for the Hugeicons set in my cross-platform component library and could really use some hard numbers and copy-and-paste code. First off, how many icons are in the entire collection? I need at least ten to make this guide worthwhile—if it’s under ten, let me know so I can rethink my approach. \n\nThen for the six core UI bits—home, search, notifications, settings, user, and logout—I’d like you to pick the very first icon that matches each name, but if it doesn’t show up try the “outline” version instead. Once you’ve chosen those, could you walk me through exactly how to import and use each one in React, Vue, Angular, Svelte, React Native, and Flutter? Finally, I need a ready-to-go React snippet for the home icon. \n\nIt would be amazing if you could bundle the whole thing—total icon count, a mapping of category to icon name (noting if you had to fall back), plus the usage instructions for each platform, and the React home example—in one JSON object I can drop straight into my docs. I really need concrete data and real code, not just general advice.",
      "ground_truth_tool": "Huge Icons",
      "query_id": "huge_icons_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Car Price Evaluator",
        "DEX Paprika",
        "Google Maps",
        "Math MCP",
        "Medical Calculator",
        "Movie Recommender",
        "OKX Exchange",
        "OSINT Intelligence",
        "OpenAPI Explorer"
      ]
    },
    {
      "query": "Hey, I’m knee-deep in setting up a spam filter for a side project and could really use some hard data to make a solid call. I’ve been poking around for a pre-trained English classifier that’s not too huge (ideally something under roughly 700 million parameters) and is released under an Apache-2.0-style license. I first checked out a few DistilBERT-ish models, but if none fit the bill, I guess I could fall back to something BERT-based. \n\nAt the same time, I need a dataset with at least around 20 k training examples so it doesn’t feel too flimsy, and I’d love to trial a couple of live demos—preferably built with something like Gradio—just to see how they actually perform on spammy text. \n\nAlso, since keeping up with the latest is crucial, I want to skim today’s fresh papers and see if any mention spam classification; if nothing jumps out, I’m okay with looking at the first handful for any useful benchmark scores or datasets they report. Oh, and if there are any community collections focusing on spam classification, I’d like a peek at those too.\n\nCould you pull together:\n- Details on the best fitting model (name, parameter count, license)\n- Dataset info (ID, train-size)\n- Any live demo spaces you find (with actual performance metrics)\n- A few of today’s papers that talk about spam filtering, with their datasets and scores\n- And any relevant collections or curated sets around spam classification\n\nThen, based on all that evidence—numbers, links, whatever—I’d love a recommendation for which model+dataset pairing seems strongest for fine-tuning. I really need concrete figures and sources so I can walk my boss through it with confidence, not just guesses. Thanks!",
      "fuzzy_query": "Hey, I’m knee-deep in setting up a spam filter for a side project and could really use some hard data to make a solid call. I’ve been poking around for a pre-trained English classifier that’s not too huge (ideally something under roughly 700 million parameters) and is released under an Apache-2.0-style license. I first checked out a few DistilBERT-ish models, but if none fit the bill, I guess I could fall back to something BERT-based. \n\nAt the same time, I need a dataset with at least around 20 k training examples so it doesn’t feel too flimsy, and I’d love to trial a couple of live demos—preferably built with something like Gradio—just to see how they actually perform on spammy text. \n\nAlso, since keeping up with the latest is crucial, I want to skim today’s fresh papers and see if any mention spam classification; if nothing jumps out, I’m okay with looking at the first handful for any useful benchmark scores or datasets they report. Oh, and if there are any community collections focusing on spam classification, I’d like a peek at those too.\n\nCould you pull together:\n- Details on the best fitting model (name, parameter count, license)\n- Dataset info (ID, train-size)\n- Any live demo spaces you find (with actual performance metrics)\n- A few of today’s papers that talk about spam filtering, with their datasets and scores\n- And any relevant collections or curated sets around spam classification\n\nThen, based on all that evidence—numbers, links, whatever—I’d love a recommendation for which model+dataset pairing seems strongest for fine-tuning. I really need concrete figures and sources so I can walk my boss through it with confidence, not just guesses. Thanks!",
      "ground_truth_tool": "Hugging Face",
      "query_id": "hugging_face_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Call for Papers",
        "DEX Paprika",
        "FruityVice",
        "NASA Data",
        "NixOS",
        "OKX Exchange",
        "Paper Search",
        "Weather Data",
        "Wikipedia"
      ]
    },
    {
      "query": "I’ve got this side project where I need to set up an English-to-French translation workflow, but I’m only allowed to use what’s already on Hugging Face. I’m a bit stuck figuring out which of Google’s translation models are both top quality and still on the lean side (maybe under a billion parameters?), and which of the OPUS English-to-French datasets have enough examples to actually work well (I’m thinking at least around ten thousand). \n\nIdeally I’d love to land on the three strongest model-dataset pairings, ranked by the dataset’s size—so I can show my boss some concrete options. And once those are picked, I’d also like to see if there are any live demos or Spaces where I can test them out, plus any recent papers that actually mention those exact models or datasets. Oh, and if Google or OPUS have bundled any of these into collections, point me to those too. \n\nI really need hard numbers, precise model sizes and dataset counts, direct links to demos, papers or collections—nothing vague. Can you dig up all that evidence for me?",
      "fuzzy_query": "I’ve got this side project where I need to set up an English-to-French translation workflow, but I’m only allowed to use what’s already on Hugging Face. I’m a bit stuck figuring out which of Google’s translation models are both top quality and still on the lean side (maybe under a billion parameters?), and which of the OPUS English-to-French datasets have enough examples to actually work well (I’m thinking at least around ten thousand). \n\nIdeally I’d love to land on the three strongest model-dataset pairings, ranked by the dataset’s size—so I can show my boss some concrete options. And once those are picked, I’d also like to see if there are any live demos or Spaces where I can test them out, plus any recent papers that actually mention those exact models or datasets. Oh, and if Google or OPUS have bundled any of these into collections, point me to those too. \n\nI really need hard numbers, precise model sizes and dataset counts, direct links to demos, papers or collections—nothing vague. Can you dig up all that evidence for me?",
      "ground_truth_tool": "Hugging Face",
      "query_id": "hugging_face_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Car Price Evaluator",
        "Context7",
        "Game Trends",
        "Google Maps",
        "Metropolitan Museum",
        "National Parks",
        "Paper Search",
        "Weather Data",
        "Wikipedia"
      ]
    },
    {
      "query": "I’m pulling together a report on last quarter’s harvest from our 10 farms, and honestly I need some hard numbers. We recorded yields of 120, 150, 150, 200, 180, 170, 160, 140, 130, and 155 tons. \n\nHere’s what I’m trying to nail down:\n- What’s our total output, average yield per farm, the median and the most common harvest size, plus our lowest and highest yields and the overall spread?\n- Then, at $30 a ton, what does that translate to in revenue?\n- After covering $2,000 in fixed costs per farm (so 10 farms total), what’s left as net profit and what’s our profit margin when you express it as a percentage (rounded to the nearest whole number)?\n- Finally, I’m curious about the gap between our top-performing farm (200 tons) and the average yield—if that difference is more than 30 tons, I want to budget extra fertilizer at $10 per ton of that gap (and round up); if it’s 30 or less, I’ll stick with a $500 allowance (and round down).\n\nCould you crunch all those figures? I really need solid data—can’t go to my boss with just guesses. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’m pulling together a report on last quarter’s harvest from our 10 farms, and honestly I need some hard numbers. We recorded yields of 120, 150, 150, 200, 180, 170, 160, 140, 130, and 155 tons. \n\nHere’s what I’m trying to nail down:\n- What’s our total output, average yield per farm, the median and the most common harvest size, plus our lowest and highest yields and the overall spread?\n- Then, at $30 a ton, what does that translate to in revenue?\n- After covering $2,000 in fixed costs per farm (so 10 farms total), what’s left as net profit and what’s our profit margin when you express it as a percentage (rounded to the nearest whole number)?\n- Finally, I’m curious about the gap between our top-performing farm (200 tons) and the average yield—if that difference is more than 30 tons, I want to budget extra fertilizer at $10 per ton of that gap (and round up); if it’s 30 or less, I’ll stick with a $500 allowance (and round down).\n\nCould you crunch all those figures? I really need solid data—can’t go to my boss with just guesses. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Math MCP",
      "query_id": "math_mcp_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "BioMCP",
        "Car Price Evaluator",
        "Context7",
        "DEX Paprika",
        "Google Maps",
        "Huge Icons",
        "Hugging Face",
        "Movie Recommender",
        "Paper Search"
      ]
    },
    {
      "query": "Hey, I’ve been digging into my sales over the last six months—120, 150, 130, 170, 150 and 160 units—and I’m honestly a bit lost on how to pull it all together for my boss. Could you help me figure out where I stand overall (like total sales, average, median, and which month number appeared most often), spot the best and worst months, and even see how the top month compares to the bottom as a ratio? \n\nAlso, I heard it’s useful to look at how skewed things are by subtracting the median from the mean, and then rounding that skewness differently depending on whether it’s positive or not. On top of that, we’re aiming for an average of 180 units over the next seven months—so I need to know the total target for those seven months and exactly how many extra units I’d have to push next month to hit it (rounded to a whole number). \n\nCould you put all of that into a clean JSON summary (with fields like total_sales, average_sales, median_sales, mode_sales, max_sales, min_sales, max_to_min_ratio, skewness, adjusted_skewness, target_total_7_months, additional_needed_next_month_exact, additional_needed_next_month_rounded)? I really need real numbers for every piece so I can back it up properly—no guesses, just solid calculations.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’ve been digging into my sales over the last six months—120, 150, 130, 170, 150 and 160 units—and I’m honestly a bit lost on how to pull it all together for my boss. Could you help me figure out where I stand overall (like total sales, average, median, and which month number appeared most often), spot the best and worst months, and even see how the top month compares to the bottom as a ratio? \n\nAlso, I heard it’s useful to look at how skewed things are by subtracting the median from the mean, and then rounding that skewness differently depending on whether it’s positive or not. On top of that, we’re aiming for an average of 180 units over the next seven months—so I need to know the total target for those seven months and exactly how many extra units I’d have to push next month to hit it (rounded to a whole number). \n\nCould you put all of that into a clean JSON summary (with fields like total_sales, average_sales, median_sales, mode_sales, max_sales, min_sales, max_to_min_ratio, skewness, adjusted_skewness, target_total_7_months, additional_needed_next_month_exact, additional_needed_next_month_rounded)? I really need real numbers for every piece so I can back it up properly—no guesses, just solid calculations.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Math MCP",
      "query_id": "math_mcp_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Call for Papers",
        "DEX Paprika",
        "FruityVice",
        "Metropolitan Museum",
        "OKX Exchange",
        "OSINT Intelligence",
        "Paper Search",
        "Unit Converter",
        "Weather Data"
      ]
    },
    {
      "query": "I’ve been wrestling with setting up Neovim in a truly rock-solid NixOS environment and could really use a clear snapshot of where things stand. Here’s the deal: I’m on the stable NixOS channel, but I’m not even sure which channels are still alive or where Neovim lives in each. I’d love to know if the specific 0.9.2 release is packaged there—if it isn’t, what are the last few Neovim versions I could grab reproducibly? On top of that, I’m dabbling with flakes and want to see how many community flakes actually offer Neovim and what the download stats look like. Then there’s Home Manager and nix-darwin—does “programs.neovim” show up in their option trees, what does its entry look like, and how deep does the support go? Basically, I need hard numbers and real metadata—channel names, package counts, version hashes or fallback lists, flake counts, option paths, anything that proves this is actually supported end to end. I can’t go forward on gut feelings alone, so whatever you find, make sure it’s backed up by concrete data.",
      "fuzzy_query": "I’ve been wrestling with setting up Neovim in a truly rock-solid NixOS environment and could really use a clear snapshot of where things stand. Here’s the deal: I’m on the stable NixOS channel, but I’m not even sure which channels are still alive or where Neovim lives in each. I’d love to know if the specific 0.9.2 release is packaged there—if it isn’t, what are the last few Neovim versions I could grab reproducibly? On top of that, I’m dabbling with flakes and want to see how many community flakes actually offer Neovim and what the download stats look like. Then there’s Home Manager and nix-darwin—does “programs.neovim” show up in their option trees, what does its entry look like, and how deep does the support go? Basically, I need hard numbers and real metadata—channel names, package counts, version hashes or fallback lists, flake counts, option paths, anything that proves this is actually supported end to end. I can’t go forward on gut feelings alone, so whatever you find, make sure it’s backed up by concrete data.",
      "ground_truth_tool": "NixOS",
      "query_id": "nixos_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Car Price Evaluator",
        "Context7",
        "FruityVice",
        "Game Trends",
        "Google Maps",
        "Huge Icons",
        "Movie Recommender",
        "National Parks",
        "OSINT Intelligence",
        "Scientific Computing"
      ]
    },
    {
      "query": "I’ve been banging my head against getting a rock-solid Python 3.10 setup that works exactly the same on NixOS (with flakes on unstable) and on my Mac via nix-darwin. What I really need is to pin down the precise Python 3.10 package from unstable—ideally lock in version 3.10.8 by its commit hash—then find out if there’s a community flake out there bundling that (or a later) release and pick the best one. On top of that, I want to wire it up in home-manager and nix-darwin so Jupyter and all my usual Python packages just land in my user environment without me juggling things by hand.\n\nCould you help me track down:\n\n• The exact NixOS package name for Python 3.10 on the unstable channel and its full package metadata?  \n• The version history so I can grab the commit hash for 3.10.8?  \n• A good community flake that already includes Python 3.10.8 or above (with name and any relevant metadata)?  \n• The right option path and example config block in home-manager to enable Python packages plus Jupyter Notebook?  \n• The parallel option group and config snippet for nix-darwin to get the same Python/Jupyter support on macOS?  \n• Finally, a complete flake.nix snippet that pins that exact commit, imports the chosen flake, and sets up both home-manager and darwin modules with those options?\n\nI really need the actual values—package names, commit hashes, option names/paths, config blocks, etc.—so I can hand this over to my team and prove it’s rock solid. Thanks!",
      "fuzzy_query": "I’ve been banging my head against getting a rock-solid Python 3.10 setup that works exactly the same on NixOS (with flakes on unstable) and on my Mac via nix-darwin. What I really need is to pin down the precise Python 3.10 package from unstable—ideally lock in version 3.10.8 by its commit hash—then find out if there’s a community flake out there bundling that (or a later) release and pick the best one. On top of that, I want to wire it up in home-manager and nix-darwin so Jupyter and all my usual Python packages just land in my user environment without me juggling things by hand.\n\nCould you help me track down:\n\n• The exact NixOS package name for Python 3.10 on the unstable channel and its full package metadata?  \n• The version history so I can grab the commit hash for 3.10.8?  \n• A good community flake that already includes Python 3.10.8 or above (with name and any relevant metadata)?  \n• The right option path and example config block in home-manager to enable Python packages plus Jupyter Notebook?  \n• The parallel option group and config snippet for nix-darwin to get the same Python/Jupyter support on macOS?  \n• Finally, a complete flake.nix snippet that pins that exact commit, imports the chosen flake, and sets up both home-manager and darwin modules with those options?\n\nI really need the actual values—package names, commit hashes, option names/paths, config blocks, etc.—so I can hand this over to my team and prove it’s rock solid. Thanks!",
      "ground_truth_tool": "NixOS",
      "query_id": "nixos_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "DEX Paprika",
        "Game Trends",
        "Hugging Face",
        "Metropolitan Museum",
        "Movie Recommender",
        "OKX Exchange",
        "OpenAPI Explorer",
        "Reddit",
        "Scientific Computing",
        "Wikipedia"
      ]
    },
    {
      "query": "I’ve got a bit of a situation with the domain example-inc.com. My boss wants a full picture of any look-alike sites, subdomains and exposed services so we can see if someone’s squatting on typos or even hosting malicious stuff on the same network. I’m not even sure how many variants there might be if you fuzz it a bit, and I don’t want to miss a single suspicious spelling error or clone that ends up pointing back to our own servers. \n\nCould you help me track down all the possible typo-style domains that resemble example-inc.com, figure out which ones pose the biggest risk, and then map out what subdomains they’ve got? I also need to know every IP they resolve to, what ports are open (especially SSH or web ports), and who technically “owns” each IP and domain from a registration standpoint. And if any of those look-alikes share IP ranges with the real example-inc.com, flag that as a potential “sibling” setup. \n\nAt the end, I really need solid numbers or output—like actual DNS/DNS record details, open-port findings, and registrar versus network-owner info—so I can show my team real evidence. Does that make sense?",
      "fuzzy_query": "I’ve got a bit of a situation with the domain example-inc.com. My boss wants a full picture of any look-alike sites, subdomains and exposed services so we can see if someone’s squatting on typos or even hosting malicious stuff on the same network. I’m not even sure how many variants there might be if you fuzz it a bit, and I don’t want to miss a single suspicious spelling error or clone that ends up pointing back to our own servers. \n\nCould you help me track down all the possible typo-style domains that resemble example-inc.com, figure out which ones pose the biggest risk, and then map out what subdomains they’ve got? I also need to know every IP they resolve to, what ports are open (especially SSH or web ports), and who technically “owns” each IP and domain from a registration standpoint. And if any of those look-alikes share IP ranges with the real example-inc.com, flag that as a potential “sibling” setup. \n\nAt the end, I really need solid numbers or output—like actual DNS/DNS record details, open-port findings, and registrar versus network-owner info—so I can show my team real evidence. Does that make sense?",
      "ground_truth_tool": "OSINT Intelligence",
      "query_id": "osint_intelligence_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Car Price Evaluator",
        "Context7",
        "DEX Paprika",
        "FruityVice",
        "Game Trends",
        "Hugging Face",
        "National Parks",
        "Scientific Computing",
        "Wikipedia"
      ]
    },
    {
      "query": "Hey, I’ve got this sketchy domain, fakeshoponline.com, that only popped up roughly three months ago and now keeps showing up in phishing reports. I’m trying to piece together who’s really behind it—what their name servers and mail servers look like, any subdomains they’ve spun up recently, and where all those endpoints actually live. On top of that, I’m worried about look-alike tricks—domains with just a letter or two changed—that might resolve to the same IP space and even run a web server or open mail relay. Can you help me trace all of that back to the registrant’s info so I can see which ones share the same owner and which are red herrings? I really need everything backed by concrete DNS records, IP mappings, port/service checks, and ownership details—so I can show my team hard evidence, not just theories.",
      "fuzzy_query": "Hey, I’ve got this sketchy domain, fakeshoponline.com, that only popped up roughly three months ago and now keeps showing up in phishing reports. I’m trying to piece together who’s really behind it—what their name servers and mail servers look like, any subdomains they’ve spun up recently, and where all those endpoints actually live. On top of that, I’m worried about look-alike tricks—domains with just a letter or two changed—that might resolve to the same IP space and even run a web server or open mail relay. Can you help me trace all of that back to the registrant’s info so I can see which ones share the same owner and which are red herrings? I really need everything backed by concrete DNS records, IP mappings, port/service checks, and ownership details—so I can show my team hard evidence, not just theories.",
      "ground_truth_tool": "OSINT Intelligence",
      "query_id": "osint_intelligence_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Call for Papers",
        "Context7",
        "Game Trends",
        "Google Maps",
        "Metropolitan Museum",
        "Movie Recommender",
        "OKX Exchange",
        "Scientific Computing",
        "Weather Data",
        "Wikipedia"
      ]
    },
    {
      "query": "Hey, I’m putting together a quick rundown of how active conversations have been in r/MachineLearning versus r/artificial over the past week. I’d love to know which of the hottest posts in each community really took off—how many comments they started with and how much they grew when you dig into the deeper threads. If any threads jumped past around fifty comments, could you take a closer look at how the discussion branches out there?\n\nI’m also really curious about anything mentioning GPT, Transformer, or LLaMA—how those keyword-driven talks compare in volume and depth to everything else. And then, for an extra comparison, if any exact same titles showed up in both subreddits, can you pull the first handful of comments from each and highlight any difference in tone or main concerns?\n\nAt the end, I need a sense of which discussions saw the biggest surge in engagement, the top three most-talked-about GPT/Transformer/LLaMA threads, and five solid recommendations on which AI topics are worth keeping an eye on next. I really need real comment counts and clear evidence behind it—no wild guesses. Thanks!",
      "fuzzy_query": "Hey, I’m putting together a quick rundown of how active conversations have been in r/MachineLearning versus r/artificial over the past week. I’d love to know which of the hottest posts in each community really took off—how many comments they started with and how much they grew when you dig into the deeper threads. If any threads jumped past around fifty comments, could you take a closer look at how the discussion branches out there?\n\nI’m also really curious about anything mentioning GPT, Transformer, or LLaMA—how those keyword-driven talks compare in volume and depth to everything else. And then, for an extra comparison, if any exact same titles showed up in both subreddits, can you pull the first handful of comments from each and highlight any difference in tone or main concerns?\n\nAt the end, I need a sense of which discussions saw the biggest surge in engagement, the top three most-talked-about GPT/Transformer/LLaMA threads, and five solid recommendations on which AI topics are worth keeping an eye on next. I really need real comment counts and clear evidence behind it—no wild guesses. Thanks!",
      "ground_truth_tool": "Reddit",
      "query_id": "reddit_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Context7",
        "DEX Paprika",
        "Google Maps",
        "NASA Data",
        "OpenAPI Explorer",
        "Paper Search",
        "Scientific Computing",
        "Unit Converter",
        "Wikipedia"
      ]
    },
    {
      "query": "Hey, I’m putting together a quick highlight for our ML community newsletter and I want to focus on two posts: the one that’s getting the most chatter right now and the next biggest by upvotes. Could you:\n\n• Grab the current top 5 hot threads from r/MachineLearning  \n• Figure out which one has the highest comment count and call that our “main” thread  \n• Skim its first 15 top-level comments (down to three replies deep) and check how many of those 15 actually sparked at least one reply—if more than 10 did, dig two more levels deep instead  \n• At the same time, pull the runner-up by score from the remaining four, read its first 10 comments up to two levels deep  \n• Finally, give me a JSON array of two objects (main and runner-up) where each object has:  \n  – id (post ID)  \n  – title  \n  – score  \n  – comment_count  \n  – fetched_depth (the depth you ended up using)  \n  – top_comment_snippet (the text of its single most upvoted top-level comment)  \n  – deeper_refetch_performed (true only if you had to go deeper on the main thread)\n\nI really need the real numbers and snippets so I can drop this straight into our newsletter—no guesses, just hard data. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’m putting together a quick highlight for our ML community newsletter and I want to focus on two posts: the one that’s getting the most chatter right now and the next biggest by upvotes. Could you:\n\n• Grab the current top 5 hot threads from r/MachineLearning  \n• Figure out which one has the highest comment count and call that our “main” thread  \n• Skim its first 15 top-level comments (down to three replies deep) and check how many of those 15 actually sparked at least one reply—if more than 10 did, dig two more levels deep instead  \n• At the same time, pull the runner-up by score from the remaining four, read its first 10 comments up to two levels deep  \n• Finally, give me a JSON array of two objects (main and runner-up) where each object has:  \n  – id (post ID)  \n  – title  \n  – score  \n  – comment_count  \n  – fetched_depth (the depth you ended up using)  \n  – top_comment_snippet (the text of its single most upvoted top-level comment)  \n  – deeper_refetch_performed (true only if you had to go deeper on the main thread)\n\nI really need the real numbers and snippets so I can drop this straight into our newsletter—no guesses, just hard data. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Reddit",
      "query_id": "reddit_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Call for Papers",
        "Context7",
        "Huge Icons",
        "Hugging Face",
        "Math MCP",
        "Metropolitan Museum",
        "NixOS",
        "OpenAPI Explorer",
        "Paper Search",
        "Weather Data"
      ]
    },
    {
      "query": "I’ve been plotting a week-long road trip through California and Oregon, bouncing between parks where I can both hike and camp. I’d love to avoid anywhere that’s under closure alerts or has serious hazards, and I really need campgrounds that actually have showers—plus I’d like the visitor centers to be open every day from about 9 AM to 5 PM so I’m not showing up at a ghost town. On top of that, I’d be thrilled if there’s something cool going on each evening after 6 PM—like ranger talks, stargazing programs, live music, whatever. \n\nCould you help me figure out which parks fit all those criteria over the next seven days and then sketch out a day-by-day plan? I’m imagining something that tells me each day: where I’m headed, a quick park overview, which visitor centers are open with their hours, which campsites have showers, and any evening events I shouldn’t miss. \n\nI really need the details—current alerts, official hours, amenity lists, event schedules—so I can actually book and not just rely on hearsay. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’ve been plotting a week-long road trip through California and Oregon, bouncing between parks where I can both hike and camp. I’d love to avoid anywhere that’s under closure alerts or has serious hazards, and I really need campgrounds that actually have showers—plus I’d like the visitor centers to be open every day from about 9 AM to 5 PM so I’m not showing up at a ghost town. On top of that, I’d be thrilled if there’s something cool going on each evening after 6 PM—like ranger talks, stargazing programs, live music, whatever. \n\nCould you help me figure out which parks fit all those criteria over the next seven days and then sketch out a day-by-day plan? I’m imagining something that tells me each day: where I’m headed, a quick park overview, which visitor centers are open with their hours, which campsites have showers, and any evening events I shouldn’t miss. \n\nI really need the details—current alerts, official hours, amenity lists, event schedules—so I can actually book and not just rely on hearsay. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "National Parks",
      "query_id": "national_parks_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Call for Papers",
        "DEX Paprika",
        "FruityVice",
        "Math MCP",
        "Medical Calculator",
        "Movie Recommender",
        "OKX Exchange",
        "OSINT Intelligence",
        "Weather Data"
      ]
    },
    {
      "query": "I’m planning a week of backpacking in California and trying to pick the three best national parks that won’t let me down. Ideally they’d offer solid hiking and camping, have almost no current closures or safety alerts, keep their visitor centers or services open every day for the next seven days, and have at least a couple of campgrounds with real potable water and toilets. It’d be even better if there’s some kind of event happening—like a ranger talk or guided walk—sometime in the upcoming week. Can you help me narrow it down to the top three spots and show me the proof—how many alerts they each have, their daily service coverage, how many campgrounds meet the water-and-toilet requirement, and what events they’ve got lined up? I need actual numbers and details so I can book with confidence.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’m planning a week of backpacking in California and trying to pick the three best national parks that won’t let me down. Ideally they’d offer solid hiking and camping, have almost no current closures or safety alerts, keep their visitor centers or services open every day for the next seven days, and have at least a couple of campgrounds with real potable water and toilets. It’d be even better if there’s some kind of event happening—like a ranger talk or guided walk—sometime in the upcoming week. Can you help me narrow it down to the top three spots and show me the proof—how many alerts they each have, their daily service coverage, how many campgrounds meet the water-and-toilet requirement, and what events they’ve got lined up? I need actual numbers and details so I can book with confidence.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "National Parks",
      "query_id": "national_parks_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Call for Papers",
        "DEX Paprika",
        "Google Maps",
        "Huge Icons",
        "Metropolitan Museum",
        "NixOS",
        "OpenAPI Explorer",
        "Paper Search",
        "Unit Converter",
        "Weather Data"
      ]
    },
    {
      "query": "I’m putting together a research talk on medieval swords and I want to pick out five examples from two different corners of the Met—the Arms and Armor collection and the Medieval Art galleries. Ideally each sword would have a nice photo for my slides, but if one section only has a few with images, it’s okay to include some without so I still end up with five. For each piece, could you pull together its name, the date or era it comes from, the artist or cultural origin, and a link to its image (if there is one)? I really need concrete details and real links so I can plug them straight into my presentation without any guesses.",
      "fuzzy_query": "I’m putting together a research talk on medieval swords and I want to pick out five examples from two different corners of the Met—the Arms and Armor collection and the Medieval Art galleries. Ideally each sword would have a nice photo for my slides, but if one section only has a few with images, it’s okay to include some without so I still end up with five. For each piece, could you pull together its name, the date or era it comes from, the artist or cultural origin, and a link to its image (if there is one)? I really need concrete details and real links so I can plug them straight into my presentation without any guesses.",
      "ground_truth_tool": "Metropolitan Museum",
      "query_id": "metropolitan_museum_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Car Price Evaluator",
        "DEX Paprika",
        "Google Maps",
        "Hugging Face",
        "Medical Calculator",
        "Movie Recommender",
        "OSINT Intelligence",
        "OpenAPI Explorer",
        "Unit Converter",
        "Wikipedia"
      ]
    },
    {
      "query": "I’ve gotten myself into a bit of an art-history deep dive: my prof wants a quick reference on the absolute earliest landscape paintings in the Met’s European collection—like, the ones that kicked off the whole genre over there. But I’m kind of lost on where to even start in their database. I think there’s a “European Paintings” section, and I only really want works tagged as “landscape,” ideally with actual images so I can drop them into my slides. Could you help me figure out which five pieces have the oldest documented dates, and then pull together each painting’s title, artist, date, medium, and a link to its main image? I really need solid, real-data details and URLs—nothing hand-wavy—so I can back up my little presentation. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’ve gotten myself into a bit of an art-history deep dive: my prof wants a quick reference on the absolute earliest landscape paintings in the Met’s European collection—like, the ones that kicked off the whole genre over there. But I’m kind of lost on where to even start in their database. I think there’s a “European Paintings” section, and I only really want works tagged as “landscape,” ideally with actual images so I can drop them into my slides. Could you help me figure out which five pieces have the oldest documented dates, and then pull together each painting’s title, artist, date, medium, and a link to its main image? I really need solid, real-data details and URLs—nothing hand-wavy—so I can back up my little presentation. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Metropolitan Museum",
      "query_id": "metropolitan_museum_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Call for Papers",
        "FruityVice",
        "Hugging Face",
        "Medical Calculator",
        "Movie Recommender",
        "NASA Data",
        "OKX Exchange",
        "OSINT Intelligence",
        "Wikipedia"
      ]
    },
    {
      "query": "Hey, I’m putting together a two-day movie marathon for my film club and I want three very different vibes: space exploration, post-apocalyptic survival, and that quirky steampunk flair. I’m thinking about ten go-to films for each vibe, but I also want to see if any titles show up in more than one category—that way those overlapping movies become the marquee picks. If nothing overlaps, I’ll just pick the top couple from each list. Then, for each of those headliners, I’d love around five more “movies like” them to really flesh out the lineup. Finally, I need a big master list of all those extra suggestions, sorted so the films that pop up most often float to the top. Can you pull together the original vibe lists, highlight the core picks, share all the expansion titles, and wrap up with that final ranked recommendation list? I really need actual movie names and how frequently they appear—no vague gut feelings—because I have to show this to the group.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’m putting together a two-day movie marathon for my film club and I want three very different vibes: space exploration, post-apocalyptic survival, and that quirky steampunk flair. I’m thinking about ten go-to films for each vibe, but I also want to see if any titles show up in more than one category—that way those overlapping movies become the marquee picks. If nothing overlaps, I’ll just pick the top couple from each list. Then, for each of those headliners, I’d love around five more “movies like” them to really flesh out the lineup. Finally, I need a big master list of all those extra suggestions, sorted so the films that pop up most often float to the top. Can you pull together the original vibe lists, highlight the core picks, share all the expansion titles, and wrap up with that final ranked recommendation list? I really need actual movie names and how frequently they appear—no vague gut feelings—because I have to show this to the group.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Movie Recommender",
      "query_id": "movie_recommender_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "DEX Paprika",
        "FruityVice",
        "Game Trends",
        "Huge Icons",
        "Hugging Face",
        "Medical Calculator",
        "NASA Data",
        "NixOS",
        "OSINT Intelligence",
        "Paper Search"
      ]
    },
    {
      "query": "Hey, I’m putting together a week-long sci-fi film showcase at my local theater next week and need to nail down a slate of five movies. Ideally, they’d all be solid science-fiction picks that really lean into space exploration—starship voyages, alien worlds, that kind of epic adventure. I’m not sure there are five titles that hit both “pure sci-fi” and “deep space” perfectly, so if we can’t find enough classics crossing both, I’d top up the list with the best new sci-fi releases opening in the next seven days. Could you help me choose those five, highlight which ones come from that overlap of space-heavy sci-fi and which are the fresh upcoming flicks, and give me a quick note on why each made the cut? I really need actual titles with solid reasons so I can pitch it to our crowd.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’m putting together a week-long sci-fi film showcase at my local theater next week and need to nail down a slate of five movies. Ideally, they’d all be solid science-fiction picks that really lean into space exploration—starship voyages, alien worlds, that kind of epic adventure. I’m not sure there are five titles that hit both “pure sci-fi” and “deep space” perfectly, so if we can’t find enough classics crossing both, I’d top up the list with the best new sci-fi releases opening in the next seven days. Could you help me choose those five, highlight which ones come from that overlap of space-heavy sci-fi and which are the fresh upcoming flicks, and give me a quick note on why each made the cut? I really need actual titles with solid reasons so I can pitch it to our crowd.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Movie Recommender",
      "query_id": "movie_recommender_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "BioMCP",
        "Call for Papers",
        "Car Price Evaluator",
        "DEX Paprika",
        "FruityVice",
        "NixOS",
        "OSINT Intelligence",
        "Reddit",
        "Weather Data",
        "Wikipedia"
      ]
    },
    {
      "query": "I’m putting together a high-level solar system briefing for some senior folks, and juggling all the pieces is giving me a headache. I need to know if any near-Earth asteroids are swinging by in the next week—especially the ones that might be flagged as potentially hazardous. At the same time, I’d love a snapshot of the Sun’s recent activity: flares, coronal mass ejections, particle storms, geomagnetic disturbances—everything from the past seven days. And if there’s been at least an M-class flare, could you grab that week-ahead solar wind forecast we usually lean on? I also want to double-check that no critical alerts slipped through, so please cross-check any space weather notifications from the past week.\n\nOn the imagery side, I could really use a fresh satellite shot of New York City (around 40.7128, –74.0060) plus the latest batch of EPIC Earth photos from deep space. Oh, and don’t forget today’s astronomy picture of the day—title, media type, and URL.\n\nFor the exoplanet section, show me the top 5 confirmed worlds that take more than about 300 days to orbit but are under twice Earth’s size. A small JSON snippet for that would be perfect so I can paste it straight into our system.\n\nFinally, I need the latest from Curiosity on Mars: what’s the most recent Martian sol and its Earth date, plus any new Mastcam shots from that sol?\n\nCould you bundle all of this into one neat report I can drop into our dashboard? I really need actual numbers and solid sources—no hand-waving, please.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’m putting together a high-level solar system briefing for some senior folks, and juggling all the pieces is giving me a headache. I need to know if any near-Earth asteroids are swinging by in the next week—especially the ones that might be flagged as potentially hazardous. At the same time, I’d love a snapshot of the Sun’s recent activity: flares, coronal mass ejections, particle storms, geomagnetic disturbances—everything from the past seven days. And if there’s been at least an M-class flare, could you grab that week-ahead solar wind forecast we usually lean on? I also want to double-check that no critical alerts slipped through, so please cross-check any space weather notifications from the past week.\n\nOn the imagery side, I could really use a fresh satellite shot of New York City (around 40.7128, –74.0060) plus the latest batch of EPIC Earth photos from deep space. Oh, and don’t forget today’s astronomy picture of the day—title, media type, and URL.\n\nFor the exoplanet section, show me the top 5 confirmed worlds that take more than about 300 days to orbit but are under twice Earth’s size. A small JSON snippet for that would be perfect so I can paste it straight into our system.\n\nFinally, I need the latest from Curiosity on Mars: what’s the most recent Martian sol and its Earth date, plus any new Mastcam shots from that sol?\n\nCould you bundle all of this into one neat report I can drop into our dashboard? I really need actual numbers and solid sources—no hand-waving, please.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "NASA Data",
      "query_id": "nasa_data_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Car Price Evaluator",
        "Game Trends",
        "Math MCP",
        "Medical Calculator",
        "National Parks",
        "NixOS",
        "OpenAPI Explorer",
        "Paper Search",
        "Reddit"
      ]
    },
    {
      "query": "Hey, I’ve got a bit of a space‐heavy request that’s been bugging me—my boss wants a one‐stop update covering a bunch of NASA goodies for the coming week, and I’m totally drowning in where to start. \n\nFirst off, can you see if any asteroids swing by Earth over the next seven days and then flag the three biggest ones? I’m talking diameter, so once you’ve got those, I’d love their JPL stats—like how bright they seem, how fast they’re moving, and just how close they actually get. \n\nWhile you’re at it, I also need a breakdown of everything going on with space weather during that same period. You know, all the flare alerts, geomagnetic storms, CMEs, radiation belt changes—any of those daily notifications—and a quick sense of how the solar wind might behave over the next week (if there’s a way to simulate it roughly, that’d be fantastic). \n\nOn top of that, I’m digging into urban growth around San Francisco. Could you grab the very latest satellite picture of the Bay Area and then zoom right in on 37.7749, –122.4194 with about a 0.1°×0.1° patch, checking the cloud cover too? \n\nAlso, Curiosity’s been snapping away—would you pull its mastcam shots from one sol before its most recent day and some navcam pics from that final sol? \n\nAnd just for fun (and science), I want to see which confirmed exoplanets out there take more than roughly 1,000 days to orbit but are under twice Earth’s radius—and from that group, which one has the looooongest year. \n\nOh, and before I forget: today’s Astronomy Picture of the Day (with a thumbnail if it’s a video) needs to be in there as well. \n\nI really can’t bring a bunch of vague opinions to my boss—everything should come with real numbers, dates, image links or data sources so I can back it all up. Thanks a ton!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’ve got a bit of a space‐heavy request that’s been bugging me—my boss wants a one‐stop update covering a bunch of NASA goodies for the coming week, and I’m totally drowning in where to start. \n\nFirst off, can you see if any asteroids swing by Earth over the next seven days and then flag the three biggest ones? I’m talking diameter, so once you’ve got those, I’d love their JPL stats—like how bright they seem, how fast they’re moving, and just how close they actually get. \n\nWhile you’re at it, I also need a breakdown of everything going on with space weather during that same period. You know, all the flare alerts, geomagnetic storms, CMEs, radiation belt changes—any of those daily notifications—and a quick sense of how the solar wind might behave over the next week (if there’s a way to simulate it roughly, that’d be fantastic). \n\nOn top of that, I’m digging into urban growth around San Francisco. Could you grab the very latest satellite picture of the Bay Area and then zoom right in on 37.7749, –122.4194 with about a 0.1°×0.1° patch, checking the cloud cover too? \n\nAlso, Curiosity’s been snapping away—would you pull its mastcam shots from one sol before its most recent day and some navcam pics from that final sol? \n\nAnd just for fun (and science), I want to see which confirmed exoplanets out there take more than roughly 1,000 days to orbit but are under twice Earth’s radius—and from that group, which one has the looooongest year. \n\nOh, and before I forget: today’s Astronomy Picture of the Day (with a thumbnail if it’s a video) needs to be in there as well. \n\nI really can’t bring a bunch of vague opinions to my boss—everything should come with real numbers, dates, image links or data sources so I can back it all up. Thanks a ton!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "NASA Data",
      "query_id": "nasa_data_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "BioMCP",
        "Call for Papers",
        "Context7",
        "Game Trends",
        "Google Maps",
        "Huge Icons",
        "Metropolitan Museum",
        "Movie Recommender",
        "OKX Exchange",
        "Scientific Computing"
      ]
    },
    {
      "query": "So, here’s the deal: I’m putting together a quick “breakout radar” for BTC-USDT, ETH-USDT, and ADA-USDT, and I really need hard numbers to back any call. What I’m wondering is:\n\n– What’s the current price vs. its average over roughly the past day?  \n– How far off is that in percentage terms?  \n– In the last 15 minutes, does it look like the coin’s on an upswing or heading down?  \n– And over the last 5 minutes, has volume shot up or tanked compared to its recent average?  \n– Finally—based on all that—are any of these really cracking out into a breakout right now?\n\nCould you pull the live data, run those calculations, and give me a concise summary (JSON, table, whatever) for each pair? I can’t walk into my team meeting with gut feels—I need real, data-driven answers. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "So, here’s the deal: I’m putting together a quick “breakout radar” for BTC-USDT, ETH-USDT, and ADA-USDT, and I really need hard numbers to back any call. What I’m wondering is:\n\n– What’s the current price vs. its average over roughly the past day?  \n– How far off is that in percentage terms?  \n– In the last 15 minutes, does it look like the coin’s on an upswing or heading down?  \n– And over the last 5 minutes, has volume shot up or tanked compared to its recent average?  \n– Finally—based on all that—are any of these really cracking out into a breakout right now?\n\nCould you pull the live data, run those calculations, and give me a concise summary (JSON, table, whatever) for each pair? I can’t walk into my team meeting with gut feels—I need real, data-driven answers. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "OKX Exchange",
      "query_id": "okx_exchange_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Car Price Evaluator",
        "Context7",
        "Hugging Face",
        "Medical Calculator",
        "Metropolitan Museum",
        "National Parks",
        "OSINT Intelligence",
        "Scientific Computing",
        "Weather Data",
        "Wikipedia"
      ]
    },
    {
      "query": "I’ve been tinkering with a quick crypto check for BTC and ETH – basically looking at the last half-hour of one-minute candles to see who’s been really moving. If either coin has jumped more than about 1% over those 30 minutes, I want to know its latest price and whether it’s still pushing in the same direction. Then, whichever one shows the bigger burst, could you peek at roughly the past hour of five-minute bars and give me a sense of how choppy its closes have been (like the % volatility)? And if that volatility turns out to be north of about 0.5%, I’d love a deeper look into the last 60 one-minute bars to see exactly what’s going on. In the end, I need a clear breakdown for each coin: the one-minute momentum %, the current price (if it qualified), a yes/no on whether it’s still trending, the five-minute volatility % for the stronger coin, and a flag saying if you did that extra minute-by-minute deep dive. I really need real numbers here – can’t just wing it in my presentation. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’ve been tinkering with a quick crypto check for BTC and ETH – basically looking at the last half-hour of one-minute candles to see who’s been really moving. If either coin has jumped more than about 1% over those 30 minutes, I want to know its latest price and whether it’s still pushing in the same direction. Then, whichever one shows the bigger burst, could you peek at roughly the past hour of five-minute bars and give me a sense of how choppy its closes have been (like the % volatility)? And if that volatility turns out to be north of about 0.5%, I’d love a deeper look into the last 60 one-minute bars to see exactly what’s going on. In the end, I need a clear breakdown for each coin: the one-minute momentum %, the current price (if it qualified), a yes/no on whether it’s still trending, the five-minute volatility % for the stronger coin, and a flag saying if you did that extra minute-by-minute deep dive. I really need real numbers here – can’t just wing it in my presentation. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "OKX Exchange",
      "query_id": "okx_exchange_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Call for Papers",
        "DEX Paprika",
        "FruityVice",
        "Google Maps",
        "Medical Calculator",
        "NASA Data",
        "Paper Search",
        "Unit Converter",
        "Weather Data",
        "Wikipedia"
      ]
    },
    {
      "query": "I’m wrapping up a project on how deep learning is being used in genomics and proteomics, and my manager has asked for a snapshot of what’s really new in the last three months. I’ve seen buzz about CNNs, RNNs, Transformers and such, but I’m not sure which models are actually gaining traction across different studies, or which datasets they’ve been tested on (like specific genome sequencing collections versus mass-spec proteomics sets). Could you dive into the recent preprints and journal articles, pick out roughly eight of the newest papers, and for each one tell me:\n\n- What type of algorithm they used (CNN, RNN, Transformer, etc.)\n- Which genomic or proteomic dataset they evaluated on\n- Their headline performance number (accuracy, AUC, whatever they highlight)\n- A one-sentence summary of the main takeaway\n\nAlso, if any algorithm only shows up in a single paper (i.e. a one-off), flag it so I know it might be a fringe idea. I really need concrete details and real numbers—no vague impressions—because I’m presenting this to my team and need solid evidence from the actual studies.",
      "fuzzy_query": "I’m wrapping up a project on how deep learning is being used in genomics and proteomics, and my manager has asked for a snapshot of what’s really new in the last three months. I’ve seen buzz about CNNs, RNNs, Transformers and such, but I’m not sure which models are actually gaining traction across different studies, or which datasets they’ve been tested on (like specific genome sequencing collections versus mass-spec proteomics sets). Could you dive into the recent preprints and journal articles, pick out roughly eight of the newest papers, and for each one tell me:\n\n- What type of algorithm they used (CNN, RNN, Transformer, etc.)\n- Which genomic or proteomic dataset they evaluated on\n- Their headline performance number (accuracy, AUC, whatever they highlight)\n- A one-sentence summary of the main takeaway\n\nAlso, if any algorithm only shows up in a single paper (i.e. a one-off), flag it so I know it might be a fringe idea. I really need concrete details and real numbers—no vague impressions—because I’m presenting this to my team and need solid evidence from the actual studies.",
      "ground_truth_tool": "Paper Search",
      "query_id": "paper_search_002",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Call for Papers",
        "DEX Paprika",
        "FruityVice",
        "Medical Calculator",
        "NASA Data",
        "OKX Exchange",
        "OpenAPI Explorer",
        "Unit Converter",
        "Weather Data"
      ]
    },
    {
      "query": "Hey, I’m trying to put together a quick overview of what’s been happening with machine learning applied to protein folding over the past three months. My boss wants to know which approach is getting the most buzz – I’m betting AlphaFold still has the lead, but if papers aren’t talking about it, feel free to switch focus to RoseTTAFold. Could you pull together a set of recent studies from all the usual sources, tally how many times each one mentions the target method, note where you found each paper, and give me a one-sentence summary? For anything you can’t grab the full text on, just use the abstract. Then sort everything by the mention count so I can see at a glance who’s really driving the field. I really need actual counts and solid sources—no guesswork—so I can show the team the real numbers.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’m trying to put together a quick overview of what’s been happening with machine learning applied to protein folding over the past three months. My boss wants to know which approach is getting the most buzz – I’m betting AlphaFold still has the lead, but if papers aren’t talking about it, feel free to switch focus to RoseTTAFold. Could you pull together a set of recent studies from all the usual sources, tally how many times each one mentions the target method, note where you found each paper, and give me a one-sentence summary? For anything you can’t grab the full text on, just use the abstract. Then sort everything by the mention count so I can see at a glance who’s really driving the field. I really need actual counts and solid sources—no guesswork—so I can show the team the real numbers.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Paper Search",
      "query_id": "paper_search_004",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "BioMCP",
        "Call for Papers",
        "Car Price Evaluator",
        "Game Trends",
        "Medical Calculator",
        "Movie Recommender",
        "NASA Data",
        "OSINT Intelligence",
        "Reddit",
        "Unit Converter"
      ]
    },
    {
      "query": "Hey, I’m wrestling with a pretty hefty bit of linear algebra and vector calculus for my project and could really use a hand. I’ve got two 3×3 matrices—one with rows [4, 2, 1], [2, 3, 0], [1, 0, 2] and the other [1, 0, 2], [0, 1, 1], [2, 1, 3]—and also two vectors [1, 2, 3] and [3, 2, 1]. On top of that there’s a scalar potential φ(x,y,z)=x²·y + y²·z + z²·x and a vector field F(x,y,z)=[x·y, y·z, z·x].  \n\nI need to see what happens when I add and subtract those matrices, multiply them, scale the product by 0.5 and then check its determinant. If the absolute value ends up over 0.1, I want the inverse; if not, we’ll have to dive into an SVD breakdown. After that I’d like to pull out eigenvalues and eigenvectors, get a QR decomposition, find an orthonormal basis for the scaled matrix’s column space, and then re-express the sum of the originals in that new basis—plus figure out the rank.  \n\nMeanwhile, for the vectors [1, 2, 3] and [3, 2, 1], I’d appreciate their dot product, cross product, and the projection of one onto the other. Then there’s the symbolic side: the gradient of φ, its directional derivative along [1, 1, 1], the curl of F at [1, 1, 1], the divergence of F at [0, 0, 0], and the scalar Laplacian of φ.  \n\nIf it’s not too much, could you also sketch a 3D plot of F over the cube x,y,z∈[–1, 1] and a 2D plot of f(x,y)=sin(√(x²+y²)) over x,y∈[–5, 5]? And once all that’s done, let’s wipe out every intermediate tensor or matrix so nothing’s left hanging.  \n\nI really need the exact numbers—my advisor wants concrete results, not just vague descriptions. Appreciate any help you can give!",
      "fuzzy_query": "Hey, I’m wrestling with a pretty hefty bit of linear algebra and vector calculus for my project and could really use a hand. I’ve got two 3×3 matrices—one with rows [4, 2, 1], [2, 3, 0], [1, 0, 2] and the other [1, 0, 2], [0, 1, 1], [2, 1, 3]—and also two vectors [1, 2, 3] and [3, 2, 1]. On top of that there’s a scalar potential φ(x,y,z)=x²·y + y²·z + z²·x and a vector field F(x,y,z)=[x·y, y·z, z·x].  \n\nI need to see what happens when I add and subtract those matrices, multiply them, scale the product by 0.5 and then check its determinant. If the absolute value ends up over 0.1, I want the inverse; if not, we’ll have to dive into an SVD breakdown. After that I’d like to pull out eigenvalues and eigenvectors, get a QR decomposition, find an orthonormal basis for the scaled matrix’s column space, and then re-express the sum of the originals in that new basis—plus figure out the rank.  \n\nMeanwhile, for the vectors [1, 2, 3] and [3, 2, 1], I’d appreciate their dot product, cross product, and the projection of one onto the other. Then there’s the symbolic side: the gradient of φ, its directional derivative along [1, 1, 1], the curl of F at [1, 1, 1], the divergence of F at [0, 0, 0], and the scalar Laplacian of φ.  \n\nIf it’s not too much, could you also sketch a 3D plot of F over the cube x,y,z∈[–1, 1] and a 2D plot of f(x,y)=sin(√(x²+y²)) over x,y∈[–5, 5]? And once all that’s done, let’s wipe out every intermediate tensor or matrix so nothing’s left hanging.  \n\nI really need the exact numbers—my advisor wants concrete results, not just vague descriptions. Appreciate any help you can give!",
      "ground_truth_tool": "Scientific Computing",
      "query_id": "scientific_computing_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Call for Papers",
        "Car Price Evaluator",
        "DEX Paprika",
        "FruityVice",
        "Hugging Face",
        "Movie Recommender",
        "NASA Data",
        "OKX Exchange",
        "Unit Converter",
        "Wikipedia"
      ]
    },
    {
      "query": "Hey, I’m working on this 3D Gaussian model for my thesis and it’s been driving me nuts. I’ve defined a covariance matrix that looks like\n\n[2.0, 0.3, 0.5  \n 0.3, 1.5, 0.4  \n 0.5, 0.4, 1.0]\n\nand my sample vector is [1.2, –0.8, 0.5]. I need to know if that matrix is actually invertible (what’s its determinant? if it comes out zero, I might shrink it by a factor of 0.01 so I can invert it), then get the inverse so I can plug it into my Mahalanobis stuff. On top of that, I’d love to see its eigenvalues and eigenvectors—and even run an SVD or QR to get a feel for its geometry—grab an orthonormal basis for its column space, and re-express the matrix there. When I project my vector onto the first eigenvector, what number do I get? \n\nAs a side project, I’m also exploring the function f(x,y,z)=exp(–0.5*(x²+y²+z²)). Could you tell me its directional derivative at [1.2, –0.8, 0.5] along that leading eigenvector? It’d be great to have the full symbolic gradient of f, plus the divergence and curl of that gradient field. And because I learn best by seeing things, I need a 3D quiver plot of the gradient over x,y,z from –2 to 2 (about 15 points per axis) and a simple 2D curve of exp(–0.5 x²) from x=–3 to 3 with y going from –0.1 to 1.1 (200 samples). \n\nMy advisor wants everything—determinant, inverse matrix, eigenvalues/vectors, singular values, Q and R from QR, your orthonormal basis, the changed-basis form, the projection value, the directional derivative, the gradient expression, divergence, curl—and the two plots all wrapped up in a JSON report. I really need hard numbers and visuals to back it all up, not just a high-level summary. Can you help me pull all that together?\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’m working on this 3D Gaussian model for my thesis and it’s been driving me nuts. I’ve defined a covariance matrix that looks like\n\n[2.0, 0.3, 0.5  \n 0.3, 1.5, 0.4  \n 0.5, 0.4, 1.0]\n\nand my sample vector is [1.2, –0.8, 0.5]. I need to know if that matrix is actually invertible (what’s its determinant? if it comes out zero, I might shrink it by a factor of 0.01 so I can invert it), then get the inverse so I can plug it into my Mahalanobis stuff. On top of that, I’d love to see its eigenvalues and eigenvectors—and even run an SVD or QR to get a feel for its geometry—grab an orthonormal basis for its column space, and re-express the matrix there. When I project my vector onto the first eigenvector, what number do I get? \n\nAs a side project, I’m also exploring the function f(x,y,z)=exp(–0.5*(x²+y²+z²)). Could you tell me its directional derivative at [1.2, –0.8, 0.5] along that leading eigenvector? It’d be great to have the full symbolic gradient of f, plus the divergence and curl of that gradient field. And because I learn best by seeing things, I need a 3D quiver plot of the gradient over x,y,z from –2 to 2 (about 15 points per axis) and a simple 2D curve of exp(–0.5 x²) from x=–3 to 3 with y going from –0.1 to 1.1 (200 samples). \n\nMy advisor wants everything—determinant, inverse matrix, eigenvalues/vectors, singular values, Q and R from QR, your orthonormal basis, the changed-basis form, the projection value, the directional derivative, the gradient expression, divergence, curl—and the two plots all wrapped up in a JSON report. I really need hard numbers and visuals to back it all up, not just a high-level summary. Can you help me pull all that together?\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Scientific Computing",
      "query_id": "scientific_computing_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Car Price Evaluator",
        "DEX Paprika",
        "Hugging Face",
        "Movie Recommender",
        "NASA Data",
        "NixOS",
        "OpenAPI Explorer",
        "Reddit",
        "Weather Data"
      ]
    },
    {
      "query": "I’m organizing a big outdoor festival and I’ve hit a bit of a snag: every time I check “Springfield” I get a dozen or more possibilities around the world, and the quick temperature readings I see online don’t always match the more detailed reports—sometimes by over two degrees, which makes me uneasy. \n\nWhat I’d really love is your help figuring out which Springfield and which day in the next week would give me the best shot at a warm, mostly dry day—ideally with the chance of rain at or under about 30%. If none of them can stay under that threshold, then just find me the day with the lowest chance of showers, no matter how it ranks on warmth. \n\nAlso, if you notice any of those Springfields where the “fast” temp and the official temp are more than 2 °C apart, just flag them for me so I know which cities to cross off. \n\nIn the end, I need a clear answer: which city, what date, and what the high/low temps, chance of rain and humidity look like that day. Plus a short note on any locations you tossed out because of weird temp mismatches. I’ve got to show my team real numbers, not just guesses, so please back everything up with solid data. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’m organizing a big outdoor festival and I’ve hit a bit of a snag: every time I check “Springfield” I get a dozen or more possibilities around the world, and the quick temperature readings I see online don’t always match the more detailed reports—sometimes by over two degrees, which makes me uneasy. \n\nWhat I’d really love is your help figuring out which Springfield and which day in the next week would give me the best shot at a warm, mostly dry day—ideally with the chance of rain at or under about 30%. If none of them can stay under that threshold, then just find me the day with the lowest chance of showers, no matter how it ranks on warmth. \n\nAlso, if you notice any of those Springfields where the “fast” temp and the official temp are more than 2 °C apart, just flag them for me so I know which cities to cross off. \n\nIn the end, I need a clear answer: which city, what date, and what the high/low temps, chance of rain and humidity look like that day. Plus a short note on any locations you tossed out because of weird temp mismatches. I’ve got to show my team real numbers, not just guesses, so please back everything up with solid data. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Weather Data",
      "query_id": "weather_data_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "BioMCP",
        "Call for Papers",
        "FruityVice",
        "Hugging Face",
        "Math MCP",
        "Medical Calculator",
        "Movie Recommender",
        "National Parks",
        "NixOS",
        "OSINT Intelligence"
      ]
    },
    {
      "query": "I’m putting together an outdoor promo in Springfield next week and, to be honest, I’m not even sure which Springfield is the right one—there are so many! I’d like to zero in on the biggest city (somewhere over 100 K folks) and get a clear picture of what’s happening weather-wise right now. Also, if you could grab a quick temperature check and flag it if it’s off by more than a couple of degrees, that’d be great. Then, can you scan the forecast for the next three days and, if more than one day looks too rainy, stretch it out to the full seven-day outlook? What I really need is up to three days that sit around 20–25 °C with less than a 30 percent chance of rain. I need solid numbers and a detailed rundown so I can sell this plan to my boss—with real data, not just vibes.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’m putting together an outdoor promo in Springfield next week and, to be honest, I’m not even sure which Springfield is the right one—there are so many! I’d like to zero in on the biggest city (somewhere over 100 K folks) and get a clear picture of what’s happening weather-wise right now. Also, if you could grab a quick temperature check and flag it if it’s off by more than a couple of degrees, that’d be great. Then, can you scan the forecast for the next three days and, if more than one day looks too rainy, stretch it out to the full seven-day outlook? What I really need is up to three days that sit around 20–25 °C with less than a 30 percent chance of rain. I need solid numbers and a detailed rundown so I can sell this plan to my boss—with real data, not just vibes.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Weather Data",
      "query_id": "weather_data_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Bibliomantic",
        "Context7",
        "FruityVice",
        "Google Maps",
        "Huge Icons",
        "Math MCP",
        "NASA Data",
        "NixOS",
        "Reddit",
        "Scientific Computing"
      ]
    },
    {
      "query": "Hey, I’m trying to schedule a one-hour global strategy call next week with our teams in New York, London and Tokyo. The only windows I’ve got are 09:00 UTC, 15:00 UTC or 20:00 UTC, and I’d love to pick the slot that keeps as many people as possible within their 9 am–5 pm workday. Could you work out what those UTC times look like locally in New York (America/New_York), London (Europe/London) and Tokyo (Asia/Tokyo), count how many offices fall into normal business hours for each option, and then recommend the best slot (going with the earlier one if there’s a tie)? It’d be awesome if you could drop all the details—local times, office counts and the final pick—in a simple JSON snippet, since I really need hard numbers to show my boss, not just guesses.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’m trying to schedule a one-hour global strategy call next week with our teams in New York, London and Tokyo. The only windows I’ve got are 09:00 UTC, 15:00 UTC or 20:00 UTC, and I’d love to pick the slot that keeps as many people as possible within their 9 am–5 pm workday. Could you work out what those UTC times look like locally in New York (America/New_York), London (Europe/London) and Tokyo (Asia/Tokyo), count how many offices fall into normal business hours for each option, and then recommend the best slot (going with the earlier one if there’s a tie)? It’d be awesome if you could drop all the details—local times, office counts and the final pick—in a simple JSON snippet, since I really need hard numbers to show my boss, not just guesses.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Time MCP",
      "query_id": "time_mcp_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Car Price Evaluator",
        "DEX Paprika",
        "FruityVice",
        "Game Trends",
        "Hugging Face",
        "Medical Calculator",
        "Metropolitan Museum",
        "OKX Exchange",
        "OSINT Intelligence",
        "OpenAPI Explorer"
      ]
    },
    {
      "query": "I’m juggling a global team spread across Los Angeles, New York, London and Tokyo, and I need to lock down a one-hour meeting sometime during everyone’s 09:00–17:00 local workday in the upcoming week. Could you start by looking at the next full hour here in LA and then convert that slot into each office’s local time? If any of them fall outside 09:00–17:00, bump it an hour forward in LA and keep checking—rolling over to the next day at 09:00 if we hit 17:00—and keep going until we find a time that works for all four offices within the next seven days. If nothing lines up, just let me know it’s impossible. I really need the exact start and end times for each city so I can send the invites.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "I’m juggling a global team spread across Los Angeles, New York, London and Tokyo, and I need to lock down a one-hour meeting sometime during everyone’s 09:00–17:00 local workday in the upcoming week. Could you start by looking at the next full hour here in LA and then convert that slot into each office’s local time? If any of them fall outside 09:00–17:00, bump it an hour forward in LA and keep checking—rolling over to the next day at 09:00 if we hit 17:00—and keep going until we find a time that works for all four offices within the next seven days. If nothing lines up, just let me know it’s impossible. I really need the exact start and end times for each city so I can send the invites.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Time MCP",
      "query_id": "time_mcp_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Call for Papers",
        "Car Price Evaluator",
        "DEX Paprika",
        "Hugging Face",
        "Medical Calculator",
        "Movie Recommender",
        "NASA Data",
        "OSINT Intelligence",
        "OpenAPI Explorer",
        "Reddit"
      ]
    },
    {
      "query": "Hey, I’m gearing up for tomorrow’s multidisciplinary rounds and I’ve got three patients that are driving me nuts with all the numbers. First is Mr. A, a 65-year-old guy who’s about 95 kg and 170 cm (so roughly 67″). He’s diabetic, hypertensive, has CHF, prior MI and AF, and he’s headed for a high-risk suprainguinal vascular case. Labs show creatinine 1.8 mg/dL, cystatin C 1.5 mg/L, fasting insulin 20 µIU/mL, fasting glucose 150 mg/dL (but his electrolytes panel spiked his glucose to 200 mg/dL), calcium 8.0 mg/dL with albumin at 3.0 g/dL, sodium 130 mEq/L, total cholesterol 5.2 mmol/L and HDL 1.0 mmol/L. Vitals are 150/90 mmHg, HR 80, QT interval around 380 ms. He’s on oxycodone 5 mg q6h plus a 25 µg/h fentanyl patch, chronic prednisone 10 mg daily, plus standard antihypertensives and a statin. On top of that, his liver numbers—bilirubin 3.0 mg/dL, albumin 2.5 g/dL, INR 1.8—with slight ascites and grade 1 encephalopathy—have me wondering about his Child-Pugh and MELD.  \n\nThen there’s a 12-year-6-month-old girl, 50 kg, 150 cm, BP around 120/80, fasting insulin 15 µIU/mL, glucose 100 mg/dL.  \n\nAnd finally a 30-year-old pregnant woman who had her LMP on 2024-02-15 with a 30-day cycle.  \n\nI need to pull together their body metrics (BMI, BSA, ideal vs. adjusted weight), IV fluid rates, creatinine clearance vs. eGFR (and switch to the cystatin‐C equation if it’s under 60), MAP, HOMA-IR, corrected calcium and sodium, QTc, CHA₂DS₂-VASc, Wells’ PE probability, RCRI, Framingham and PREVENT 10-year risk, plus that liver scoring and her obstetric dates. Oh, and converting prednisone 10 mg to hydrocortisone and tallying his daily MME. Can you walk me through the actual calculations with those exact numbers and then tell me what you’d recommend for each? I really need hard data—no loose guesses—so I can confidently present to the team.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’m gearing up for tomorrow’s multidisciplinary rounds and I’ve got three patients that are driving me nuts with all the numbers. First is Mr. A, a 65-year-old guy who’s about 95 kg and 170 cm (so roughly 67″). He’s diabetic, hypertensive, has CHF, prior MI and AF, and he’s headed for a high-risk suprainguinal vascular case. Labs show creatinine 1.8 mg/dL, cystatin C 1.5 mg/L, fasting insulin 20 µIU/mL, fasting glucose 150 mg/dL (but his electrolytes panel spiked his glucose to 200 mg/dL), calcium 8.0 mg/dL with albumin at 3.0 g/dL, sodium 130 mEq/L, total cholesterol 5.2 mmol/L and HDL 1.0 mmol/L. Vitals are 150/90 mmHg, HR 80, QT interval around 380 ms. He’s on oxycodone 5 mg q6h plus a 25 µg/h fentanyl patch, chronic prednisone 10 mg daily, plus standard antihypertensives and a statin. On top of that, his liver numbers—bilirubin 3.0 mg/dL, albumin 2.5 g/dL, INR 1.8—with slight ascites and grade 1 encephalopathy—have me wondering about his Child-Pugh and MELD.  \n\nThen there’s a 12-year-6-month-old girl, 50 kg, 150 cm, BP around 120/80, fasting insulin 15 µIU/mL, glucose 100 mg/dL.  \n\nAnd finally a 30-year-old pregnant woman who had her LMP on 2024-02-15 with a 30-day cycle.  \n\nI need to pull together their body metrics (BMI, BSA, ideal vs. adjusted weight), IV fluid rates, creatinine clearance vs. eGFR (and switch to the cystatin‐C equation if it’s under 60), MAP, HOMA-IR, corrected calcium and sodium, QTc, CHA₂DS₂-VASc, Wells’ PE probability, RCRI, Framingham and PREVENT 10-year risk, plus that liver scoring and her obstetric dates. Oh, and converting prednisone 10 mg to hydrocortisone and tallying his daily MME. Can you walk me through the actual calculations with those exact numbers and then tell me what you’d recommend for each? I really need hard data—no loose guesses—so I can confidently present to the team.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Medical Calculator",
      "query_id": "medical_calculator_000",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "Call for Papers",
        "Context7",
        "FruityVice",
        "Huge Icons",
        "Math MCP",
        "Metropolitan Museum",
        "NASA Data",
        "NixOS",
        "OKX Exchange",
        "Wikipedia"
      ]
    },
    {
      "query": "Hey, I’m looking at a 65-year-old guy who’s booked for an elective hip replacement and I’m a bit overwhelmed by all his numbers. He’s 95 kg, 175 cm tall, type 2 diabetic on insulin, hypertensive on meds, on a statin for high lipids, has chronic kidney disease (creatinine 1.4 mg/dL, cystatin C 1.0 mg/L), peripheral arterial disease, atrial fibrillation—and he still smokes. His latest labs show sodium 130 mEq/L with glucose at 280 mg/dL, calcium 8.2 mg/dL with albumin 3.3 g/dL, blood pressure about 150/95, total cholesterol 5.0 mmol/L and HDL 1.0 mmol/L. \n\nI’m trying to pull together:\n• a sense of his BMI and body surface area  \n• which weight to use for creatinine clearance (actual vs ideal vs adjusted)  \n• whether to trust a creatinine-only eGFR or the one that adds cystatin C (and what to do if they differ)  \n• corrected sodium for his high glucose and corrected calcium for low albumin  \n• his mean arterial pressure  \n• his 10-year cardiovascular event risk given age 65, male, TC 5.0, HDL 1.0, SBP 150, diabetes, smoking, on blood pressure meds and statin  \n• his revised cardiac risk index for non-cardiac surgery  \n• his CHA₂DS₂-VASc with AF, HTN, diabetes, peripheral vascular disease and age  \n• and even an idea of his insulin resistance via HOMA-IR using fasting insulin 20 µIU/mL and fasting glucose 140 mg/dL\n\nCan you walk me through all of that with every calculation, how you decided between weights or eGFRs, and the final risk estimates? I need all the intermediate figures and the reasoning—real numbers, no guesswork—so I can feel confident about the recommendations.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "fuzzy_query": "Hey, I’m looking at a 65-year-old guy who’s booked for an elective hip replacement and I’m a bit overwhelmed by all his numbers. He’s 95 kg, 175 cm tall, type 2 diabetic on insulin, hypertensive on meds, on a statin for high lipids, has chronic kidney disease (creatinine 1.4 mg/dL, cystatin C 1.0 mg/L), peripheral arterial disease, atrial fibrillation—and he still smokes. His latest labs show sodium 130 mEq/L with glucose at 280 mg/dL, calcium 8.2 mg/dL with albumin 3.3 g/dL, blood pressure about 150/95, total cholesterol 5.0 mmol/L and HDL 1.0 mmol/L. \n\nI’m trying to pull together:\n• a sense of his BMI and body surface area  \n• which weight to use for creatinine clearance (actual vs ideal vs adjusted)  \n• whether to trust a creatinine-only eGFR or the one that adds cystatin C (and what to do if they differ)  \n• corrected sodium for his high glucose and corrected calcium for low albumin  \n• his mean arterial pressure  \n• his 10-year cardiovascular event risk given age 65, male, TC 5.0, HDL 1.0, SBP 150, diabetes, smoking, on blood pressure meds and statin  \n• his revised cardiac risk index for non-cardiac surgery  \n• his CHA₂DS₂-VASc with AF, HTN, diabetes, peripheral vascular disease and age  \n• and even an idea of his insulin resistance via HOMA-IR using fasting insulin 20 µIU/mL and fasting glucose 140 mg/dL\n\nCan you walk me through all of that with every calculation, how you decided between weights or eGFRs, and the final risk estimates? I need all the intermediate figures and the reasoning—real numbers, no guesswork—so I can feel confident about the recommendations.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "ground_truth_tool": "Medical Calculator",
      "query_id": "medical_calculator_001",
      "category": "single_server",
      "difficulty": "unknown",
      "distraction_servers": [
        "BioMCP",
        "Math MCP",
        "Metropolitan Museum",
        "National Parks",
        "OpenAPI Explorer",
        "Paper Search",
        "Reddit",
        "Scientific Computing",
        "Weather Data",
        "Wikipedia"
      ]
    }
  ],
  "retrieval_results": [
    {
      "query": "Hey, I’m working on this new dashboard that pulls search results from three different services—one for AI stuff, one for code hosting, and one for edge networking—and I’m scratching my head over how each handles pagination. Some APIs might use a page/page_size setup, others a cursor or next_cursor, and I’m not even sure if all of them support paging in their search calls or if I have to switch to their “list” routes instead. \n\nCould you dig into each service’s search endpoints and tell me:\n• whether it pages at all or not  \n• if it does, what style it uses (page numbers, cursors, etc.)  \n• the exact parameter names, types, required flags, and defaults  \n• any response fields that indicate where to pick up the next batch  \n\nAnd if a service’s search doesn’t page, check its list endpoints the same way. I really need a solid breakdown—names, defaults, response tokens—the whole picture, so I can convince my boss this setup will actually work. Need real details, not guesses. Thanks!",
      "retrieved_servers": [
        "Weather Data",
        "Paper Search",
        "NixOS",
        "Car Price Evaluator",
        "Game Trends"
      ],
      "ground_truth_server": "OpenAPI Explorer",
      "query_id": "openapi_explorer_000",
      "retrieval_time_ms": 82.02385902404785,
      "is_correct": false
    },
    {
      "query": "Hey, I’m building a little integration for my team and could really use a sanity check on two services we’re about to hook up. One of them is an AI platform where most of what I’ll do is “create” stuff (models, completions, that kind of thing), and the other is a code-hosting service where I only care about endpoints under “/repos” for cloning, PRs, labels, etc. \n\nHere’s what I’m trying to figure out: for each of those AI create-calls, how many required fields do I actually need to send? And then for the repo routes on the other side, how many mandatory inputs are there in the path, query string or request body? On top of that, each service uses its own auth methods—API keys, OAuth2 flows, maybe others—and I’d love to know which types each one offers and which types they share so I can reuse our login flow.\n\nIt’d be a huge help if you could pull those counts straight from their specs, highlight any endpoints that demand more than three required inputs (those will need extra form design on our side), list out the auth scheme types for both platforms, and then point out the overlap. Ideally I’d get back a tidy JSON-style summary I can hand off to my manager. And please, real numbers only—I can’t show up with guesswork. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "NixOS",
        "FruityVice",
        "Reddit",
        "Unknown",
        "Car Price Evaluator"
      ],
      "ground_truth_server": "OpenAPI Explorer",
      "query_id": "openapi_explorer_001",
      "retrieval_time_ms": 62.4089241027832,
      "is_correct": false
    },
    {
      "query": "Hey, I’m prepping for a Reactor X startup tomorrow and it’s stressing me out a bit. My boss handed me 14 different sensor readings, all in weird units, and I need to know if we meet the safety thresholds (which are all in SI or related metric units). Here’s what I’ve got:\n\n- Inlet temperature: 350 °F (threshold 150 °C)  \n- Inlet pressure: 50 psi (threshold 350 kPa)  \n- Reactor length: 10 ft (threshold 5 m)  \n- Catalyst weight: 500 lb (threshold 200 kg)  \n- Tank volume: 2000 imperial gal (threshold 8 m³)  \n- Data buffer: 2 GB (threshold 1500 MB)  \n- Heat-exchanger area: 1000 ft² (threshold 90 m²)  \n- Motor power: 50 hp (threshold 40 kW)  \n- Reaction time: 2 hours (threshold 6000 s)  \n- Valve angle: 0.25 turns (threshold 45 °)  \n- Conveyor speed: 2 m/s (threshold 4000 ft/min)  \n- Valve force: 500 lbf (threshold 2000 N)  \n- Fluid density: 128 lb/ft³ (threshold 2000 kg/m³)  \n- Fuel energy: 10000 Btu (threshold 12000 kJ)  \n\nCould you convert each reading into the same units as its threshold, then tell me for each one whether it passes (converted ≥ threshold) or fails? And if any come up as a fail, I’d really appreciate you doing a second check with a different conversion route—just to be absolutely sure we didn’t slip up on units. \n\nIt’d be awesome if you could bundle everything in a JSON summary that shows, for each sensor: its name, the original reading, the converted value with units, the threshold with units, pass/fail status, and the cross-validation details when you’ve done that extra check. I really need actual numbers on this—can’t go to my boss with just opinions. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Medical Calculator",
        "Scientific Computing",
        "NASA Data",
        "NixOS",
        "Weather Data"
      ],
      "ground_truth_server": "Unit Converter",
      "query_id": "unit_converter_000",
      "retrieval_time_ms": 67.99197196960449,
      "is_correct": false
    },
    {
      "query": "I’m gearing up for a 2 h 30 min high-altitude drone test flight and my boss wants every single detail in SI. Right now all my numbers are in U.S. customary units: engine inlet at 500 °F and outlet at 300 °F; propeller pitch is 15° (I’d like that in gons); cruise speed is 60 knots; altitude’s 10 000 ft; wing span 15 ft; wing area 1 200 in²; cargo-bay pressure 50 psi; takeoff thrust 3 000 lbf; on-board log storage is 2 GB with a 10 MB downlink buffer; battery capacity 5 kWh over this 2 h 30 min flight; and the fuel tank holds 200 US gal of fuel whose density is 810 g/L. \n\nCan you help me convert all of that—temperatures to kelvins, angle to gons, speed to m/s, lengths to meters, area to m², pressure to pascals, force to newtons, storage to bytes, energy to joules, compute the average power draw in kW then to horsepower, volume to m³, density to kg/m³, and time to seconds—then calculate the total starting fuel mass in kilograms and, if it ends up over 100 kg, report it in tonnes (otherwise in pounds)? In the end I need a tidy JSON where each entry has original_value, original_unit, converted_value, converted_unit, plus two computed fields—average_power and starting_fuel_mass—and a note on which fuel-mass branch you chose. I really need solid, data-driven numbers here—no hand-wavy estimates.",
      "retrieved_servers": [
        "Medical Calculator",
        "Scientific Computing",
        "Car Price Evaluator",
        "NASA Data",
        "Weather Data"
      ],
      "ground_truth_server": "Unit Converter",
      "query_id": "unit_converter_001",
      "retrieval_time_ms": 65.22822380065918,
      "is_correct": false
    },
    {
      "query": "I’m prepping for a presentation on the big global climate deals and could really use some solid data. Could you find the main half-dozen—or so—negotiation frameworks that show up most often and give me a quick intro to each, plus roughly how many internal links or references they have? Then dive into the Paris Agreement: I’d like about a 200-word summary focused on its emission-reduction targets and five standout facts. After that, I’m curious what topics usually pop up alongside the Kyoto Protocol—aim for at least five related ideas, and if you only spot a few, try to round it out. Oh, and would you cross-check those five Paris facts against your summary and flag any that don’t actually appear there? Finally, please wrap everything into a single JSON output since my professor insists on that. And whatever you pull, make sure it’s backed by real numbers or citations—I can’t go in there with just opinions.",
      "retrieved_servers": [
        "NASA Data",
        "Reddit",
        "Call for Papers",
        "Weather Data",
        "Bibliomantic"
      ],
      "ground_truth_server": "Wikipedia",
      "query_id": "wikipedia_000",
      "retrieval_time_ms": 57.04998970031738,
      "is_correct": false
    },
    {
      "query": "I’m putting together a sustainability briefing and need to really understand how solar panels stack up against wind turbines when it comes to environmental impacts—think resource use, lifecycle emissions, land use, etc. Could you:\n\n- Give me a short, punchy summary of each technology’s environmental footprint (a paragraph or two each).\n- Pull out about five of the most important facts related to their environmental impact for each, and show them side-by-side so I can see the main differences at a glance.\n\nOn top of that, I’ve got to cover the policy side—what incentive schemes or regulatory frameworks are actually driving solar and wind adoption right now? A clear, two-to-three-paragraph overview of the key support mechanisms would be great. While you’re at it, when you look at the main write-ups on solar and wind, do they actually link to that policy overview? Let me know “yes” or “no” for each.\n\nLastly, if you spot another renewable technology in those policy discussions that seems like a smart next step for us to research, tell me which one and give me two sentences on why it’s worth a closer look. \n\nI’m presenting next week, so I really need solid numbers and references—can’t go in with just vague statements. Thanks!",
      "retrieved_servers": [
        "NASA Data",
        "Bibliomantic",
        "Game Trends",
        "Paper Search",
        "Scientific Computing"
      ],
      "ground_truth_server": "Wikipedia",
      "query_id": "wikipedia_001",
      "retrieval_time_ms": 59.66305732727051,
      "is_correct": false
    },
    {
      "query": "I’m trying to plan a fun bike ride around Denver’s Central Park this Saturday morning—thinking of starting and ending at the Denver Art Museum sometime between 9 and noon. I’d love to swing by a really good café on the way—something within a few miles that’s got at least a 4-star rating and is actually open when I’m riding. But I don’t want to kill myself on hills or end up riding forever, so I’m hoping to find the spot that gives me the shortest round-trip plus the least uphill grunt. \n\nCould you help me figure out which cafés in about a 5 km radius fit the bill, rank them by total distance plus elevation gain, pick the best one, and then give me turn-by-turn bike directions (with distances, estimated times, and elevation change) for a 9 AM departure? Also, it’d be awesome to get a quick summary of all the candidates—name, address, rating, distance and elevation details—so I can see why the top pick wins. I really need actual numbers here, not just opinions, so I can be confident this ride won’t turn into a slog.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Weather Data",
        "Car Price Evaluator",
        "Game Trends",
        "NASA Data",
        "National Parks"
      ],
      "ground_truth_server": "Google Maps",
      "query_id": "google_maps_000",
      "retrieval_time_ms": 55.76968193054199,
      "is_correct": false
    },
    {
      "query": "I’m planning a bike outing in downtown San Francisco next weekend and could really use a hand. I want to start around City Hall and rent from a solid shop that’s actually open when I arrive—and ideally rated 4 stars or higher. If I can’t find at least three places like that within a couple of kilometers, I’m okay with dropping to 3.5 stars just to have enough options. Then I’d love to cruise over to a top-rated café about a kilometer away. What I’m really after is the bike-shop/coffee-shop pairing that gives me the shortest ride. \n\nCould you figure out which rental spot and café that is, and give me all the nitty-gritty? I’d need the shop’s address, hours, phone number and website, plus the café’s name, address and rating. Also please include the total biking distance and time, full turn-by-turn directions, and how hilly the route is by giving me elevations at the start, midpoint and end—and even the street address of that midpoint. I need actual numbers and real locations, not vague guesses, so I can share it with my friends and get everything booked. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Car Price Evaluator",
        "Weather Data",
        "Bibliomantic",
        "FruityVice",
        "NixOS"
      ],
      "ground_truth_server": "Google Maps",
      "query_id": "google_maps_001",
      "retrieval_time_ms": 61.57183647155762,
      "is_correct": false
    },
    {
      "query": "Hey, I’ve been tossing around this idea of launching a small sustainable agriculture venture—think urban farming or community gardens—right in downtown Seattle over the next six months. I’m really on the fence about timing and direction, so I was wondering if you could do a deep-dive I Ching reading for me. \n\nLike, what hexagram comes up first? Do any lines shift, and if they do, what’s the follow-up hexagram all about? Then, maybe run a second style of I Ching consult just to see if it echoes the first reading or highlights something totally different. I’d love to get the exact Chinese names, symbols, full commentary, and the line-by-line texts—so I’m not just getting a TL;DR, but the actual guidance in its own words.\n\nAt the end, could you weigh both readings side by side? Do they agree on the core message, or is one more cautious while the other pushes forward? And then give me a final take—should I dive in now, tweak the plan, or wait a bit? I really need those real quotes and details to share with my partner and make a solid call. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Bibliomantic",
        "Paper Search",
        "NASA Data",
        "Reddit",
        "Weather Data"
      ],
      "ground_truth_server": "Bibliomantic",
      "query_id": "bibliomantic_000",
      "retrieval_time_ms": 52.80041694641113,
      "is_correct": true
    },
    {
      "query": "I’m trying to decide whether we should roll out our flagship product in the Southeast Asian market over the next few months. Our leadership team’s split – some think it’s the perfect moment, others worry it’s too much of a gamble. I’d love to tap into some I Ching insight to guide us. Could you peek at the oracle’s load (if it’s handling fewer than about fifty readings, go ahead with a full, in-depth cast; if it’s busier, do a quick toss of the coins)? Jot down the hexagram numbers and any moving lines for each, then pull in the commentaries. If the quick and deep readings agree, that’s our final verdict; if they clash, maybe do one more light toss to break the tie. Then, if there are moving lines, flip them to see the secondary hexagram and note its message too. At the end, I need everything laid out – the raw toss results, the final hexagram and its write-up, the follow-up one if it exists, and a clear recommendation I can share with my boss. Please give me actual numbers and detailed notes so I’m not just presenting opinions.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Bibliomantic",
        "NASA Data",
        "Paper Search",
        "Game Trends",
        "Reddit"
      ],
      "ground_truth_server": "Bibliomantic",
      "query_id": "bibliomantic_001",
      "retrieval_time_ms": 60.327768325805664,
      "is_correct": true
    },
    {
      "query": "I’ve been asked to put together a 360-degree update on the BRAF V600E mutation in melanoma and honestly, I’m a bit swamped. I need to know what’s come out in the last three months—papers (including any preprints), how often this mutation actually shows up and what that might mean clinically, which late-stage vemurafenib trials are still recruiting and who’s backing them, plus any biomarker angles (like PD-L1 criteria), the current take on vemurafenib’s profile, and whether there have been serious safety alerts or even hiccups with the genomic testing kits used in these studies. Basically, I can’t show up without solid figures—allele frequencies, trial counts, sponsor names, adverse-event tallies, device problem reports—everything tied back to real sources. Can you help me pull all that together in one place?\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "NASA Data",
        "Paper Search",
        "Medical Calculator",
        "Game Trends",
        "National Parks"
      ],
      "ground_truth_server": "BioMCP",
      "query_id": "biomcp_000",
      "retrieval_time_ms": 60.46032905578613,
      "is_correct": false
    },
    {
      "query": "I’m working on a melanoma project and really stuck piecing together everything about that common BRAF V600E change. My boss wants a solid briefing on how that mutation drives the disease, what recent studies are saying, and whether treatments like vemurafenib or dabrafenib are truly holding up in patients who carry it. On top of that, I need to know what clinical trials are actually enrolling V600E-positive melanoma folks right now, how those trials are set up, what outcomes they’re reporting (and if any published papers or updates back them up), and how all that lines up with the drugs’ approved uses and safety concerns. \n\nI’m not looking for vague summaries—I need hard numbers, trial IDs, approval dates, key label warnings, safety‐signal stats, that sort of thing—all from the latest half‐year or so. Can you help me pull together a clear, evidence‐backed overview covering:\n\n• The role of BRAF V600E in melanoma  \n• Highlights from recent papers on that mutation  \n• Open Phase 2/3 studies targeting it (designs, outcomes, refs)  \n• Approval status and key label sections for vemurafenib/dabrafenib  \n• Any serious adverse event patterns reported post‐approval  \n\nI’ve got to show real data and sources—nothing off the cuff—so I can recommend the best targeted strategy. Thanks!",
      "retrieved_servers": [
        "NASA Data",
        "Medical Calculator",
        "Paper Search",
        "Game Trends",
        "NixOS"
      ],
      "ground_truth_server": "BioMCP",
      "query_id": "biomcp_001",
      "retrieval_time_ms": 72.4036693572998,
      "is_correct": false
    },
    {
      "query": "Hey, I’m knee-deep in organizing paper submissions for my team and just noticed there are dozens of Europe-based conferences on AI and on data privacy with deadlines sneaking up in the next week. I’m kind of panicking because I don’t want to miss any last-call dates—some might even close in the next 24 hours. \n\nCould you pull together a list of those upcoming European events in artificial intelligence and data privacy that still have open calls over the next seven days? It’d be awesome if you could flag which ones are truly urgent (like closing in a day) versus those with a bit more breathing room, and jot down the city, how many days we’ve got left, and whether it’s AI or privacy. \n\nI really need solid info—actual deadlines and locations—so I can get our proposals in on time. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Call for Papers",
        "Weather Data",
        "Game Trends",
        "NASA Data",
        "NixOS"
      ],
      "ground_truth_server": "Call for Papers",
      "query_id": "call_for_papers_000",
      "retrieval_time_ms": 54.40163612365723,
      "is_correct": true
    },
    {
      "query": "I’m working on my PhD in sustainable energy and my supervisor just asked me to pull together a shortlist of conferences happening over the next six months that I should really keep an eye on. Honestly, there are so many calls for papers out there under labels like “renewable energy” or “sustainable energy” that I’m getting lost. Could you find me about five upcoming conferences—complete with their names, when they start (relative to now), and where they’re held—and highlight any common themes? I’ve noticed terms like wind, solar or hydro seem to show up a lot in titles, so if one of those subtopics is particularly hot, maybe zoom in on that a bit more. I need to send something solid to my supervisor soon, so please back it up with real event details, not just guesses.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Call for Papers",
        "NASA Data",
        "Game Trends",
        "Weather Data",
        "Reddit"
      ],
      "ground_truth_server": "Call for Papers",
      "query_id": "call_for_papers_001",
      "retrieval_time_ms": 46.692609786987305,
      "is_correct": true
    },
    {
      "query": "Hey, I’m prepping for a marketing push next week and could use some solid data. We need to spotlight the pickup brands that have the most models priced north of 100 000, while also highlighting car brands whose average model price sits under about 60 000. Then, if any brand shows up in both groups, I’d like to see what motorcycles they offer and how much those bikes go for. Could you pull together who the top three truck brands are (by count of six-figure models), which car brands make the budget cut, and any overlaps—and for those overlaps list out the bike models and their prices? I really need actual counts, averages, and price tags so I can back up my plan with real numbers, not just gut feelings. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Car Price Evaluator",
        "Movie Recommender",
        "Game Trends",
        "NixOS",
        "Weather Data"
      ],
      "ground_truth_server": "Car Price Evaluator",
      "query_id": "car_price_evaluator_000",
      "retrieval_time_ms": 52.83689498901367,
      "is_correct": true
    },
    {
      "query": "Hey, I’m working on a little overview for my boss about how Brazilian car brands line up price-wise. Basically, I want to see which brands are on the cheaper end (say under R$40 000 on average), which sit in a mid-range (around R$40–80 000), and which ones are in that premium R$80 000-plus territory. For those top-tier brands, it’d be great to know if they’re big enough to also show up in bikes or trucks—and if there’s some internal brand code we can reference. At the end, I need a simple rundown with each brand’s average price, its segment (low/mid/high), and for the high-end names, their code plus a yes/no on whether they’ve diversified into motorcycles or trucks. I really need actual numbers and facts here—not just gut feelings—so I can back my recommendations with solid data. Could you help me pull this together?\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Car Price Evaluator",
        "Game Trends",
        "NixOS",
        "Medical Calculator",
        "Movie Recommender"
      ],
      "ground_truth_server": "Car Price Evaluator",
      "query_id": "car_price_evaluator_001",
      "retrieval_time_ms": 50.2314567565918,
      "is_correct": true
    },
    {
      "query": "I’m trying to choose between Next.js and Gatsby for a new project, and my manager wants a side-by-side look at their routing docs. Basically, I need to know how many real code examples each framework includes in its routing guide. If they’re almost neck-and-neck, I’d also like to see how many snippets they each have on dynamic routing. Could you dive into both official docs, count up those snippet examples for routing and dynamic routing, and let me know which one comes out ahead? I really need hard numbers—can’t just go to the boss with gut feelings.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "NixOS",
        "Game Trends",
        "Movie Recommender",
        "Bibliomantic",
        "Call for Papers"
      ],
      "ground_truth_server": "Context7",
      "query_id": "context7_000",
      "retrieval_time_ms": 42.809486389160156,
      "is_correct": false
    },
    {
      "query": "Hey, I’ve got to lock in a JavaScript front-end framework for a new single-page app by next week, and routing plus solid state management are deal-breakers. I’m really prioritizing documentation that’s packed with real code examples, not just theory. Could you check out the two most highly regarded frameworks right now, tally up how many code snippets they each have for routing and for state handling, and see which one comes out ahead? If the front-runner has roughly 50 or more total snippets in those areas, I’ll go with that. If it falls short, I’d also want to know how many “advanced patterns” examples the second tool has and then pick whichever has more. I need actual counts to back this up—no vague opinions—so I can make a strong case to the team.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "NixOS",
        "Game Trends",
        "Reddit",
        "Weather Data",
        "Call for Papers"
      ],
      "ground_truth_server": "Context7",
      "query_id": "context7_001",
      "retrieval_time_ms": 52.42204666137695,
      "is_correct": false
    },
    {
      "query": "I’m putting together a DeFi deep-dive for a client who’s curious how Ethereum stacks up against that other fast chain, Solana, in terms of big-money pools and how choppy they’ve been lately. Could you help me figure out which three pools on each network are moving the most USD volume right now, and call out any that jumped or dropped by more than about 5% in the last 24 hours? For those volatile ones, I’d love to see a daily price chart for roughly the past month and a look at the most recent ~50 swaps or liquidity moves. \n\nOn top of that, I need to know where USDC is getting the most action on each chain—so what’s the single largest USDC pair by volume, and how has its price trended day-to-day over the last month? And finally, can you give me a quick snapshot of overall DEX health across the ecosystem? I really need hard numbers and real data here—I can’t go in with just opinions. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Game Trends",
        "NASA Data",
        "Weather Data",
        "Medical Calculator",
        "Bibliomantic"
      ],
      "ground_truth_server": "DEX Paprika",
      "query_id": "dex_paprika_000",
      "retrieval_time_ms": 53.95030975341797,
      "is_correct": false
    },
    {
      "query": "I’ve got this project where my team needs a clear picture of what’s been happening on the biggest DeFi venues over the last six months—specifically Uniswap V3 on Ethereum and QuickSwap on Polygon. I’m trying to figure out which pools have been doing the heaviest trading (let’s say the top five by volume on each chain), then dig into how those pools have behaved day-to-day: price swings, rough volatility, number of trades, that kind of thing. \n\nOn top of that, I’d like to know what tokens are sitting in each of those pools, and whether those same tokens show up in any major pools on the other network. Ultimately, I want a side-by-side look at each pool’s address, token info, volume stats, daily price history (so we can calculate a volatility percentage), plus a quick snapshot of transaction counts and where else those tokens are getting traded cross-chain. \n\nSounds like a lot, I know—but I really need actual figures and solid data to back this up. Can you help me pull all that together? Whatever you find, please make sure it’s backed up by real numbers or reliable sources, okay?\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Game Trends",
        "NASA Data",
        "Weather Data",
        "Call for Papers",
        "Reddit"
      ],
      "ground_truth_server": "DEX Paprika",
      "query_id": "dex_paprika_001",
      "retrieval_time_ms": 68.0084228515625,
      "is_correct": false
    },
    {
      "query": "Hey, I’m tinkering with a new snack idea and could really use your help. I want to build a fruit salad that ends up at about 500 calories, loads of fiber but under roughly 30 g of sugar total. My rough plan is to kick things off with an apple, then—depending on whether it falls into the Rosaceae family—go with either a strawberry or switch to pineapple. Next, based on how sweet that second pick is (I’m eyeballing about 5 g sugar per 100 g as my cutoff), I’d add either an orange or a banana. \n\nCan you grab the real nutrition facts for each of those fruits, help me decide which ones to use, figure out exactly how many grams of each to hit the 500 calories, maximize fiber, and stay under 30 g of sugar? I’d need:\n\n- The calories, fiber, and sugar per 100 g for each selected fruit\n- The precise weights of each fruit in the mix\n- A final tally of total calories, fiber, and sugar\n\nI really need hard numbers backed by genuine data—no guessing—so I can show the results to my team. Thanks!",
      "retrieved_servers": [
        "FruityVice",
        "Car Price Evaluator",
        "Reddit",
        "Game Trends",
        "Medical Calculator"
      ],
      "ground_truth_server": "FruityVice",
      "query_id": "fruityvice_000",
      "retrieval_time_ms": 63.32540512084961,
      "is_correct": true
    },
    {
      "query": "Hey, I’ve got a bit of a smoothie challenge for next week and could use your brain on it. My coach wants each 300 mL drink to have exactly 200 g of fruit but stay under about 30 g of sugar and still hit at least 8 g of fiber. I’m thinking about using things like apple, banana, orange, strawberry, kiwi, mango, pineapple, blueberry—and if that doesn’t give me enough options, maybe throw in pear or grape. \n\nWhat I really need is a handful of three-fruit blends (so roughly 66–67 g of each fruit) that meet those sugar and fiber limits, and then a 7-day lineup cycling through all the valid combos. Could you break down each day’s smoothie with exactly which fruits, how many grams of each, plus the total sugar and fiber? I can’t just wing this—I need real numbers to show my coach.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "FruityVice",
        "Car Price Evaluator",
        "Movie Recommender",
        "Game Trends",
        "Reddit"
      ],
      "ground_truth_server": "FruityVice",
      "query_id": "fruityvice_001",
      "retrieval_time_ms": 59.04364585876465,
      "is_correct": true
    },
    {
      "query": "I’m working at a small indie game publisher and my boss wants me to spot any breakout titles over the next week. What I’m really after are those under-the-radar games that haven’t cracked the top five bestsellers but are still pulling in roughly 5,000 concurrent players. If any of those are buzzing on both Steam and Epic, I’d love to see their individual ranks and an averaged ranking—only if that average comes out to ten or below. For games that only pop on Steam, make sure they’re not quietly heading into any Epic free-to-play or upcoming giveaways. And for anything only trending on Epic, flag if it’s set to go free in the next seven days. Could you put together a shortlist laid out like that, with real rank numbers, player counts, and free-status notes? I really need hard data to bring back to my team, not just gut feelings.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Game Trends",
        "Movie Recommender",
        "NixOS",
        "Call for Papers",
        "NASA Data"
      ],
      "ground_truth_server": "Game Trends",
      "query_id": "game_trends_000",
      "retrieval_time_ms": 61.38110160827637,
      "is_correct": true
    },
    {
      "query": "Hey, I’m putting together a pitch for next week’s gaming campaign and I need a clear picture of what’s really popping on both Steam and Epic over the past seven days. I’m curious which titles made it into the top tier of buzz on each store, and then for the ten biggest hitters I’d like to know two things on Steam: what their peak live player counts looked like and where they sit in the sales charts right now. At the same time, I want to check on Epic whether those same games are free today or dropping free soon, and how hot they are on Epic’s trending list.\n\nI’m trying to spot the sweet spots—like games that have huge Steam crowds (say above about fifty-thousand at peak) but are free on Epic, which I’d flag as “High-Impact Free Play,” or stuff that’s selling really well on Steam (top twenty sellers) but isn’t filling its lobbies (under around ten-thousand peak) that I’d call “Sales-Driven.” Everything else would just be “Standard Trend.” \n\nCould you pull together real numbers for those ten games—Steam peak player counts, Steam sales ranks, Epic free status, Epic trending scores—and label each one with the category above? I’d really appreciate a neat, data-driven rundown (ideally something I can drop straight into a JSON-style report) because I need hard evidence to show the team, not just gut feelings.",
      "retrieved_servers": [
        "Game Trends",
        "Call for Papers",
        "Car Price Evaluator",
        "NASA Data",
        "Movie Recommender"
      ],
      "ground_truth_server": "Game Trends",
      "query_id": "game_trends_001",
      "retrieval_time_ms": 62.391042709350586,
      "is_correct": true
    },
    {
      "query": "Hey, I’m wrapping up a new UI kit for my app and there are five icons I absolutely need—home, search, user-profile, notification and settings—but I’m not sure they all show up under those exact names in the library I’m using. For example, I’ve seen “user-profile” turned into “person” or “account,” notifications sneak in as “bell” or “alert,” and settings sometimes go by “gear” or “cog.” Could you dig in and see which ones are available under the exact or fallback names, then give me the actual import or usage snippets for React, Vue, Angular, Svelte, React Native and Flutter? If any icon doesn’t exist at all or a framework can’t handle one, just flag it so I know what’s missing or only partially supported. I really need real code examples, not just guesses, so I can hand it straight to my team.",
      "retrieved_servers": [
        "NixOS",
        "Game Trends",
        "FruityVice",
        "Huge Icons",
        "NASA Data"
      ],
      "ground_truth_server": "Huge Icons",
      "query_id": "huge_icons_000",
      "retrieval_time_ms": 50.99010467529297,
      "is_correct": false
    },
    {
      "query": "I’m putting together docs for the Hugeicons set in my cross-platform component library and could really use some hard numbers and copy-and-paste code. First off, how many icons are in the entire collection? I need at least ten to make this guide worthwhile—if it’s under ten, let me know so I can rethink my approach. \n\nThen for the six core UI bits—home, search, notifications, settings, user, and logout—I’d like you to pick the very first icon that matches each name, but if it doesn’t show up try the “outline” version instead. Once you’ve chosen those, could you walk me through exactly how to import and use each one in React, Vue, Angular, Svelte, React Native, and Flutter? Finally, I need a ready-to-go React snippet for the home icon. \n\nIt would be amazing if you could bundle the whole thing—total icon count, a mapping of category to icon name (noting if you had to fall back), plus the usage instructions for each platform, and the React home example—in one JSON object I can drop straight into my docs. I really need concrete data and real code, not just general advice.",
      "retrieved_servers": [
        "NixOS",
        "Huge Icons",
        "NASA Data",
        "Car Price Evaluator",
        "FruityVice"
      ],
      "ground_truth_server": "Huge Icons",
      "query_id": "huge_icons_001",
      "retrieval_time_ms": 66.03384017944336,
      "is_correct": false
    },
    {
      "query": "Hey, I’m knee-deep in setting up a spam filter for a side project and could really use some hard data to make a solid call. I’ve been poking around for a pre-trained English classifier that’s not too huge (ideally something under roughly 700 million parameters) and is released under an Apache-2.0-style license. I first checked out a few DistilBERT-ish models, but if none fit the bill, I guess I could fall back to something BERT-based. \n\nAt the same time, I need a dataset with at least around 20 k training examples so it doesn’t feel too flimsy, and I’d love to trial a couple of live demos—preferably built with something like Gradio—just to see how they actually perform on spammy text. \n\nAlso, since keeping up with the latest is crucial, I want to skim today’s fresh papers and see if any mention spam classification; if nothing jumps out, I’m okay with looking at the first handful for any useful benchmark scores or datasets they report. Oh, and if there are any community collections focusing on spam classification, I’d like a peek at those too.\n\nCould you pull together:\n- Details on the best fitting model (name, parameter count, license)\n- Dataset info (ID, train-size)\n- Any live demo spaces you find (with actual performance metrics)\n- A few of today’s papers that talk about spam filtering, with their datasets and scores\n- And any relevant collections or curated sets around spam classification\n\nThen, based on all that evidence—numbers, links, whatever—I’d love a recommendation for which model+dataset pairing seems strongest for fine-tuning. I really need concrete figures and sources so I can walk my boss through it with confidence, not just guesses. Thanks!",
      "retrieved_servers": [
        "NASA Data",
        "Call for Papers",
        "Paper Search",
        "Reddit",
        "Game Trends"
      ],
      "ground_truth_server": "Hugging Face",
      "query_id": "hugging_face_000",
      "retrieval_time_ms": 75.8199691772461,
      "is_correct": false
    },
    {
      "query": "I’ve got this side project where I need to set up an English-to-French translation workflow, but I’m only allowed to use what’s already on Hugging Face. I’m a bit stuck figuring out which of Google’s translation models are both top quality and still on the lean side (maybe under a billion parameters?), and which of the OPUS English-to-French datasets have enough examples to actually work well (I’m thinking at least around ten thousand). \n\nIdeally I’d love to land on the three strongest model-dataset pairings, ranked by the dataset’s size—so I can show my boss some concrete options. And once those are picked, I’d also like to see if there are any live demos or Spaces where I can test them out, plus any recent papers that actually mention those exact models or datasets. Oh, and if Google or OPUS have bundled any of these into collections, point me to those too. \n\nI really need hard numbers, precise model sizes and dataset counts, direct links to demos, papers or collections—nothing vague. Can you dig up all that evidence for me?",
      "retrieved_servers": [
        "Paper Search",
        "Bibliomantic",
        "Movie Recommender",
        "Car Price Evaluator",
        "Call for Papers"
      ],
      "ground_truth_server": "Hugging Face",
      "query_id": "hugging_face_001",
      "retrieval_time_ms": 62.36457824707031,
      "is_correct": false
    },
    {
      "query": "I’m pulling together a report on last quarter’s harvest from our 10 farms, and honestly I need some hard numbers. We recorded yields of 120, 150, 150, 200, 180, 170, 160, 140, 130, and 155 tons. \n\nHere’s what I’m trying to nail down:\n- What’s our total output, average yield per farm, the median and the most common harvest size, plus our lowest and highest yields and the overall spread?\n- Then, at $30 a ton, what does that translate to in revenue?\n- After covering $2,000 in fixed costs per farm (so 10 farms total), what’s left as net profit and what’s our profit margin when you express it as a percentage (rounded to the nearest whole number)?\n- Finally, I’m curious about the gap between our top-performing farm (200 tons) and the average yield—if that difference is more than 30 tons, I want to budget extra fertilizer at $10 per ton of that gap (and round up); if it’s 30 or less, I’ll stick with a $500 allowance (and round down).\n\nCould you crunch all those figures? I really need solid data—can’t go to my boss with just guesses. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Game Trends",
        "Car Price Evaluator",
        "FruityVice",
        "Medical Calculator",
        "Math MCP"
      ],
      "ground_truth_server": "Math MCP",
      "query_id": "math_mcp_000",
      "retrieval_time_ms": 63.575029373168945,
      "is_correct": false
    },
    {
      "query": "Hey, I’ve been digging into my sales over the last six months—120, 150, 130, 170, 150 and 160 units—and I’m honestly a bit lost on how to pull it all together for my boss. Could you help me figure out where I stand overall (like total sales, average, median, and which month number appeared most often), spot the best and worst months, and even see how the top month compares to the bottom as a ratio? \n\nAlso, I heard it’s useful to look at how skewed things are by subtracting the median from the mean, and then rounding that skewness differently depending on whether it’s positive or not. On top of that, we’re aiming for an average of 180 units over the next seven months—so I need to know the total target for those seven months and exactly how many extra units I’d have to push next month to hit it (rounded to a whole number). \n\nCould you put all of that into a clean JSON summary (with fields like total_sales, average_sales, median_sales, mode_sales, max_sales, min_sales, max_to_min_ratio, skewness, adjusted_skewness, target_total_7_months, additional_needed_next_month_exact, additional_needed_next_month_rounded)? I really need real numbers for every piece so I can back it up properly—no guesses, just solid calculations.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Game Trends",
        "Car Price Evaluator",
        "Weather Data",
        "Medical Calculator",
        "NASA Data"
      ],
      "ground_truth_server": "Math MCP",
      "query_id": "math_mcp_001",
      "retrieval_time_ms": 66.87068939208984,
      "is_correct": false
    },
    {
      "query": "I’ve been wrestling with setting up Neovim in a truly rock-solid NixOS environment and could really use a clear snapshot of where things stand. Here’s the deal: I’m on the stable NixOS channel, but I’m not even sure which channels are still alive or where Neovim lives in each. I’d love to know if the specific 0.9.2 release is packaged there—if it isn’t, what are the last few Neovim versions I could grab reproducibly? On top of that, I’m dabbling with flakes and want to see how many community flakes actually offer Neovim and what the download stats look like. Then there’s Home Manager and nix-darwin—does “programs.neovim” show up in their option trees, what does its entry look like, and how deep does the support go? Basically, I need hard numbers and real metadata—channel names, package counts, version hashes or fallback lists, flake counts, option paths, anything that proves this is actually supported end to end. I can’t go forward on gut feelings alone, so whatever you find, make sure it’s backed up by concrete data.",
      "retrieved_servers": [
        "NixOS",
        "Game Trends",
        "Wikipedia",
        "Weather Data",
        "NASA Data"
      ],
      "ground_truth_server": "NixOS",
      "query_id": "nixos_000",
      "retrieval_time_ms": 64.47243690490723,
      "is_correct": true
    },
    {
      "query": "I’ve been banging my head against getting a rock-solid Python 3.10 setup that works exactly the same on NixOS (with flakes on unstable) and on my Mac via nix-darwin. What I really need is to pin down the precise Python 3.10 package from unstable—ideally lock in version 3.10.8 by its commit hash—then find out if there’s a community flake out there bundling that (or a later) release and pick the best one. On top of that, I want to wire it up in home-manager and nix-darwin so Jupyter and all my usual Python packages just land in my user environment without me juggling things by hand.\n\nCould you help me track down:\n\n• The exact NixOS package name for Python 3.10 on the unstable channel and its full package metadata?  \n• The version history so I can grab the commit hash for 3.10.8?  \n• A good community flake that already includes Python 3.10.8 or above (with name and any relevant metadata)?  \n• The right option path and example config block in home-manager to enable Python packages plus Jupyter Notebook?  \n• The parallel option group and config snippet for nix-darwin to get the same Python/Jupyter support on macOS?  \n• Finally, a complete flake.nix snippet that pins that exact commit, imports the chosen flake, and sets up both home-manager and darwin modules with those options?\n\nI really need the actual values—package names, commit hashes, option names/paths, config blocks, etc.—so I can hand this over to my team and prove it’s rock solid. Thanks!",
      "retrieved_servers": [
        "NixOS",
        "OKX Exchange",
        "National Parks",
        "Bibliomantic",
        "Metropolitan Museum"
      ],
      "ground_truth_server": "NixOS",
      "query_id": "nixos_001",
      "retrieval_time_ms": 62.218427658081055,
      "is_correct": true
    },
    {
      "query": "I’ve got a bit of a situation with the domain example-inc.com. My boss wants a full picture of any look-alike sites, subdomains and exposed services so we can see if someone’s squatting on typos or even hosting malicious stuff on the same network. I’m not even sure how many variants there might be if you fuzz it a bit, and I don’t want to miss a single suspicious spelling error or clone that ends up pointing back to our own servers. \n\nCould you help me track down all the possible typo-style domains that resemble example-inc.com, figure out which ones pose the biggest risk, and then map out what subdomains they’ve got? I also need to know every IP they resolve to, what ports are open (especially SSH or web ports), and who technically “owns” each IP and domain from a registration standpoint. And if any of those look-alikes share IP ranges with the real example-inc.com, flag that as a potential “sibling” setup. \n\nAt the end, I really need solid numbers or output—like actual DNS/DNS record details, open-port findings, and registrar versus network-owner info—so I can show my team real evidence. Does that make sense?",
      "retrieved_servers": [
        "Unknown",
        "Paper Search",
        "NixOS",
        "Bibliomantic",
        "Weather Data"
      ],
      "ground_truth_server": "OSINT Intelligence",
      "query_id": "osint_intelligence_000",
      "retrieval_time_ms": 65.83523750305176,
      "is_correct": false
    },
    {
      "query": "Hey, I’ve got this sketchy domain, fakeshoponline.com, that only popped up roughly three months ago and now keeps showing up in phishing reports. I’m trying to piece together who’s really behind it—what their name servers and mail servers look like, any subdomains they’ve spun up recently, and where all those endpoints actually live. On top of that, I’m worried about look-alike tricks—domains with just a letter or two changed—that might resolve to the same IP space and even run a web server or open mail relay. Can you help me trace all of that back to the registrant’s info so I can see which ones share the same owner and which are red herrings? I really need everything backed by concrete DNS records, IP mappings, port/service checks, and ownership details—so I can show my team hard evidence, not just theories.",
      "retrieved_servers": [
        "Unknown",
        "Game Trends",
        "NixOS",
        "Wikipedia",
        "Weather Data"
      ],
      "ground_truth_server": "OSINT Intelligence",
      "query_id": "osint_intelligence_001",
      "retrieval_time_ms": 47.27053642272949,
      "is_correct": false
    },
    {
      "query": "Hey, I’m putting together a quick rundown of how active conversations have been in r/MachineLearning versus r/artificial over the past week. I’d love to know which of the hottest posts in each community really took off—how many comments they started with and how much they grew when you dig into the deeper threads. If any threads jumped past around fifty comments, could you take a closer look at how the discussion branches out there?\n\nI’m also really curious about anything mentioning GPT, Transformer, or LLaMA—how those keyword-driven talks compare in volume and depth to everything else. And then, for an extra comparison, if any exact same titles showed up in both subreddits, can you pull the first handful of comments from each and highlight any difference in tone or main concerns?\n\nAt the end, I need a sense of which discussions saw the biggest surge in engagement, the top three most-talked-about GPT/Transformer/LLaMA threads, and five solid recommendations on which AI topics are worth keeping an eye on next. I really need real comment counts and clear evidence behind it—no wild guesses. Thanks!",
      "retrieved_servers": [
        "Reddit",
        "Game Trends",
        "NASA Data",
        "Movie Recommender",
        "Call for Papers"
      ],
      "ground_truth_server": "Reddit",
      "query_id": "reddit_000",
      "retrieval_time_ms": 62.72435188293457,
      "is_correct": true
    },
    {
      "query": "Hey, I’m putting together a quick highlight for our ML community newsletter and I want to focus on two posts: the one that’s getting the most chatter right now and the next biggest by upvotes. Could you:\n\n• Grab the current top 5 hot threads from r/MachineLearning  \n• Figure out which one has the highest comment count and call that our “main” thread  \n• Skim its first 15 top-level comments (down to three replies deep) and check how many of those 15 actually sparked at least one reply—if more than 10 did, dig two more levels deep instead  \n• At the same time, pull the runner-up by score from the remaining four, read its first 10 comments up to two levels deep  \n• Finally, give me a JSON array of two objects (main and runner-up) where each object has:  \n  – id (post ID)  \n  – title  \n  – score  \n  – comment_count  \n  – fetched_depth (the depth you ended up using)  \n  – top_comment_snippet (the text of its single most upvoted top-level comment)  \n  – deeper_refetch_performed (true only if you had to go deeper on the main thread)\n\nI really need the real numbers and snippets so I can drop this straight into our newsletter—no guesses, just hard data. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Reddit",
        "NASA Data",
        "Game Trends",
        "Call for Papers",
        "Weather Data"
      ],
      "ground_truth_server": "Reddit",
      "query_id": "reddit_001",
      "retrieval_time_ms": 66.02764129638672,
      "is_correct": true
    },
    {
      "query": "I’ve been plotting a week-long road trip through California and Oregon, bouncing between parks where I can both hike and camp. I’d love to avoid anywhere that’s under closure alerts or has serious hazards, and I really need campgrounds that actually have showers—plus I’d like the visitor centers to be open every day from about 9 AM to 5 PM so I’m not showing up at a ghost town. On top of that, I’d be thrilled if there’s something cool going on each evening after 6 PM—like ranger talks, stargazing programs, live music, whatever. \n\nCould you help me figure out which parks fit all those criteria over the next seven days and then sketch out a day-by-day plan? I’m imagining something that tells me each day: where I’m headed, a quick park overview, which visitor centers are open with their hours, which campsites have showers, and any evening events I shouldn’t miss. \n\nI really need the details—current alerts, official hours, amenity lists, event schedules—so I can actually book and not just rely on hearsay. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Weather Data",
        "NASA Data",
        "NixOS",
        "Game Trends",
        "Call for Papers"
      ],
      "ground_truth_server": "National Parks",
      "query_id": "national_parks_000",
      "retrieval_time_ms": 61.87891960144043,
      "is_correct": false
    },
    {
      "query": "I’m planning a week of backpacking in California and trying to pick the three best national parks that won’t let me down. Ideally they’d offer solid hiking and camping, have almost no current closures or safety alerts, keep their visitor centers or services open every day for the next seven days, and have at least a couple of campgrounds with real potable water and toilets. It’d be even better if there’s some kind of event happening—like a ranger talk or guided walk—sometime in the upcoming week. Can you help me narrow it down to the top three spots and show me the proof—how many alerts they each have, their daily service coverage, how many campgrounds meet the water-and-toilet requirement, and what events they’ve got lined up? I need actual numbers and details so I can book with confidence.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Weather Data",
        "NASA Data",
        "NixOS",
        "National Parks",
        "Game Trends"
      ],
      "ground_truth_server": "National Parks",
      "query_id": "national_parks_001",
      "retrieval_time_ms": 45.783042907714844,
      "is_correct": false
    },
    {
      "query": "I’m putting together a research talk on medieval swords and I want to pick out five examples from two different corners of the Met—the Arms and Armor collection and the Medieval Art galleries. Ideally each sword would have a nice photo for my slides, but if one section only has a few with images, it’s okay to include some without so I still end up with five. For each piece, could you pull together its name, the date or era it comes from, the artist or cultural origin, and a link to its image (if there is one)? I really need concrete details and real links so I can plug them straight into my presentation without any guesses.",
      "retrieved_servers": [
        "Paper Search",
        "Bibliomantic",
        "Call for Papers",
        "FruityVice",
        "Reddit"
      ],
      "ground_truth_server": "Metropolitan Museum",
      "query_id": "metropolitan_museum_000",
      "retrieval_time_ms": 31.385183334350586,
      "is_correct": false
    },
    {
      "query": "I’ve gotten myself into a bit of an art-history deep dive: my prof wants a quick reference on the absolute earliest landscape paintings in the Met’s European collection—like, the ones that kicked off the whole genre over there. But I’m kind of lost on where to even start in their database. I think there’s a “European Paintings” section, and I only really want works tagged as “landscape,” ideally with actual images so I can drop them into my slides. Could you help me figure out which five pieces have the oldest documented dates, and then pull together each painting’s title, artist, date, medium, and a link to its main image? I really need solid, real-data details and URLs—nothing hand-wavy—so I can back up my little presentation. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Paper Search",
        "Bibliomantic",
        "Game Trends",
        "Weather Data",
        "NASA Data"
      ],
      "ground_truth_server": "Metropolitan Museum",
      "query_id": "metropolitan_museum_001",
      "retrieval_time_ms": 47.18661308288574,
      "is_correct": false
    },
    {
      "query": "Hey, I’m putting together a two-day movie marathon for my film club and I want three very different vibes: space exploration, post-apocalyptic survival, and that quirky steampunk flair. I’m thinking about ten go-to films for each vibe, but I also want to see if any titles show up in more than one category—that way those overlapping movies become the marquee picks. If nothing overlaps, I’ll just pick the top couple from each list. Then, for each of those headliners, I’d love around five more “movies like” them to really flesh out the lineup. Finally, I need a big master list of all those extra suggestions, sorted so the films that pop up most often float to the top. Can you pull together the original vibe lists, highlight the core picks, share all the expansion titles, and wrap up with that final ranked recommendation list? I really need actual movie names and how frequently they appear—no vague gut feelings—because I have to show this to the group.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Movie Recommender",
        "Game Trends",
        "Reddit",
        "NASA Data",
        "Car Price Evaluator"
      ],
      "ground_truth_server": "Movie Recommender",
      "query_id": "movie_recommender_000",
      "retrieval_time_ms": 57.15131759643555,
      "is_correct": true
    },
    {
      "query": "Hey, I’m putting together a week-long sci-fi film showcase at my local theater next week and need to nail down a slate of five movies. Ideally, they’d all be solid science-fiction picks that really lean into space exploration—starship voyages, alien worlds, that kind of epic adventure. I’m not sure there are five titles that hit both “pure sci-fi” and “deep space” perfectly, so if we can’t find enough classics crossing both, I’d top up the list with the best new sci-fi releases opening in the next seven days. Could you help me choose those five, highlight which ones come from that overlap of space-heavy sci-fi and which are the fresh upcoming flicks, and give me a quick note on why each made the cut? I really need actual titles with solid reasons so I can pitch it to our crowd.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Movie Recommender",
        "NASA Data",
        "Call for Papers",
        "NixOS",
        "Reddit"
      ],
      "ground_truth_server": "Movie Recommender",
      "query_id": "movie_recommender_001",
      "retrieval_time_ms": 52.99806594848633,
      "is_correct": true
    },
    {
      "query": "I’m putting together a high-level solar system briefing for some senior folks, and juggling all the pieces is giving me a headache. I need to know if any near-Earth asteroids are swinging by in the next week—especially the ones that might be flagged as potentially hazardous. At the same time, I’d love a snapshot of the Sun’s recent activity: flares, coronal mass ejections, particle storms, geomagnetic disturbances—everything from the past seven days. And if there’s been at least an M-class flare, could you grab that week-ahead solar wind forecast we usually lean on? I also want to double-check that no critical alerts slipped through, so please cross-check any space weather notifications from the past week.\n\nOn the imagery side, I could really use a fresh satellite shot of New York City (around 40.7128, –74.0060) plus the latest batch of EPIC Earth photos from deep space. Oh, and don’t forget today’s astronomy picture of the day—title, media type, and URL.\n\nFor the exoplanet section, show me the top 5 confirmed worlds that take more than about 300 days to orbit but are under twice Earth’s size. A small JSON snippet for that would be perfect so I can paste it straight into our system.\n\nFinally, I need the latest from Curiosity on Mars: what’s the most recent Martian sol and its Earth date, plus any new Mastcam shots from that sol?\n\nCould you bundle all of this into one neat report I can drop into our dashboard? I really need actual numbers and solid sources—no hand-waving, please.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "NASA Data",
        "Weather Data",
        "Game Trends",
        "Call for Papers",
        "NixOS"
      ],
      "ground_truth_server": "NASA Data",
      "query_id": "nasa_data_000",
      "retrieval_time_ms": 60.701847076416016,
      "is_correct": true
    },
    {
      "query": "Hey, I’ve got a bit of a space‐heavy request that’s been bugging me—my boss wants a one‐stop update covering a bunch of NASA goodies for the coming week, and I’m totally drowning in where to start. \n\nFirst off, can you see if any asteroids swing by Earth over the next seven days and then flag the three biggest ones? I’m talking diameter, so once you’ve got those, I’d love their JPL stats—like how bright they seem, how fast they’re moving, and just how close they actually get. \n\nWhile you’re at it, I also need a breakdown of everything going on with space weather during that same period. You know, all the flare alerts, geomagnetic storms, CMEs, radiation belt changes—any of those daily notifications—and a quick sense of how the solar wind might behave over the next week (if there’s a way to simulate it roughly, that’d be fantastic). \n\nOn top of that, I’m digging into urban growth around San Francisco. Could you grab the very latest satellite picture of the Bay Area and then zoom right in on 37.7749, –122.4194 with about a 0.1°×0.1° patch, checking the cloud cover too? \n\nAlso, Curiosity’s been snapping away—would you pull its mastcam shots from one sol before its most recent day and some navcam pics from that final sol? \n\nAnd just for fun (and science), I want to see which confirmed exoplanets out there take more than roughly 1,000 days to orbit but are under twice Earth’s radius—and from that group, which one has the looooongest year. \n\nOh, and before I forget: today’s Astronomy Picture of the Day (with a thumbnail if it’s a video) needs to be in there as well. \n\nI really can’t bring a bunch of vague opinions to my boss—everything should come with real numbers, dates, image links or data sources so I can back it all up. Thanks a ton!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "NASA Data",
        "Weather Data",
        "Game Trends",
        "Call for Papers",
        "NixOS"
      ],
      "ground_truth_server": "NASA Data",
      "query_id": "nasa_data_001",
      "retrieval_time_ms": 63.0643367767334,
      "is_correct": true
    },
    {
      "query": "So, here’s the deal: I’m putting together a quick “breakout radar” for BTC-USDT, ETH-USDT, and ADA-USDT, and I really need hard numbers to back any call. What I’m wondering is:\n\n– What’s the current price vs. its average over roughly the past day?  \n– How far off is that in percentage terms?  \n– In the last 15 minutes, does it look like the coin’s on an upswing or heading down?  \n– And over the last 5 minutes, has volume shot up or tanked compared to its recent average?  \n– Finally—based on all that—are any of these really cracking out into a breakout right now?\n\nCould you pull the live data, run those calculations, and give me a concise summary (JSON, table, whatever) for each pair? I can’t walk into my team meeting with gut feels—I need real, data-driven answers. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Game Trends",
        "NASA Data",
        "Bibliomantic",
        "Weather Data",
        "Car Price Evaluator"
      ],
      "ground_truth_server": "OKX Exchange",
      "query_id": "okx_exchange_000",
      "retrieval_time_ms": 58.129310607910156,
      "is_correct": false
    },
    {
      "query": "I’ve been tinkering with a quick crypto check for BTC and ETH – basically looking at the last half-hour of one-minute candles to see who’s been really moving. If either coin has jumped more than about 1% over those 30 minutes, I want to know its latest price and whether it’s still pushing in the same direction. Then, whichever one shows the bigger burst, could you peek at roughly the past hour of five-minute bars and give me a sense of how choppy its closes have been (like the % volatility)? And if that volatility turns out to be north of about 0.5%, I’d love a deeper look into the last 60 one-minute bars to see exactly what’s going on. In the end, I need a clear breakdown for each coin: the one-minute momentum %, the current price (if it qualified), a yes/no on whether it’s still trending, the five-minute volatility % for the stronger coin, and a flag saying if you did that extra minute-by-minute deep dive. I really need real numbers here – can’t just wing it in my presentation. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Game Trends",
        "NASA Data",
        "Weather Data",
        "Bibliomantic",
        "NixOS"
      ],
      "ground_truth_server": "OKX Exchange",
      "query_id": "okx_exchange_001",
      "retrieval_time_ms": 55.34839630126953,
      "is_correct": false
    },
    {
      "query": "I’m wrapping up a project on how deep learning is being used in genomics and proteomics, and my manager has asked for a snapshot of what’s really new in the last three months. I’ve seen buzz about CNNs, RNNs, Transformers and such, but I’m not sure which models are actually gaining traction across different studies, or which datasets they’ve been tested on (like specific genome sequencing collections versus mass-spec proteomics sets). Could you dive into the recent preprints and journal articles, pick out roughly eight of the newest papers, and for each one tell me:\n\n- What type of algorithm they used (CNN, RNN, Transformer, etc.)\n- Which genomic or proteomic dataset they evaluated on\n- Their headline performance number (accuracy, AUC, whatever they highlight)\n- A one-sentence summary of the main takeaway\n\nAlso, if any algorithm only shows up in a single paper (i.e. a one-off), flag it so I know it might be a fringe idea. I really need concrete details and real numbers—no vague impressions—because I’m presenting this to my team and need solid evidence from the actual studies.",
      "retrieved_servers": [
        "Paper Search",
        "Game Trends",
        "Call for Papers",
        "NASA Data",
        "Scientific Computing"
      ],
      "ground_truth_server": "Paper Search",
      "query_id": "paper_search_002",
      "retrieval_time_ms": 70.71948051452637,
      "is_correct": true
    },
    {
      "query": "Hey, I’m trying to put together a quick overview of what’s been happening with machine learning applied to protein folding over the past three months. My boss wants to know which approach is getting the most buzz – I’m betting AlphaFold still has the lead, but if papers aren’t talking about it, feel free to switch focus to RoseTTAFold. Could you pull together a set of recent studies from all the usual sources, tally how many times each one mentions the target method, note where you found each paper, and give me a one-sentence summary? For anything you can’t grab the full text on, just use the abstract. Then sort everything by the mention count so I can see at a glance who’s really driving the field. I really need actual counts and solid sources—no guesswork—so I can show the team the real numbers.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Paper Search",
        "Call for Papers",
        "NASA Data",
        "Reddit",
        "Game Trends"
      ],
      "ground_truth_server": "Paper Search",
      "query_id": "paper_search_004",
      "retrieval_time_ms": 64.8043155670166,
      "is_correct": true
    },
    {
      "query": "Hey, I’m wrestling with a pretty hefty bit of linear algebra and vector calculus for my project and could really use a hand. I’ve got two 3×3 matrices—one with rows [4, 2, 1], [2, 3, 0], [1, 0, 2] and the other [1, 0, 2], [0, 1, 1], [2, 1, 3]—and also two vectors [1, 2, 3] and [3, 2, 1]. On top of that there’s a scalar potential φ(x,y,z)=x²·y + y²·z + z²·x and a vector field F(x,y,z)=[x·y, y·z, z·x].  \n\nI need to see what happens when I add and subtract those matrices, multiply them, scale the product by 0.5 and then check its determinant. If the absolute value ends up over 0.1, I want the inverse; if not, we’ll have to dive into an SVD breakdown. After that I’d like to pull out eigenvalues and eigenvectors, get a QR decomposition, find an orthonormal basis for the scaled matrix’s column space, and then re-express the sum of the originals in that new basis—plus figure out the rank.  \n\nMeanwhile, for the vectors [1, 2, 3] and [3, 2, 1], I’d appreciate their dot product, cross product, and the projection of one onto the other. Then there’s the symbolic side: the gradient of φ, its directional derivative along [1, 1, 1], the curl of F at [1, 1, 1], the divergence of F at [0, 0, 0], and the scalar Laplacian of φ.  \n\nIf it’s not too much, could you also sketch a 3D plot of F over the cube x,y,z∈[–1, 1] and a 2D plot of f(x,y)=sin(√(x²+y²)) over x,y∈[–5, 5]? And once all that’s done, let’s wipe out every intermediate tensor or matrix so nothing’s left hanging.  \n\nI really need the exact numbers—my advisor wants concrete results, not just vague descriptions. Appreciate any help you can give!",
      "retrieved_servers": [
        "Scientific Computing",
        "Car Price Evaluator",
        "Medical Calculator",
        "FruityVice",
        "Paper Search"
      ],
      "ground_truth_server": "Scientific Computing",
      "query_id": "scientific_computing_000",
      "retrieval_time_ms": 68.69983673095703,
      "is_correct": true
    },
    {
      "query": "Hey, I’m working on this 3D Gaussian model for my thesis and it’s been driving me nuts. I’ve defined a covariance matrix that looks like\n\n[2.0, 0.3, 0.5  \n 0.3, 1.5, 0.4  \n 0.5, 0.4, 1.0]\n\nand my sample vector is [1.2, –0.8, 0.5]. I need to know if that matrix is actually invertible (what’s its determinant? if it comes out zero, I might shrink it by a factor of 0.01 so I can invert it), then get the inverse so I can plug it into my Mahalanobis stuff. On top of that, I’d love to see its eigenvalues and eigenvectors—and even run an SVD or QR to get a feel for its geometry—grab an orthonormal basis for its column space, and re-express the matrix there. When I project my vector onto the first eigenvector, what number do I get? \n\nAs a side project, I’m also exploring the function f(x,y,z)=exp(–0.5*(x²+y²+z²)). Could you tell me its directional derivative at [1.2, –0.8, 0.5] along that leading eigenvector? It’d be great to have the full symbolic gradient of f, plus the divergence and curl of that gradient field. And because I learn best by seeing things, I need a 3D quiver plot of the gradient over x,y,z from –2 to 2 (about 15 points per axis) and a simple 2D curve of exp(–0.5 x²) from x=–3 to 3 with y going from –0.1 to 1.1 (200 samples). \n\nMy advisor wants everything—determinant, inverse matrix, eigenvalues/vectors, singular values, Q and R from QR, your orthonormal basis, the changed-basis form, the projection value, the directional derivative, the gradient expression, divergence, curl—and the two plots all wrapped up in a JSON report. I really need hard numbers and visuals to back it all up, not just a high-level summary. Can you help me pull all that together?\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Scientific Computing",
        "NixOS",
        "Medical Calculator",
        "Movie Recommender",
        "Wikipedia"
      ],
      "ground_truth_server": "Scientific Computing",
      "query_id": "scientific_computing_001",
      "retrieval_time_ms": 58.197021484375,
      "is_correct": true
    },
    {
      "query": "I’m organizing a big outdoor festival and I’ve hit a bit of a snag: every time I check “Springfield” I get a dozen or more possibilities around the world, and the quick temperature readings I see online don’t always match the more detailed reports—sometimes by over two degrees, which makes me uneasy. \n\nWhat I’d really love is your help figuring out which Springfield and which day in the next week would give me the best shot at a warm, mostly dry day—ideally with the chance of rain at or under about 30%. If none of them can stay under that threshold, then just find me the day with the lowest chance of showers, no matter how it ranks on warmth. \n\nAlso, if you notice any of those Springfields where the “fast” temp and the official temp are more than 2 °C apart, just flag them for me so I know which cities to cross off. \n\nIn the end, I need a clear answer: which city, what date, and what the high/low temps, chance of rain and humidity look like that day. Plus a short note on any locations you tossed out because of weird temp mismatches. I’ve got to show my team real numbers, not just guesses, so please back everything up with solid data. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Weather Data",
        "NASA Data",
        "Call for Papers",
        "Game Trends",
        "Scientific Computing"
      ],
      "ground_truth_server": "Weather Data",
      "query_id": "weather_data_000",
      "retrieval_time_ms": 66.03002548217773,
      "is_correct": true
    },
    {
      "query": "I’m putting together an outdoor promo in Springfield next week and, to be honest, I’m not even sure which Springfield is the right one—there are so many! I’d like to zero in on the biggest city (somewhere over 100 K folks) and get a clear picture of what’s happening weather-wise right now. Also, if you could grab a quick temperature check and flag it if it’s off by more than a couple of degrees, that’d be great. Then, can you scan the forecast for the next three days and, if more than one day looks too rainy, stretch it out to the full seven-day outlook? What I really need is up to three days that sit around 20–25 °C with less than a 30 percent chance of rain. I need solid numbers and a detailed rundown so I can sell this plan to my boss—with real data, not just vibes.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Weather Data",
        "NASA Data",
        "Call for Papers",
        "Game Trends",
        "NixOS"
      ],
      "ground_truth_server": "Weather Data",
      "query_id": "weather_data_001",
      "retrieval_time_ms": 58.248281478881836,
      "is_correct": true
    },
    {
      "query": "Hey, I’m trying to schedule a one-hour global strategy call next week with our teams in New York, London and Tokyo. The only windows I’ve got are 09:00 UTC, 15:00 UTC or 20:00 UTC, and I’d love to pick the slot that keeps as many people as possible within their 9 am–5 pm workday. Could you work out what those UTC times look like locally in New York (America/New_York), London (Europe/London) and Tokyo (Asia/Tokyo), count how many offices fall into normal business hours for each option, and then recommend the best slot (going with the earlier one if there’s a tie)? It’d be awesome if you could drop all the details—local times, office counts and the final pick—in a simple JSON snippet, since I really need hard numbers to show my boss, not just guesses.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Weather Data",
        "Game Trends",
        "NixOS",
        "Call for Papers",
        "NASA Data"
      ],
      "ground_truth_server": "Time MCP",
      "query_id": "time_mcp_000",
      "retrieval_time_ms": 56.15997314453125,
      "is_correct": false
    },
    {
      "query": "I’m juggling a global team spread across Los Angeles, New York, London and Tokyo, and I need to lock down a one-hour meeting sometime during everyone’s 09:00–17:00 local workday in the upcoming week. Could you start by looking at the next full hour here in LA and then convert that slot into each office’s local time? If any of them fall outside 09:00–17:00, bump it an hour forward in LA and keep checking—rolling over to the next day at 09:00 if we hit 17:00—and keep going until we find a time that works for all four offices within the next seven days. If nothing lines up, just let me know it’s impossible. I really need the exact start and end times for each city so I can send the invites.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Time MCP",
        "Weather Data",
        "Call for Papers",
        "NASA Data",
        "Game Trends"
      ],
      "ground_truth_server": "Time MCP",
      "query_id": "time_mcp_001",
      "retrieval_time_ms": 54.351091384887695,
      "is_correct": true
    },
    {
      "query": "Hey, I’m gearing up for tomorrow’s multidisciplinary rounds and I’ve got three patients that are driving me nuts with all the numbers. First is Mr. A, a 65-year-old guy who’s about 95 kg and 170 cm (so roughly 67″). He’s diabetic, hypertensive, has CHF, prior MI and AF, and he’s headed for a high-risk suprainguinal vascular case. Labs show creatinine 1.8 mg/dL, cystatin C 1.5 mg/L, fasting insulin 20 µIU/mL, fasting glucose 150 mg/dL (but his electrolytes panel spiked his glucose to 200 mg/dL), calcium 8.0 mg/dL with albumin at 3.0 g/dL, sodium 130 mEq/L, total cholesterol 5.2 mmol/L and HDL 1.0 mmol/L. Vitals are 150/90 mmHg, HR 80, QT interval around 380 ms. He’s on oxycodone 5 mg q6h plus a 25 µg/h fentanyl patch, chronic prednisone 10 mg daily, plus standard antihypertensives and a statin. On top of that, his liver numbers—bilirubin 3.0 mg/dL, albumin 2.5 g/dL, INR 1.8—with slight ascites and grade 1 encephalopathy—have me wondering about his Child-Pugh and MELD.  \n\nThen there’s a 12-year-6-month-old girl, 50 kg, 150 cm, BP around 120/80, fasting insulin 15 µIU/mL, glucose 100 mg/dL.  \n\nAnd finally a 30-year-old pregnant woman who had her LMP on 2024-02-15 with a 30-day cycle.  \n\nI need to pull together their body metrics (BMI, BSA, ideal vs. adjusted weight), IV fluid rates, creatinine clearance vs. eGFR (and switch to the cystatin‐C equation if it’s under 60), MAP, HOMA-IR, corrected calcium and sodium, QTc, CHA₂DS₂-VASc, Wells’ PE probability, RCRI, Framingham and PREVENT 10-year risk, plus that liver scoring and her obstetric dates. Oh, and converting prednisone 10 mg to hydrocortisone and tallying his daily MME. Can you walk me through the actual calculations with those exact numbers and then tell me what you’d recommend for each? I really need hard data—no loose guesses—so I can confidently present to the team.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Medical Calculator",
        "NASA Data",
        "Bibliomantic",
        "FruityVice",
        "Car Price Evaluator"
      ],
      "ground_truth_server": "Medical Calculator",
      "query_id": "medical_calculator_000",
      "retrieval_time_ms": 84.25784111022949,
      "is_correct": true
    },
    {
      "query": "Hey, I’m looking at a 65-year-old guy who’s booked for an elective hip replacement and I’m a bit overwhelmed by all his numbers. He’s 95 kg, 175 cm tall, type 2 diabetic on insulin, hypertensive on meds, on a statin for high lipids, has chronic kidney disease (creatinine 1.4 mg/dL, cystatin C 1.0 mg/L), peripheral arterial disease, atrial fibrillation—and he still smokes. His latest labs show sodium 130 mEq/L with glucose at 280 mg/dL, calcium 8.2 mg/dL with albumin 3.3 g/dL, blood pressure about 150/95, total cholesterol 5.0 mmol/L and HDL 1.0 mmol/L. \n\nI’m trying to pull together:\n• a sense of his BMI and body surface area  \n• which weight to use for creatinine clearance (actual vs ideal vs adjusted)  \n• whether to trust a creatinine-only eGFR or the one that adds cystatin C (and what to do if they differ)  \n• corrected sodium for his high glucose and corrected calcium for low albumin  \n• his mean arterial pressure  \n• his 10-year cardiovascular event risk given age 65, male, TC 5.0, HDL 1.0, SBP 150, diabetes, smoking, on blood pressure meds and statin  \n• his revised cardiac risk index for non-cardiac surgery  \n• his CHA₂DS₂-VASc with AF, HTN, diabetes, peripheral vascular disease and age  \n• and even an idea of his insulin resistance via HOMA-IR using fasting insulin 20 µIU/mL and fasting glucose 140 mg/dL\n\nCan you walk me through all of that with every calculation, how you decided between weights or eGFRs, and the final risk estimates? I need all the intermediate figures and the reasoning—real numbers, no guesswork—so I can feel confident about the recommendations.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "retrieved_servers": [
        "Medical Calculator",
        "Bibliomantic",
        "BioMCP",
        "Car Price Evaluator",
        "Game Trends"
      ],
      "ground_truth_server": "Medical Calculator",
      "query_id": "medical_calculator_001",
      "retrieval_time_ms": 68.74465942382812,
      "is_correct": true
    }
  ],
  "metrics": {
    "overall": {
      "accuracy@1": 0.48214285714285715,
      "recall@1": 0.48214285714285715,
      "recall@3": 0.5,
      "recall@5": 0.5535714285714286,
      "mrr@1": 0.48214285714285715,
      "mrr@3": 0.49107142857142855,
      "mrr@5": 0.5035714285714286,
      "mrr": 0.5035714285714286,
      "avg_retrieval_time_ms": 60.05778908729553,
      "min_retrieval_time_ms": 31.385183334350586,
      "max_retrieval_time_ms": 84.25784111022949
    }
  },
  "failures": [
    {
      "query": "Hey, I’m working on this new dashboard that pulls search results from three different services—one for AI stuff, one for code hosting, and one for edge networking—and I’m scratching my head over how each handles pagination. Some APIs might use a page/page_size setup, others a cursor or next_cursor, and I’m not even sure if all of them support paging in their search calls or if I have to switch to their “list” routes instead. \n\nCould you dig into each service’s search endpoints and tell me:\n• whether it pages at all or not  \n• if it does, what style it uses (page numbers, cursors, etc.)  \n• the exact parameter names, types, required flags, and defaults  \n• any response fields that indicate where to pick up the next batch  \n\nAnd if a service’s search doesn’t page, check its list endpoints the same way. I really need a solid breakdown—names, defaults, response tokens—the whole picture, so I can convince my boss this setup will actually work. Need real details, not guesses. Thanks!",
      "query_id": "openapi_explorer_000",
      "ground_truth_server": "OpenAPI Explorer",
      "retrieved_servers": [
        "Weather Data",
        "Paper Search",
        "NixOS",
        "Car Price Evaluator",
        "Game Trends"
      ]
    },
    {
      "query": "Hey, I’m building a little integration for my team and could really use a sanity check on two services we’re about to hook up. One of them is an AI platform where most of what I’ll do is “create” stuff (models, completions, that kind of thing), and the other is a code-hosting service where I only care about endpoints under “/repos” for cloning, PRs, labels, etc. \n\nHere’s what I’m trying to figure out: for each of those AI create-calls, how many required fields do I actually need to send? And then for the repo routes on the other side, how many mandatory inputs are there in the path, query string or request body? On top of that, each service uses its own auth methods—API keys, OAuth2 flows, maybe others—and I’d love to know which types each one offers and which types they share so I can reuse our login flow.\n\nIt’d be a huge help if you could pull those counts straight from their specs, highlight any endpoints that demand more than three required inputs (those will need extra form design on our side), list out the auth scheme types for both platforms, and then point out the overlap. Ideally I’d get back a tidy JSON-style summary I can hand off to my manager. And please, real numbers only—I can’t show up with guesswork. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "query_id": "openapi_explorer_001",
      "ground_truth_server": "OpenAPI Explorer",
      "retrieved_servers": [
        "NixOS",
        "FruityVice",
        "Reddit",
        "Unknown",
        "Car Price Evaluator"
      ]
    },
    {
      "query": "Hey, I’m prepping for a Reactor X startup tomorrow and it’s stressing me out a bit. My boss handed me 14 different sensor readings, all in weird units, and I need to know if we meet the safety thresholds (which are all in SI or related metric units). Here’s what I’ve got:\n\n- Inlet temperature: 350 °F (threshold 150 °C)  \n- Inlet pressure: 50 psi (threshold 350 kPa)  \n- Reactor length: 10 ft (threshold 5 m)  \n- Catalyst weight: 500 lb (threshold 200 kg)  \n- Tank volume: 2000 imperial gal (threshold 8 m³)  \n- Data buffer: 2 GB (threshold 1500 MB)  \n- Heat-exchanger area: 1000 ft² (threshold 90 m²)  \n- Motor power: 50 hp (threshold 40 kW)  \n- Reaction time: 2 hours (threshold 6000 s)  \n- Valve angle: 0.25 turns (threshold 45 °)  \n- Conveyor speed: 2 m/s (threshold 4000 ft/min)  \n- Valve force: 500 lbf (threshold 2000 N)  \n- Fluid density: 128 lb/ft³ (threshold 2000 kg/m³)  \n- Fuel energy: 10000 Btu (threshold 12000 kJ)  \n\nCould you convert each reading into the same units as its threshold, then tell me for each one whether it passes (converted ≥ threshold) or fails? And if any come up as a fail, I’d really appreciate you doing a second check with a different conversion route—just to be absolutely sure we didn’t slip up on units. \n\nIt’d be awesome if you could bundle everything in a JSON summary that shows, for each sensor: its name, the original reading, the converted value with units, the threshold with units, pass/fail status, and the cross-validation details when you’ve done that extra check. I really need actual numbers on this—can’t go to my boss with just opinions. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "query_id": "unit_converter_000",
      "ground_truth_server": "Unit Converter",
      "retrieved_servers": [
        "Medical Calculator",
        "Scientific Computing",
        "NASA Data",
        "NixOS",
        "Weather Data"
      ]
    },
    {
      "query": "I’m gearing up for a 2 h 30 min high-altitude drone test flight and my boss wants every single detail in SI. Right now all my numbers are in U.S. customary units: engine inlet at 500 °F and outlet at 300 °F; propeller pitch is 15° (I’d like that in gons); cruise speed is 60 knots; altitude’s 10 000 ft; wing span 15 ft; wing area 1 200 in²; cargo-bay pressure 50 psi; takeoff thrust 3 000 lbf; on-board log storage is 2 GB with a 10 MB downlink buffer; battery capacity 5 kWh over this 2 h 30 min flight; and the fuel tank holds 200 US gal of fuel whose density is 810 g/L. \n\nCan you help me convert all of that—temperatures to kelvins, angle to gons, speed to m/s, lengths to meters, area to m², pressure to pascals, force to newtons, storage to bytes, energy to joules, compute the average power draw in kW then to horsepower, volume to m³, density to kg/m³, and time to seconds—then calculate the total starting fuel mass in kilograms and, if it ends up over 100 kg, report it in tonnes (otherwise in pounds)? In the end I need a tidy JSON where each entry has original_value, original_unit, converted_value, converted_unit, plus two computed fields—average_power and starting_fuel_mass—and a note on which fuel-mass branch you chose. I really need solid, data-driven numbers here—no hand-wavy estimates.",
      "query_id": "unit_converter_001",
      "ground_truth_server": "Unit Converter",
      "retrieved_servers": [
        "Medical Calculator",
        "Scientific Computing",
        "Car Price Evaluator",
        "NASA Data",
        "Weather Data"
      ]
    },
    {
      "query": "I’m prepping for a presentation on the big global climate deals and could really use some solid data. Could you find the main half-dozen—or so—negotiation frameworks that show up most often and give me a quick intro to each, plus roughly how many internal links or references they have? Then dive into the Paris Agreement: I’d like about a 200-word summary focused on its emission-reduction targets and five standout facts. After that, I’m curious what topics usually pop up alongside the Kyoto Protocol—aim for at least five related ideas, and if you only spot a few, try to round it out. Oh, and would you cross-check those five Paris facts against your summary and flag any that don’t actually appear there? Finally, please wrap everything into a single JSON output since my professor insists on that. And whatever you pull, make sure it’s backed by real numbers or citations—I can’t go in there with just opinions.",
      "query_id": "wikipedia_000",
      "ground_truth_server": "Wikipedia",
      "retrieved_servers": [
        "NASA Data",
        "Reddit",
        "Call for Papers",
        "Weather Data",
        "Bibliomantic"
      ]
    },
    {
      "query": "I’m putting together a sustainability briefing and need to really understand how solar panels stack up against wind turbines when it comes to environmental impacts—think resource use, lifecycle emissions, land use, etc. Could you:\n\n- Give me a short, punchy summary of each technology’s environmental footprint (a paragraph or two each).\n- Pull out about five of the most important facts related to their environmental impact for each, and show them side-by-side so I can see the main differences at a glance.\n\nOn top of that, I’ve got to cover the policy side—what incentive schemes or regulatory frameworks are actually driving solar and wind adoption right now? A clear, two-to-three-paragraph overview of the key support mechanisms would be great. While you’re at it, when you look at the main write-ups on solar and wind, do they actually link to that policy overview? Let me know “yes” or “no” for each.\n\nLastly, if you spot another renewable technology in those policy discussions that seems like a smart next step for us to research, tell me which one and give me two sentences on why it’s worth a closer look. \n\nI’m presenting next week, so I really need solid numbers and references—can’t go in with just vague statements. Thanks!",
      "query_id": "wikipedia_001",
      "ground_truth_server": "Wikipedia",
      "retrieved_servers": [
        "NASA Data",
        "Bibliomantic",
        "Game Trends",
        "Paper Search",
        "Scientific Computing"
      ]
    },
    {
      "query": "I’m trying to plan a fun bike ride around Denver’s Central Park this Saturday morning—thinking of starting and ending at the Denver Art Museum sometime between 9 and noon. I’d love to swing by a really good café on the way—something within a few miles that’s got at least a 4-star rating and is actually open when I’m riding. But I don’t want to kill myself on hills or end up riding forever, so I’m hoping to find the spot that gives me the shortest round-trip plus the least uphill grunt. \n\nCould you help me figure out which cafés in about a 5 km radius fit the bill, rank them by total distance plus elevation gain, pick the best one, and then give me turn-by-turn bike directions (with distances, estimated times, and elevation change) for a 9 AM departure? Also, it’d be awesome to get a quick summary of all the candidates—name, address, rating, distance and elevation details—so I can see why the top pick wins. I really need actual numbers here, not just opinions, so I can be confident this ride won’t turn into a slog.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "query_id": "google_maps_000",
      "ground_truth_server": "Google Maps",
      "retrieved_servers": [
        "Weather Data",
        "Car Price Evaluator",
        "Game Trends",
        "NASA Data",
        "National Parks"
      ]
    },
    {
      "query": "I’m planning a bike outing in downtown San Francisco next weekend and could really use a hand. I want to start around City Hall and rent from a solid shop that’s actually open when I arrive—and ideally rated 4 stars or higher. If I can’t find at least three places like that within a couple of kilometers, I’m okay with dropping to 3.5 stars just to have enough options. Then I’d love to cruise over to a top-rated café about a kilometer away. What I’m really after is the bike-shop/coffee-shop pairing that gives me the shortest ride. \n\nCould you figure out which rental spot and café that is, and give me all the nitty-gritty? I’d need the shop’s address, hours, phone number and website, plus the café’s name, address and rating. Also please include the total biking distance and time, full turn-by-turn directions, and how hilly the route is by giving me elevations at the start, midpoint and end—and even the street address of that midpoint. I need actual numbers and real locations, not vague guesses, so I can share it with my friends and get everything booked. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "query_id": "google_maps_001",
      "ground_truth_server": "Google Maps",
      "retrieved_servers": [
        "Car Price Evaluator",
        "Weather Data",
        "Bibliomantic",
        "FruityVice",
        "NixOS"
      ]
    },
    {
      "query": "I’ve been asked to put together a 360-degree update on the BRAF V600E mutation in melanoma and honestly, I’m a bit swamped. I need to know what’s come out in the last three months—papers (including any preprints), how often this mutation actually shows up and what that might mean clinically, which late-stage vemurafenib trials are still recruiting and who’s backing them, plus any biomarker angles (like PD-L1 criteria), the current take on vemurafenib’s profile, and whether there have been serious safety alerts or even hiccups with the genomic testing kits used in these studies. Basically, I can’t show up without solid figures—allele frequencies, trial counts, sponsor names, adverse-event tallies, device problem reports—everything tied back to real sources. Can you help me pull all that together in one place?\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "query_id": "biomcp_000",
      "ground_truth_server": "BioMCP",
      "retrieved_servers": [
        "NASA Data",
        "Paper Search",
        "Medical Calculator",
        "Game Trends",
        "National Parks"
      ]
    },
    {
      "query": "I’m working on a melanoma project and really stuck piecing together everything about that common BRAF V600E change. My boss wants a solid briefing on how that mutation drives the disease, what recent studies are saying, and whether treatments like vemurafenib or dabrafenib are truly holding up in patients who carry it. On top of that, I need to know what clinical trials are actually enrolling V600E-positive melanoma folks right now, how those trials are set up, what outcomes they’re reporting (and if any published papers or updates back them up), and how all that lines up with the drugs’ approved uses and safety concerns. \n\nI’m not looking for vague summaries—I need hard numbers, trial IDs, approval dates, key label warnings, safety‐signal stats, that sort of thing—all from the latest half‐year or so. Can you help me pull together a clear, evidence‐backed overview covering:\n\n• The role of BRAF V600E in melanoma  \n• Highlights from recent papers on that mutation  \n• Open Phase 2/3 studies targeting it (designs, outcomes, refs)  \n• Approval status and key label sections for vemurafenib/dabrafenib  \n• Any serious adverse event patterns reported post‐approval  \n\nI’ve got to show real data and sources—nothing off the cuff—so I can recommend the best targeted strategy. Thanks!",
      "query_id": "biomcp_001",
      "ground_truth_server": "BioMCP",
      "retrieved_servers": [
        "NASA Data",
        "Medical Calculator",
        "Paper Search",
        "Game Trends",
        "NixOS"
      ]
    },
    {
      "query": "I’m trying to choose between Next.js and Gatsby for a new project, and my manager wants a side-by-side look at their routing docs. Basically, I need to know how many real code examples each framework includes in its routing guide. If they’re almost neck-and-neck, I’d also like to see how many snippets they each have on dynamic routing. Could you dive into both official docs, count up those snippet examples for routing and dynamic routing, and let me know which one comes out ahead? I really need hard numbers—can’t just go to the boss with gut feelings.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "query_id": "context7_000",
      "ground_truth_server": "Context7",
      "retrieved_servers": [
        "NixOS",
        "Game Trends",
        "Movie Recommender",
        "Bibliomantic",
        "Call for Papers"
      ]
    },
    {
      "query": "Hey, I’ve got to lock in a JavaScript front-end framework for a new single-page app by next week, and routing plus solid state management are deal-breakers. I’m really prioritizing documentation that’s packed with real code examples, not just theory. Could you check out the two most highly regarded frameworks right now, tally up how many code snippets they each have for routing and for state handling, and see which one comes out ahead? If the front-runner has roughly 50 or more total snippets in those areas, I’ll go with that. If it falls short, I’d also want to know how many “advanced patterns” examples the second tool has and then pick whichever has more. I need actual counts to back this up—no vague opinions—so I can make a strong case to the team.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "query_id": "context7_001",
      "ground_truth_server": "Context7",
      "retrieved_servers": [
        "NixOS",
        "Game Trends",
        "Reddit",
        "Weather Data",
        "Call for Papers"
      ]
    },
    {
      "query": "I’m putting together a DeFi deep-dive for a client who’s curious how Ethereum stacks up against that other fast chain, Solana, in terms of big-money pools and how choppy they’ve been lately. Could you help me figure out which three pools on each network are moving the most USD volume right now, and call out any that jumped or dropped by more than about 5% in the last 24 hours? For those volatile ones, I’d love to see a daily price chart for roughly the past month and a look at the most recent ~50 swaps or liquidity moves. \n\nOn top of that, I need to know where USDC is getting the most action on each chain—so what’s the single largest USDC pair by volume, and how has its price trended day-to-day over the last month? And finally, can you give me a quick snapshot of overall DEX health across the ecosystem? I really need hard numbers and real data here—I can’t go in with just opinions. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "query_id": "dex_paprika_000",
      "ground_truth_server": "DEX Paprika",
      "retrieved_servers": [
        "Game Trends",
        "NASA Data",
        "Weather Data",
        "Medical Calculator",
        "Bibliomantic"
      ]
    },
    {
      "query": "I’ve got this project where my team needs a clear picture of what’s been happening on the biggest DeFi venues over the last six months—specifically Uniswap V3 on Ethereum and QuickSwap on Polygon. I’m trying to figure out which pools have been doing the heaviest trading (let’s say the top five by volume on each chain), then dig into how those pools have behaved day-to-day: price swings, rough volatility, number of trades, that kind of thing. \n\nOn top of that, I’d like to know what tokens are sitting in each of those pools, and whether those same tokens show up in any major pools on the other network. Ultimately, I want a side-by-side look at each pool’s address, token info, volume stats, daily price history (so we can calculate a volatility percentage), plus a quick snapshot of transaction counts and where else those tokens are getting traded cross-chain. \n\nSounds like a lot, I know—but I really need actual figures and solid data to back this up. Can you help me pull all that together? Whatever you find, please make sure it’s backed up by real numbers or reliable sources, okay?\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "query_id": "dex_paprika_001",
      "ground_truth_server": "DEX Paprika",
      "retrieved_servers": [
        "Game Trends",
        "NASA Data",
        "Weather Data",
        "Call for Papers",
        "Reddit"
      ]
    },
    {
      "query": "Hey, I’m wrapping up a new UI kit for my app and there are five icons I absolutely need—home, search, user-profile, notification and settings—but I’m not sure they all show up under those exact names in the library I’m using. For example, I’ve seen “user-profile” turned into “person” or “account,” notifications sneak in as “bell” or “alert,” and settings sometimes go by “gear” or “cog.” Could you dig in and see which ones are available under the exact or fallback names, then give me the actual import or usage snippets for React, Vue, Angular, Svelte, React Native and Flutter? If any icon doesn’t exist at all or a framework can’t handle one, just flag it so I know what’s missing or only partially supported. I really need real code examples, not just guesses, so I can hand it straight to my team.",
      "query_id": "huge_icons_000",
      "ground_truth_server": "Huge Icons",
      "retrieved_servers": [
        "NixOS",
        "Game Trends",
        "FruityVice",
        "Huge Icons",
        "NASA Data"
      ]
    },
    {
      "query": "I’m putting together docs for the Hugeicons set in my cross-platform component library and could really use some hard numbers and copy-and-paste code. First off, how many icons are in the entire collection? I need at least ten to make this guide worthwhile—if it’s under ten, let me know so I can rethink my approach. \n\nThen for the six core UI bits—home, search, notifications, settings, user, and logout—I’d like you to pick the very first icon that matches each name, but if it doesn’t show up try the “outline” version instead. Once you’ve chosen those, could you walk me through exactly how to import and use each one in React, Vue, Angular, Svelte, React Native, and Flutter? Finally, I need a ready-to-go React snippet for the home icon. \n\nIt would be amazing if you could bundle the whole thing—total icon count, a mapping of category to icon name (noting if you had to fall back), plus the usage instructions for each platform, and the React home example—in one JSON object I can drop straight into my docs. I really need concrete data and real code, not just general advice.",
      "query_id": "huge_icons_001",
      "ground_truth_server": "Huge Icons",
      "retrieved_servers": [
        "NixOS",
        "Huge Icons",
        "NASA Data",
        "Car Price Evaluator",
        "FruityVice"
      ]
    },
    {
      "query": "Hey, I’m knee-deep in setting up a spam filter for a side project and could really use some hard data to make a solid call. I’ve been poking around for a pre-trained English classifier that’s not too huge (ideally something under roughly 700 million parameters) and is released under an Apache-2.0-style license. I first checked out a few DistilBERT-ish models, but if none fit the bill, I guess I could fall back to something BERT-based. \n\nAt the same time, I need a dataset with at least around 20 k training examples so it doesn’t feel too flimsy, and I’d love to trial a couple of live demos—preferably built with something like Gradio—just to see how they actually perform on spammy text. \n\nAlso, since keeping up with the latest is crucial, I want to skim today’s fresh papers and see if any mention spam classification; if nothing jumps out, I’m okay with looking at the first handful for any useful benchmark scores or datasets they report. Oh, and if there are any community collections focusing on spam classification, I’d like a peek at those too.\n\nCould you pull together:\n- Details on the best fitting model (name, parameter count, license)\n- Dataset info (ID, train-size)\n- Any live demo spaces you find (with actual performance metrics)\n- A few of today’s papers that talk about spam filtering, with their datasets and scores\n- And any relevant collections or curated sets around spam classification\n\nThen, based on all that evidence—numbers, links, whatever—I’d love a recommendation for which model+dataset pairing seems strongest for fine-tuning. I really need concrete figures and sources so I can walk my boss through it with confidence, not just guesses. Thanks!",
      "query_id": "hugging_face_000",
      "ground_truth_server": "Hugging Face",
      "retrieved_servers": [
        "NASA Data",
        "Call for Papers",
        "Paper Search",
        "Reddit",
        "Game Trends"
      ]
    },
    {
      "query": "I’ve got this side project where I need to set up an English-to-French translation workflow, but I’m only allowed to use what’s already on Hugging Face. I’m a bit stuck figuring out which of Google’s translation models are both top quality and still on the lean side (maybe under a billion parameters?), and which of the OPUS English-to-French datasets have enough examples to actually work well (I’m thinking at least around ten thousand). \n\nIdeally I’d love to land on the three strongest model-dataset pairings, ranked by the dataset’s size—so I can show my boss some concrete options. And once those are picked, I’d also like to see if there are any live demos or Spaces where I can test them out, plus any recent papers that actually mention those exact models or datasets. Oh, and if Google or OPUS have bundled any of these into collections, point me to those too. \n\nI really need hard numbers, precise model sizes and dataset counts, direct links to demos, papers or collections—nothing vague. Can you dig up all that evidence for me?",
      "query_id": "hugging_face_001",
      "ground_truth_server": "Hugging Face",
      "retrieved_servers": [
        "Paper Search",
        "Bibliomantic",
        "Movie Recommender",
        "Car Price Evaluator",
        "Call for Papers"
      ]
    },
    {
      "query": "I’m pulling together a report on last quarter’s harvest from our 10 farms, and honestly I need some hard numbers. We recorded yields of 120, 150, 150, 200, 180, 170, 160, 140, 130, and 155 tons. \n\nHere’s what I’m trying to nail down:\n- What’s our total output, average yield per farm, the median and the most common harvest size, plus our lowest and highest yields and the overall spread?\n- Then, at $30 a ton, what does that translate to in revenue?\n- After covering $2,000 in fixed costs per farm (so 10 farms total), what’s left as net profit and what’s our profit margin when you express it as a percentage (rounded to the nearest whole number)?\n- Finally, I’m curious about the gap between our top-performing farm (200 tons) and the average yield—if that difference is more than 30 tons, I want to budget extra fertilizer at $10 per ton of that gap (and round up); if it’s 30 or less, I’ll stick with a $500 allowance (and round down).\n\nCould you crunch all those figures? I really need solid data—can’t go to my boss with just guesses. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "query_id": "math_mcp_000",
      "ground_truth_server": "Math MCP",
      "retrieved_servers": [
        "Game Trends",
        "Car Price Evaluator",
        "FruityVice",
        "Medical Calculator",
        "Math MCP"
      ]
    },
    {
      "query": "Hey, I’ve been digging into my sales over the last six months—120, 150, 130, 170, 150 and 160 units—and I’m honestly a bit lost on how to pull it all together for my boss. Could you help me figure out where I stand overall (like total sales, average, median, and which month number appeared most often), spot the best and worst months, and even see how the top month compares to the bottom as a ratio? \n\nAlso, I heard it’s useful to look at how skewed things are by subtracting the median from the mean, and then rounding that skewness differently depending on whether it’s positive or not. On top of that, we’re aiming for an average of 180 units over the next seven months—so I need to know the total target for those seven months and exactly how many extra units I’d have to push next month to hit it (rounded to a whole number). \n\nCould you put all of that into a clean JSON summary (with fields like total_sales, average_sales, median_sales, mode_sales, max_sales, min_sales, max_to_min_ratio, skewness, adjusted_skewness, target_total_7_months, additional_needed_next_month_exact, additional_needed_next_month_rounded)? I really need real numbers for every piece so I can back it up properly—no guesses, just solid calculations.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "query_id": "math_mcp_001",
      "ground_truth_server": "Math MCP",
      "retrieved_servers": [
        "Game Trends",
        "Car Price Evaluator",
        "Weather Data",
        "Medical Calculator",
        "NASA Data"
      ]
    },
    {
      "query": "I’ve got a bit of a situation with the domain example-inc.com. My boss wants a full picture of any look-alike sites, subdomains and exposed services so we can see if someone’s squatting on typos or even hosting malicious stuff on the same network. I’m not even sure how many variants there might be if you fuzz it a bit, and I don’t want to miss a single suspicious spelling error or clone that ends up pointing back to our own servers. \n\nCould you help me track down all the possible typo-style domains that resemble example-inc.com, figure out which ones pose the biggest risk, and then map out what subdomains they’ve got? I also need to know every IP they resolve to, what ports are open (especially SSH or web ports), and who technically “owns” each IP and domain from a registration standpoint. And if any of those look-alikes share IP ranges with the real example-inc.com, flag that as a potential “sibling” setup. \n\nAt the end, I really need solid numbers or output—like actual DNS/DNS record details, open-port findings, and registrar versus network-owner info—so I can show my team real evidence. Does that make sense?",
      "query_id": "osint_intelligence_000",
      "ground_truth_server": "OSINT Intelligence",
      "retrieved_servers": [
        "Unknown",
        "Paper Search",
        "NixOS",
        "Bibliomantic",
        "Weather Data"
      ]
    },
    {
      "query": "Hey, I’ve got this sketchy domain, fakeshoponline.com, that only popped up roughly three months ago and now keeps showing up in phishing reports. I’m trying to piece together who’s really behind it—what their name servers and mail servers look like, any subdomains they’ve spun up recently, and where all those endpoints actually live. On top of that, I’m worried about look-alike tricks—domains with just a letter or two changed—that might resolve to the same IP space and even run a web server or open mail relay. Can you help me trace all of that back to the registrant’s info so I can see which ones share the same owner and which are red herrings? I really need everything backed by concrete DNS records, IP mappings, port/service checks, and ownership details—so I can show my team hard evidence, not just theories.",
      "query_id": "osint_intelligence_001",
      "ground_truth_server": "OSINT Intelligence",
      "retrieved_servers": [
        "Unknown",
        "Game Trends",
        "NixOS",
        "Wikipedia",
        "Weather Data"
      ]
    },
    {
      "query": "I’ve been plotting a week-long road trip through California and Oregon, bouncing between parks where I can both hike and camp. I’d love to avoid anywhere that’s under closure alerts or has serious hazards, and I really need campgrounds that actually have showers—plus I’d like the visitor centers to be open every day from about 9 AM to 5 PM so I’m not showing up at a ghost town. On top of that, I’d be thrilled if there’s something cool going on each evening after 6 PM—like ranger talks, stargazing programs, live music, whatever. \n\nCould you help me figure out which parks fit all those criteria over the next seven days and then sketch out a day-by-day plan? I’m imagining something that tells me each day: where I’m headed, a quick park overview, which visitor centers are open with their hours, which campsites have showers, and any evening events I shouldn’t miss. \n\nI really need the details—current alerts, official hours, amenity lists, event schedules—so I can actually book and not just rely on hearsay. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "query_id": "national_parks_000",
      "ground_truth_server": "National Parks",
      "retrieved_servers": [
        "Weather Data",
        "NASA Data",
        "NixOS",
        "Game Trends",
        "Call for Papers"
      ]
    },
    {
      "query": "I’m planning a week of backpacking in California and trying to pick the three best national parks that won’t let me down. Ideally they’d offer solid hiking and camping, have almost no current closures or safety alerts, keep their visitor centers or services open every day for the next seven days, and have at least a couple of campgrounds with real potable water and toilets. It’d be even better if there’s some kind of event happening—like a ranger talk or guided walk—sometime in the upcoming week. Can you help me narrow it down to the top three spots and show me the proof—how many alerts they each have, their daily service coverage, how many campgrounds meet the water-and-toilet requirement, and what events they’ve got lined up? I need actual numbers and details so I can book with confidence.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "query_id": "national_parks_001",
      "ground_truth_server": "National Parks",
      "retrieved_servers": [
        "Weather Data",
        "NASA Data",
        "NixOS",
        "National Parks",
        "Game Trends"
      ]
    },
    {
      "query": "I’m putting together a research talk on medieval swords and I want to pick out five examples from two different corners of the Met—the Arms and Armor collection and the Medieval Art galleries. Ideally each sword would have a nice photo for my slides, but if one section only has a few with images, it’s okay to include some without so I still end up with five. For each piece, could you pull together its name, the date or era it comes from, the artist or cultural origin, and a link to its image (if there is one)? I really need concrete details and real links so I can plug them straight into my presentation without any guesses.",
      "query_id": "metropolitan_museum_000",
      "ground_truth_server": "Metropolitan Museum",
      "retrieved_servers": [
        "Paper Search",
        "Bibliomantic",
        "Call for Papers",
        "FruityVice",
        "Reddit"
      ]
    },
    {
      "query": "I’ve gotten myself into a bit of an art-history deep dive: my prof wants a quick reference on the absolute earliest landscape paintings in the Met’s European collection—like, the ones that kicked off the whole genre over there. But I’m kind of lost on where to even start in their database. I think there’s a “European Paintings” section, and I only really want works tagged as “landscape,” ideally with actual images so I can drop them into my slides. Could you help me figure out which five pieces have the oldest documented dates, and then pull together each painting’s title, artist, date, medium, and a link to its main image? I really need solid, real-data details and URLs—nothing hand-wavy—so I can back up my little presentation. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "query_id": "metropolitan_museum_001",
      "ground_truth_server": "Metropolitan Museum",
      "retrieved_servers": [
        "Paper Search",
        "Bibliomantic",
        "Game Trends",
        "Weather Data",
        "NASA Data"
      ]
    },
    {
      "query": "So, here’s the deal: I’m putting together a quick “breakout radar” for BTC-USDT, ETH-USDT, and ADA-USDT, and I really need hard numbers to back any call. What I’m wondering is:\n\n– What’s the current price vs. its average over roughly the past day?  \n– How far off is that in percentage terms?  \n– In the last 15 minutes, does it look like the coin’s on an upswing or heading down?  \n– And over the last 5 minutes, has volume shot up or tanked compared to its recent average?  \n– Finally—based on all that—are any of these really cracking out into a breakout right now?\n\nCould you pull the live data, run those calculations, and give me a concise summary (JSON, table, whatever) for each pair? I can’t walk into my team meeting with gut feels—I need real, data-driven answers. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "query_id": "okx_exchange_000",
      "ground_truth_server": "OKX Exchange",
      "retrieved_servers": [
        "Game Trends",
        "NASA Data",
        "Bibliomantic",
        "Weather Data",
        "Car Price Evaluator"
      ]
    },
    {
      "query": "I’ve been tinkering with a quick crypto check for BTC and ETH – basically looking at the last half-hour of one-minute candles to see who’s been really moving. If either coin has jumped more than about 1% over those 30 minutes, I want to know its latest price and whether it’s still pushing in the same direction. Then, whichever one shows the bigger burst, could you peek at roughly the past hour of five-minute bars and give me a sense of how choppy its closes have been (like the % volatility)? And if that volatility turns out to be north of about 0.5%, I’d love a deeper look into the last 60 one-minute bars to see exactly what’s going on. In the end, I need a clear breakdown for each coin: the one-minute momentum %, the current price (if it qualified), a yes/no on whether it’s still trending, the five-minute volatility % for the stronger coin, and a flag saying if you did that extra minute-by-minute deep dive. I really need real numbers here – can’t just wing it in my presentation. Thanks!\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "query_id": "okx_exchange_001",
      "ground_truth_server": "OKX Exchange",
      "retrieved_servers": [
        "Game Trends",
        "NASA Data",
        "Weather Data",
        "Bibliomantic",
        "NixOS"
      ]
    },
    {
      "query": "Hey, I’m trying to schedule a one-hour global strategy call next week with our teams in New York, London and Tokyo. The only windows I’ve got are 09:00 UTC, 15:00 UTC or 20:00 UTC, and I’d love to pick the slot that keeps as many people as possible within their 9 am–5 pm workday. Could you work out what those UTC times look like locally in New York (America/New_York), London (Europe/London) and Tokyo (Asia/Tokyo), count how many offices fall into normal business hours for each option, and then recommend the best slot (going with the earlier one if there’s a tie)? It’d be awesome if you could drop all the details—local times, office counts and the final pick—in a simple JSON snippet, since I really need hard numbers to show my boss, not just guesses.\n\nPlease ensure all findings are supported by concrete data and verifiable sources. I need specific numbers and evidence, not generalizations.",
      "query_id": "time_mcp_000",
      "ground_truth_server": "Time MCP",
      "retrieved_servers": [
        "Weather Data",
        "Game Trends",
        "NixOS",
        "Call for Papers",
        "NASA Data"
      ]
    }
  ]
}